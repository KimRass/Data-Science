- References
    - https://towardsdatascience.com/difference-between-autoencoder-ae-and-variational-autoencoder-vae-ed7be1c038f2
    - https://towardsdatascience.com/understanding-variational-autoencoders-vaes-f70510919f73

# Data Compression
- Data compression is an essential phase in training a network. The idea is to compress the data so that the same amount of information can be represented by fewer bits. This also helps with the problem of the curse of dimensionality. A dataset with many attributes is difficult to train with because it tends to overfit the model. Hence dimensionality reduction techniques need to be applied before the dataset can be used for training.

# AE (AutoEncoder)
- The autoencoder consists of two parts, an encoder, and a decoder. The encoder compresses the data from a higher-dimensional space to a lower-dimensional space (also called the latent space), while the decoder does the opposite i.e., convert the latent space back to higher-dimensional space. The decoder is used to ensure that latent space can capture most of the information from the dataset space, by forcing it to output what was fed as input to the decoder.
- ![ae](https://miro.medium.com/max/720/1*qFzKC1GqOR17XaiQBex83w.webp)
- During training, the input data x is fed to the encoder function e_theta(x). The input is passed through a series of layers (*parameterized by the variable theta*) reducing its dimensions to achieve a compressed latent vector z. The number of layers, type and size of the layers, and the latent space dimension are user-controlled parameters. Compression is achieved if the dimension of the latent space is less than that of the input space, essentially getting rid of redundant attributes.
- The decoder d_phi(z) usually (but not necessarily) consists of near-complement layers of the layers used in the encoder but in reverse order. A near-complement layer of a layer is the one that can be used to undo the operations (to some extent) of the original layer such as transposed conv layer to conv layer, pooling to unpooling, fully connected to fully connected, etc.
- Loss function
    - The entire encoder-decoder architecture is collectively trained on the loss function which encourages that the input is reconstructed at the output. Hence the loss function is the mean squared error between the encoder input and the decoder output.
    - *The idea is to have a very low dimensional latent space so that maximum compression is achieved, but at the same time, the error is small enough. Reducing the dimension of the latent space beyond a certain value will result in a significant loss of information.*
    - There are no constraints on the values/distribution of the latent space. It can be anything, as long as it can reconstruct the input when the decoder function is applied to it.
    - **The autoencoder is solely trained to encode and decode with as few loss as possible, no matter how the latent space is organized. Thus, if we are not careful about the definition of the architecture, it is natural that, during the training, the network takes advantage of any overfitting possibilities to achieve its task as well as it can… unless we explicitly regularize it!**
- Latent space visualization
    - ![ae_visualization](https://miro.medium.com/max/720/1*9yGDXANpZ-8j67m22RDDBA.webp)
    - It can be seen that the same digits tend to cluster themselves in the latent space. **Another important thing to note is that there are parts of the latent space that doesn't correspond to any data point. Using those as inputs to the encoder will result in an output that doesn’t look like any digit from the MNIST data. This is what we mean by that the latent space is not regularized. Such a latent space only has a few regions/cluster that has the generative capability, which means that sampling any point in the latent space that belongs within a cluster will generate a variation of the data that the cluster belongs to. But the entire latent space does not have the generative capability. The regions which do not belong to any cluster will generate garbage output. Once the network is trained, and the training data is removed, we have no way of knowing if the output generated by the decoder from a randomly sampled latent vector is valid or not. Hence AE is mainly used for compression.**
    - **For valid inputs, the AE is able to compress them to fewer bits essentially getting rid of the redundancy (Encoder) but due to non-regularized latent space, the decoder can not be used to generate valid input data from latent vectors sampled from the latent space.**
    - Once the autoencoder has been trained, we have both an encoder and a decoder but still no real way to produce any new content. At first sight, we could be tempted to think that, if the latent space is regular enough (well "organized" by the encoder during the training process), we could take a point randomly from that latent space and decode it to get a new content. The decoder would then act more or less like the generator of a Generative Adversarial Network.
    - ![ae_content_generation](https://miro.medium.com/max/1400/1*iSfaVxcGi_ELkKgAG0YRlQ@2x.webp)
    - Irregular latent space prevent us from using autoencoder for new content generation.

# VAE (Variational AutoEncoder)
- *Variational autoencoder addresses the issue of non-regularized latent space in autoencoder and provides the generative capability to the entire space.* The encoder in the AE outputs latent vectors. **Instead of outputting the vectors in the latent space, the encoder of VAE outputs parameters of a pre-defined distribution in the latent space for every input. The VAE then imposes a constraint on this latent distribution forcing it to be a normal distribution. This constraint makes sure that the latent space is regularized.**
- ![vae](https://miro.medium.com/max/720/1*ET6FM_KEmwa2N4qgW2MglQ.webp)
- During training, the input data x is fed to the encoder function e_theta(x). Just like AE, the input is passed through a series of layers (parameterized by the variable theta) reducing its dimensions to achieve a compressed latent vector z. **However, the latent vector is not the output of the encoder. Instead, the encoder outputs the mean and the standard deviation for each latent variable. The latent vector is then sampled from this mean and standard deviation which is then fed to the decoder to reconstruct the input. The decoder in the VAE works similarly to the one in AE.**
- **So, in order to be able to use the decoder of our autoencoder for generative purpose, we have to be sure that the latent space is regular enough. One possible solution to obtain such regularity is to introduce explicit regularization during the training process. Thus, a variational autoencoder can be defined as being an autoencoder whose training is regularized to avoid overfitting and ensure that the latent space has good properties that enable generative process.**
- *In order to introduce some regularization of the latent space, we proceed to a slight modification of the encoding-decoding process: instead of encoding an input as a single point, we encode it as a distribution over the latent space.*
- ![ae_and_vae](https://miro.medium.com/max/1400/1*ejNnusxYrn1NRDZf4Kg2lw@2x.webp)
- *In practice, the encoded distributions are chosen to be normal so that the encoder can be trained to return the mean and the covariance matrix that describe these Gaussians.* **The reason why an input is encoded as a distribution with some variance instead of a single point is that it makes possible to express very naturally the latent space regularization: the distributions returned by the encoder are enforced to be close to a standard normal distribution.**
- Loss function
    - Hence the training loss of VAE is defined as the sum of the reconstruction loss and the similarity loss. The reconstruction error, just like in AE, is the mean squared loss of the input and reconstructed output. *The similarity loss is the KL divergence between the latent space distribution and standard gaussian (zero mean and unit variance).* The loss function is then the sum of these two losses.
    - **As mentioned before, the latent vector is sampled from the encoder-generated distribution before feeding it to the decoder. This random sampling makes it difficult for backpropagation to happen for the encoder since we can’t trace back errors due to this random sampling. Hence we use a reparameterization trick to model the sampling process which makes it possible for the errors to propagate through the network. The latent vector z is represented as a function of the encoder’s output.**
    - *Thus, the loss function that is minimized when training a VAE is composed of a "reconstruction term", that tends to make the encoding-decoding scheme as performant as possible, and a "regularization term", that tends to regularize the organization of the latent space by making the distributions returned by the encoder close to a standard normal distribution.* That regularization term is expressed as the Kulback-Leibler divergence between the returned distribution and a standard Gaussian.
- Latent space visualization
    - **The training tries to find a balance between the two losses and ends up with a latent space distribution that looks like the unit norm with clusters grouping similar input data points. The unit norm condition makes sure that the latent space is evenly spread out and does not have significant gaps between clusters. In fact, the clusters of similar-looking data inputs usually overlap in some regions.**
    - ![vae_visualization](https://miro.medium.com/max/640/1*EdYJUXgXiM4M78-YeNMVwA.webp)
    - An important thing to note is that when the latent vector is sampled from the regions with overlapping clusters, we get morphed data. We get a smooth transition between the decoder's output when we sample the latent space moving from one cluster to the other.
- Regularization
    - ![regularization](https://miro.medium.com/max/1400/1*83S0T8IEJyudR_I5rI9now@2x.webp)
    - The regularity that is expected from the latent space in order to make generative process possible can be expressed through two main properties: *continuity (two close points in the latent space should not give two completely different contents once decoded) and completeness (for a chosen distribution, a point sampled from the latent space should give "meaningful" content once decoded).*
    - **The only fact that VAEs encode inputs as distributions instead of simple points is not sufficient to ensure continuity and completeness. Without a well defined regularization term, the model can learn, in order to minimise its reconstruction error, to "ignore" the fact that distributions are returned and behave almost like classic autoencoders (leading to overfitting). To do so, the encoder can either return distributions with tiny variances (that would tend to be punctual distributions) or return distributions with very different means (that would then be really far apart from each other in the latent space). In both cases, distributions are used the wrong way (cancelling the expected benefit) and continuity and/or completeness are not satisfied.**
    - **So, in order to avoid these effects we have to regularize both the covariance matrix and the mean of the distributions returned by the encoder. In practice, this regularization is done by enforcing distributions to be close to a standard normal distribution (centered and reduced). This way, we require the covariance matrices to be close to the identity, preventing punctual distributions, and the mean to be close to 0, preventing encoded distributions to be too far apart from each others.**
    - ![regulariation_2](https://miro.medium.com/max/1400/1*9ouOKh2w-b3NNOVx4Mw9bg@2x.webp)