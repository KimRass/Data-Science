{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Teacher-Forcing\" data-toc-modified-id=\"Teacher-Forcing-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Teacher Forcing</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#(?)-seq2seq-기계-번역기-동작시키기\" data-toc-modified-id=\"(?)-seq2seq-기계-번역기-동작시키기-1.0.1\"><span class=\"toc-item-num\">1.0.1&nbsp;&nbsp;</span>(?) seq2seq 기계 번역기 동작시키기</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-23T10:18:18.768054Z",
     "start_time": "2022-01-23T10:18:18.752269Z"
    }
   },
   "source": [
    "- ![seq2seq](https://wikidocs.net/images/page/24996/%EC%9D%B8%EC%BD%94%EB%8D%94%EB%94%94%EC%BD%94%EB%8D%94%EB%AA%A8%EB%8D%B8.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-23T11:42:33.212772Z",
     "start_time": "2022-01-23T11:42:33.175357Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 22029,
     "status": "ok",
     "timestamp": 1609330819777,
     "user": {
      "displayName": "Jongbeom Kim",
      "photoUrl": "",
      "userId": "17252605958116038360"
     },
     "user_tz": -540
    },
    "id": "l34_bpbmfVPK",
    "outputId": "56154e30-4c71-476f-ad31-546e3d0da6de"
   },
   "outputs": [],
   "source": [
    "# from IPython.display import HTML, display\n",
    "# def set_css():\n",
    "#   display(HTML('''\n",
    "#   <style>\n",
    "#     pre {white-space: pre-wrap;}\n",
    "#   </style>\n",
    "#   '''))\n",
    "# get_ipython().events.register(\"pre_run_cell\", set_css)\n",
    "# from google.colab import drive\n",
    "# drive.mount(\"/content/drive\", force_remount=True)\n",
    "# import os\n",
    "# import sys\n",
    "# try:\n",
    "#     my_path = \"/content/notebooks\"\n",
    "#     os.symlink(\"/content/drive/MyDrive/ColabNotebooks/my_env\", my_path)\n",
    "#     sys.path.insert(0, my_path)\n",
    "# except:\n",
    "#     pass\n",
    "# os.chdir(my_path)\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Input, Model, Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator\n",
    "from tensorflow.keras.layers import Layer, Dense, Flatten, Dropout, Concatenate, Add, Dot, Multiply, Reshape, Activation, BatchNormalization, SimpleRNNCell, RNN, SimpleRNN, LSTM, Embedding, Bidirectional, TimeDistributed, Conv1D, Conv2D, MaxPool1D, MaxPool2D, GlobalMaxPool1D, GlobalMaxPool2D, AveragePooling1D, AveragePooling2D, GlobalAveragePooling1D, GlobalAveragePooling2D, ZeroPadding2D\n",
    "from tensorflow.keras.optimizers import SGD, Adam, Adagrad\n",
    "from tensorflow.keras.metrics import MeanSquaredError, RootMeanSquaredError, MeanAbsoluteError, MeanAbsolutePercentageError, BinaryCrossentropy, CategoricalCrossentropy, SparseCategoricalCrossentropy, CosineSimilarity\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Rescaling\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.activations import linear, sigmoid, relu\n",
    "from tensorflow.keras.initializers import RandomNormal, glorot_uniform, he_uniform, Constant\n",
    "from tensorflow.keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import urllib3\n",
    "import zipfile\n",
    "import shutil\n",
    "import json\n",
    "import os\n",
    "from nltk.translate.bleu_score import sentence_bleu, corpus_bleu, SmoothingFunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-23T10:17:35.389380Z",
     "start_time": "2022-01-23T10:17:35.035925Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "executionInfo": {
     "elapsed": 2574,
     "status": "ok",
     "timestamp": 1609327961361,
     "user": {
      "displayName": "Jongbeom Kim",
      "photoUrl": "",
      "userId": "17252605958116038360"
     },
     "user_tz": -540
    },
    "id": "w650GKn9YTN8",
    "outputId": "3d7f6ef5-600a-4fde-eb2d-420e3c697097"
   },
   "outputs": [],
   "source": [
    "raw_data = pd.read_table(\"./Datasets/fra-eng/fra.txt\", usecols=[0, 1], names=[\"tar\", \"src\"])\n",
    "\n",
    "# raw_data = raw_data.sample(60000, random_state=777)\n",
    "# raw_data = raw_data.reset_index(drop=True)\n",
    "raw_data[\"src\"] = raw_data[\"src\"].str.lower()\n",
    "raw_data[\"tar\"] = raw_data[\"tar\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-23T11:44:40.141653Z",
     "start_time": "2022-01-23T11:44:40.121650Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tar</th>\n",
       "      <th>src</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go.</td>\n",
       "      <td>Va !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hi.</td>\n",
       "      <td>Salut !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hi.</td>\n",
       "      <td>Salut.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Run!</td>\n",
       "      <td>Cours !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Run!</td>\n",
       "      <td>Courez !</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    tar       src\n",
       "0   Go.      Va !\n",
       "1   Hi.   Salut !\n",
       "2   Hi.    Salut.\n",
       "3  Run!   Cours !\n",
       "4  Run!  Courez !"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-23T11:45:21.081420Z",
     "start_time": "2022-01-23T11:45:19.007202Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(char_level=True)\n",
    "tokenizer.fit_on_texts(raw_data[\"src\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-10T12:26:18.033301Z",
     "start_time": "2022-01-10T12:26:17.324343Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "executionInfo": {
     "elapsed": 984,
     "status": "ok",
     "timestamp": 1609327965610,
     "user": {
      "displayName": "Jongbeom Kim",
      "photoUrl": "",
      "userId": "17252605958116038360"
     },
     "user_tz": -540
    },
    "id": "Kp9YEIuPYTN-",
    "outputId": "8fa5cd10-8ed4-43c9-c29b-8fdb3788254e"
   },
   "outputs": [],
   "source": [
    "chars_src = set([char for sent in data[\"src\"] for char in sent])\n",
    "chars_tar = set([char for sent in data[\"tar\"] for char in sent])\n",
    "\n",
    "char2idx_src = {}\n",
    "char2idx_src.update({char:idx+1 for idx, char in enumerate(chars_src)})\n",
    "idx2char_src = {value:key for key, value in char2idx_src.items()}\n",
    "\n",
    "char2idx_tar = {}\n",
    "char2idx_tar[\"<SOS>\"] = 1\n",
    "char2idx_tar[\"<EOS>\"] = 2\n",
    "char2idx_tar.update({char:idx+3 for idx, char in enumerate(chars_tar)})\n",
    "idx2char_tar = {value:key for key, value in char2idx_tar.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-10T12:28:09.143836Z",
     "start_time": "2022-01-10T12:28:09.119830Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'t': 1, 'v': 2, 'Q': 3, 'a': 4, '€': 5, 'B': 6, 'm': 7, 'o': 8, '7': 9, 's': 10, 'ú': 11, 'e': 12, 'H': 13, 'R': 14, '6': 15, '-': 16, 'L': 17, 'A': 18, 'U': 19, '%': 20, '0': 21, 'w': 22, \"'\": 23, 'r': 24, 'G': 25, '\"': 26, '\\xa0': 27, 'º': 28, '‘': 29, 'u': 30, 'V': 31, 'K': 32, '3': 33, 'O': 34, 'n': 35, 'y': 36, '4': 37, 'J': 38, 'ö': 39, ' ': 40, '/': 41, '?': 42, 'i': 43, ';': 44, 'p': 45, 'c': 46, '8': 47, 'b': 48, 'F': 49, 'C': 50, 'X': 51, 'l': 52, 'f': 53, '$': 54, 'é': 55, '–': 56, 'ç': 57, '₂': 58, ',': 59, '&': 60, '!': 61, 'Z': 62, 'z': 63, 'S': 64, 'E': 65, '5': 66, '+': 67, '1': 68, 'x': 69, 'h': 70, 'k': 71, 'd': 72, '\\xad': 73, 'D': 74, 'I': 75, '’': 76, 'P': 77, 'M': 78, ':': 79, 'N': 80, 'Y': 81, 'q': 82, '.': 83, '2': 84, 'T': 85, 'W': 86, '—': 87, 'g': 88, 'j': 89, '9': 90}\n",
      "{'<SOS>': 1, '<EOS>': 2, '…': 3, 't': 4, 'v': 5, 'Q': 6, 'Ê': 7, 'a': 8, 'B': 9, '(': 10, 'm': 11, 'À': 12, 'o': 13, '7': 14, 's': 15, 'e': 16, '‽': 17, 'H': 18, 'R': 19, ')': 20, '6': 21, '-': 22, 'L': 23, 'A': 24, 'U': 25, '%': 26, '0': 27, \"'\": 28, 'w': 29, '\\u202f': 30, 'r': 31, 'Ô': 32, '\\u2009': 33, 'G': 34, '\"': 35, '\\xa0': 36, 'œ': 37, '‘': 38, '»': 39, 'u': 40, 'V': 41, 'â': 42, 'É': 43, 'K': 44, '3': 45, 'Â': 46, 'è': 47, 'O': 48, 'n': 49, 'y': 50, '4': 51, 'J': 52, 'ö': 53, ' ': 54, '/': 55, '?': 56, 'i': 57, 'î': 58, ';': 59, 'p': 60, 'ï': 61, 'c': 62, '8': 63, 'b': 64, 'F': 65, 'C': 66, 'X': 67, 'l': 68, 'f': 69, 'ù': 70, '$': 71, 'é': 72, '–': 73, 'ç': 74, '₂': 75, 'С': 76, 'ô': 77, ',': 78, '&': 79, '!': 80, 'Z': 81, 'z': 82, 'S': 83, 'E': 84, '5': 85, '+': 86, '1': 87, 'x': 88, 'h': 89, 'k': 90, 'd': 91, 'û': 92, 'á': 93, 'D': 94, 'ë': 95, 'à': 96, '«': 97, '’': 98, 'I': 99, 'P': 100, '\\u200b': 101, 'M': 102, 'ê': 103, 'N': 104, ':': 105, 'Y': 106, 'q': 107, '.': 108, '2': 109, 'T': 110, 'W': 111, 'Ç': 112, 'j': 113, 'g': 114, '9': 115}\n"
     ]
    }
   ],
   "source": [
    "print(char2idx_src)\n",
    "print(char2idx_tar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tI7uHCCzYTN-"
   },
   "source": [
    "- 정상적으로 정수 인코딩이 수행된 것을 볼 수 있습니다. 아직 정수 인코딩을 수행해야 할 데이터가 하나 더 남았습니다. 디코더의 예측값과 비교하기 위한 실제값이 필요합니다. 그런데 이 실제값에는 시작 심볼에 해당되는 `<sos>`가 있을 필요가 없습니다. 이해가 되지 않는다면 이전 페이지의 그림으로 돌아가 Dense와 Softmax 위에 있는 단어들을 다시 보시기 바랍니다. 그래서 이번에는 정수 인코딩 과정에서 `<sos>`를 제거합니다. 즉, 모든 프랑스어 문장의 맨 앞에 붙어있는 '\\t'를 제거하도록 합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-10T12:32:19.836719Z",
     "start_time": "2022-01-10T12:32:17.976497Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "executionInfo": {
     "elapsed": 1736,
     "status": "ok",
     "timestamp": 1609327966771,
     "user": {
      "displayName": "Jongbeom Kim",
      "photoUrl": "",
      "userId": "17252605958116038360"
     },
     "user_tz": -540
    },
    "id": "lpEdzne7YTN-",
    "outputId": "658c94a4-f1c5-4148-b091-c1f4815f54cc"
   },
   "outputs": [],
   "source": [
    "enc_input = data[\"src\"].apply(lambda x:[char2idx_src[char] for char in x]).tolist()\n",
    "dec_input = data[\"tar\"].apply(lambda x:[1]+[char2idx_tar[char] for char in x]).tolist()\n",
    "dec_true = data[\"tar\"].apply(lambda x:[char2idx_tar[char] for char in x]+[2]).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-10T12:41:54.274863Z",
     "start_time": "2022-01-10T12:41:54.168639Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "executionInfo": {
     "elapsed": 751,
     "status": "ok",
     "timestamp": 1609328042825,
     "user": {
      "displayName": "Jongbeom Kim",
      "photoUrl": "",
      "userId": "17252605958116038360"
     },
     "user_tz": -540
    },
    "id": "spk0qLNOa0jE",
    "outputId": "b59e1a47-4a29-4e4a-c2ab-6d4d07e02ffb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "길이가 가장 긴 문장의 길이는 262이고 길이가 71 이하인 문장이 전체의 99%를 차지합니다.\n",
      "길이가 가장 긴 문장의 길이는 326이고 길이가 87 이하인 문장이 전체의 99%를 차지합니다.\n"
     ]
    }
   ],
   "source": [
    "lens_enc = sorted([len(doc) for doc in enc_input])\n",
    "ratio = 0.99\n",
    "max_len_enc = int(np.quantile(lens_enc, ratio))\n",
    "print(f\"길이가 가장 긴 문장의 길이는 {np.max(lens_enc)}이고 길이가 {max_len_enc} 이하인 문장이 전체의 {ratio:.0%}를 차지합니다.\")\n",
    "\n",
    "lens_dec = sorted([len(doc) for doc in dec_input])\n",
    "ratio = 0.99\n",
    "max_len_dec = int(np.quantile(lens_dec, ratio))\n",
    "print(f\"길이가 가장 긴 문장의 길이는 {np.max(lens_dec)}이고 길이가 {max_len_dec} 이하인 문장이 전체의 {ratio:.0%}를 차지합니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-10T12:44:08.418834Z",
     "start_time": "2022-01-10T12:42:55.224861Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "executionInfo": {
     "elapsed": 4784,
     "status": "ok",
     "timestamp": 1609328054802,
     "user": {
      "displayName": "Jongbeom Kim",
      "photoUrl": "",
      "userId": "17252605958116038360"
     },
     "user_tz": -540
    },
    "id": "mPi-I91BYTOB",
    "outputId": "8c596da2-8979-476b-9f83-58bbdb7e6d8a"
   },
   "outputs": [],
   "source": [
    "enc_input = tf.keras.preprocessing.sequence.pad_sequences(enc_input, padding=\"post\", maxlen=max_len_enc)\n",
    "dec_input = tf.keras.preprocessing.sequence.pad_sequences(dec_input, padding=\"post\", maxlen=max_len_dec)\n",
    "dec_true = tf.keras.preprocessing.sequence.pad_sequences(dec_true, padding=\"post\", maxlen=max_len_dec)\n",
    "\n",
    "enc_input = tf.keras.utils.to_categorical(enc_input)\n",
    "dec_input = tf.keras.utils.to_categorical(dec_input)\n",
    "dec_true = tf.keras.utils.to_categorical(dec_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VFgSoJ1BYTOB"
   },
   "source": [
    "- ![rnn](https://wikidocs.net/images/page/24996/rnn%EA%B7%BC%ED%99%A9.PNG)\n",
    "- 이미 RNN에 대해서 배운 적이 있지만, 다시 복습을 해보도록 하겠습니다. 하나의 RNN 셀은 각각의 시점(time step)마다 두 개의 입력을 받습니다.\n",
    "- 현재 시점(time step)을 t라고 할 때, RNN 셀은 t-1에서의 은닉 상태와 t에서의 입력 벡터를 입력으로 받고, t에서의 은닉 상태를 만듭니다. 이때 t에서의 은닉 상태는 바로 위에 또 다른 은닉층이나 출력층이 존재할 경우에는 위의 층으로 보내거나, 필요없으면 값을 무시할 수 있습니다. 그리고 RNN 셀은 다음 시점에 해당하는 t+1의 RNN 셀의 입력으로 현재 t에서의 은닉 상태를 입력으로 보냅니다.\n",
    "- RNN 챕터에서도 언급했지만, 이런 구조에서 현재 시점 t에서의 은닉 상태는 과거 시점의 동일한 RNN 셀에서의 모든 은닉 상태의 값들의 영향을 누적해서 받아온 값이라고 할 수 있습니다. 그렇기 때문에 앞서 우리가 언급했던 컨텍스트 벡터는 사실 인코더에서의 마지막 RNN 셀의 은닉 상태값을 말하는 것이며, 이는 입력 문장의 모든 단어 토큰들의 정보를 요약해서 담고있다고 할 수 있습니다.\n",
    "- 디코더는 인코더의 마지막 RNN 셀의 은닉 상태인 컨텍스트 벡터를 첫번째 은닉 상태의 값으로 사용합니다. 디코더의 첫번째 RNN 셀은 이 첫번째 은닉 상태의 값과, 현재 t에서의 입력값인 `<sos>`로부터, 다음에 등장할 단어를 예측합니다.\n",
    "\n",
    "# Teacher Forcing\n",
    "- 모델을 설계하기 전에 혹시 의아한 점은 없으신가요? 현재 시점의 디코더 셀의 입력은 오직 이전 디코더 셀의 출력을 입력으로 받는다고 설명하였는데 dec_input이 왜 필요할까요?\n",
    "- 훈련 과정에서는 이전 시점의 디코더 셀의 출력을 현재 시점의 디코더 셀의 입력으로 넣어주지 않고, 이전 시점의 실제값을 현재 시점의 디코더 셀의 입력값으로 하는 방법을 사용할 겁니다. 그 이유는 이전 시점의 디코더 셀의 예측이 틀렸는데 이를 현재 시점의 디코더 셀의 입력으로 사용하면 현재 시점의 디코더 셀의 예측도 잘못될 가능성이 높고 이는 연쇄 작용으로 디코더 전체의 예측을 어렵게 합니다. 이런 상황이 반복되면 훈련 시간이 느려집니다. 만약 이 상황을 원하지 않는다면 이전 시점의 디코더 셀의 예측값 대신 실제값을 현재 시점의 디코더 셀의 입력으로 사용하는 방법을 사용할 수 있습니다. 이와 같이 RNN의 모든 시점에 대해서 이전 시점의 예측값 대신 실제값을 입력으로 주는 방법을 교사 강요라고 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 379
    },
    "executionInfo": {
     "elapsed": 1246,
     "status": "ok",
     "timestamp": 1609330223709,
     "user": {
      "displayName": "Jongbeom Kim",
      "photoUrl": "",
      "userId": "17252605958116038360"
     },
     "user_tz": -540
    },
    "id": "Cv1RK5MTxeFC",
    "outputId": "f69d5197-8a74-41da-8459-c9dda337e8c9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {white-space: pre-wrap;}\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input_enc (InputLayer)          [(None, None, 59)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Input_dec (InputLayer)          [(None, None, 78)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "LSTM_enc (LSTM)                 [(None, 256), (None, 323584      Input_enc[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "LSTM_dec (LSTM)                 [(None, None, 256),  343040      Input_dec[0][0]                  \n",
      "                                                                 LSTM_enc[0][1]                   \n",
      "                                                                 LSTM_enc[0][2]                   \n",
      "__________________________________________________________________________________________________\n",
      "Dense (Dense)                   (None, None, 78)     20046       LSTM_dec[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 686,670\n",
      "Trainable params: 686,670\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_path = os.path.join(my_path, f\"fra_eng_char-level_seq2seq-2.h5\")\n",
    "if os.path.exists(model_path):\n",
    "    model = tf.keras.models.load_model(model_path)\n",
    "\n",
    "    model.summary()\n",
    "else:\n",
    "    input_enc = Input(shape=(None, len(char2idx_src)+1), name=\"input_enc\")\n",
    "    _, h_state, c_state = LSTM(units=256, return_state=True, name=\"lstm_enc\")(input_enc)\n",
    "\n",
    "    input_dec = Input(shape=(None, len(char2idx_tar)+1), name=\"input_dec\")\n",
    "    lstm_dec_layer = LSTM(units=256, return_sequences=True, return_state=True, name=\"lstm_dec\")\n",
    "    lstm_dec, _, _ = lstm_dec_layer(input_dec, initial_state=[h_state, c_state])\n",
    "    # 디코더의 첫 상태를 인코더의 은닉 상태, 셀 상태로 합니다.\n",
    "    dense_dec_layer = Dense(units=len(char2idx_tar)+1, activation=\"softmax\", name=\"dense_dec\")\n",
    "    dense_dec = dense_dec_layer(lstm_dec)\n",
    "\n",
    "    model = Model(inputs=[input_enc, input_dec], outputs=dense_dec)\n",
    "\n",
    "    model.summary()\n",
    "    \n",
    "    model.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\",\n",
    "                  metrics=[\"categorical_accuracy\"])\n",
    "\n",
    "    es = EarlyStopping(monitor=\"val_loss\", mode=\"auto\", verbose=1, patience=4)\n",
    "    mc = ModelCheckpoint(filepath=model_path, monitor=\"val_categorical_accuracy\",\n",
    "                         mode=\"auto\", verbose=1, save_best_only=True)\n",
    "    \n",
    "    hist = model.fit(x=[enc_input, dec_input], y=dec_true, batch_size=128, epochs=50,\n",
    "                     validation_split=0.2, callbacks=[es, mc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 216
    },
    "executionInfo": {
     "elapsed": 1399,
     "status": "ok",
     "timestamp": 1609330224589,
     "user": {
      "displayName": "Jongbeom Kim",
      "photoUrl": "",
      "userId": "17252605958116038360"
     },
     "user_tz": -540
    },
    "id": "uQqqHIhRYTOD",
    "outputId": "8f14345f-e65b-40f0-e71a-456d13660337"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {white-space: pre-wrap;}\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 7 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f97525d46a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "je suis contre ce projet de loi.<EOS>\n",
      "œ1ll1zp1lp/j90999 9,  + ,,, 9,3ê9\n"
     ]
    }
   ],
   "source": [
    "# 학습이 맞게 됐는지 확인\n",
    "i = 110\n",
    "pred = model.predict([tf.expand_dims(enc_input[i], axis=0), tf.expand_dims(dec_input[i], axis=0)])\n",
    "\n",
    "sent = \"\"\n",
    "for idx in tf.argmax(dec_true[i], axis=1).numpy():\n",
    "    if idx != 0:\n",
    "        sent += idx2char_tar[idx]\n",
    "print(sent)\n",
    "\n",
    "sent = \"\"\n",
    "for idx in tf.argmax(pred[0], axis=1).numpy():\n",
    "    if idx != 0:\n",
    "        sent += idx2char_tar[idx]\n",
    "print(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YQDLJkvCYTOE"
   },
   "source": [
    "### (?) seq2seq 기계 번역기 동작시키기\n",
    "- 앞서 seq2seq는 훈련할 때와 동작할 때의 방식이 다르다고 언급한 바 있습니다. 이번에는 입력한 문장에 대해서 기계 번역을 하도록 모델을 조정하고 동작시켜보도록 하겠습니다.\n",
    "- 전체적인 번역 동작 단계를 정리하면 아래와 같습니다.\n",
    "    1. 번역하고자 하는 입력 문장이 인코더에 들어가서 은닉 상태와 셀 상태를 얻습니다.\n",
    "    2. 상태와 `<SOS>`를 디코더로 보냅니다.\n",
    "    3. 디코더가 `<EOS>`가 나올 때까지 다음 문자를 예측하는 행동을 반복합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rD5vl9rcYTOF"
   },
   "source": [
    "- 우선 인코더를 정의합니다. enc_inputs와 encoder_states는 훈련 과정에서 이미 정의한 것들을 재사용하는 것입니다. 이제 디코더를 설계해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 107
    },
    "executionInfo": {
     "elapsed": 997,
     "status": "ok",
     "timestamp": 1609330243042,
     "user": {
      "displayName": "Jongbeom Kim",
      "photoUrl": "",
      "userId": "17252605958116038360"
     },
     "user_tz": -540
    },
    "id": "54KFid58fJoC",
    "outputId": "3a4c805b-effe-4f00-a98b-94e1a91603f1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {white-space: pre-wrap;}\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.engine.input_layer.InputLayer at 0x7f97529d7438>,\n",
       " <tensorflow.python.keras.engine.input_layer.InputLayer at 0x7f9752d01f60>,\n",
       " <tensorflow.python.keras.layers.recurrent_v2.LSTM at 0x7f97529d7908>,\n",
       " <tensorflow.python.keras.layers.recurrent_v2.LSTM at 0x7f9753533278>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x7f9753533cc0>]"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "executionInfo": {
     "elapsed": 855,
     "status": "ok",
     "timestamp": 1609330243361,
     "user": {
      "displayName": "Jongbeom Kim",
      "photoUrl": "",
      "userId": "17252605958116038360"
     },
     "user_tz": -540
    },
    "id": "NGBHG4gTYTOF",
    "outputId": "e729e08f-5fd7-4d20-8568-4c2de1753ae1",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {white-space: pre-wrap;}\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_enc = model.layers[0].output\n",
    "_, h_state, c_state = model.layers[2].output\n",
    "\n",
    "enc_model = tf.keras.Model(inputs=input_enc, outputs=[h_state, c_state])\n",
    "\n",
    "input_dec = model.layers[1].output\n",
    "h_state_bef = Input(shape=(256,))\n",
    "c_state_bef = Input(shape=(256,))\n",
    "# 문장의 다음 단어를 예측하기 위해서 initial_state를 이전 시점의 상태로 사용합니다.\n",
    "lstm_dec_layer = model.layers[3]\n",
    "lstm_dec, h_state_aft, c_state_aft = lstm_dec_layer(input_dec, initial_state=[h_state_bef, c_state_bef])\n",
    "dense_dec_layer = model.layers[4]\n",
    "dense_dec = dense_dec_layer(lstm_dec)\n",
    "\n",
    "dec_model = tf.keras.Model(inputs=[input_dec]+[h_state_bef, c_state_bef], outputs=[dense_dec]+[h_state_aft, c_state_aft])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "executionInfo": {
     "elapsed": 776,
     "status": "ok",
     "timestamp": 1609331354782,
     "user": {
      "displayName": "Jongbeom Kim",
      "photoUrl": "",
      "userId": "17252605958116038360"
     },
     "user_tz": -540
    },
    "id": "MqbVBmExYTOG",
    "outputId": "9be7b630-3b2b-429e-a87a-7af26720a027"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {white-space: pre-wrap;}\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {white-space: pre-wrap;}\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def decode_seq(input_seq):\n",
    "# seq = enc_input[i:i+1]\n",
    "    enc_states = enc_model.predict(input_seq)\n",
    "\n",
    "    # <SOS>에 해당하는 OHE를 생성합니다.\n",
    "    seq = np.zeros((1, 1, len(char2idx_tar)+1))\n",
    "    seq[0, 0, char2idx_tar[\"<SOS>\"]] = 1\n",
    "\n",
    "    stop_cond = False\n",
    "    decoded_sent = \"\"\n",
    "    # stop_cond이 True가 될 때까지 반복합니다.\n",
    "    while not stop_cond:\n",
    "        # 이점 시점의 states를 현재 시점의 states로 사용합니다.\n",
    "        output_tokens, h_state, c_state = dec_model.predict([seq] + enc_states)\n",
    "        argmax = np.argmax(output_tokens[0, -1, :])\n",
    "    #     argmax = np.argmax(output_tokens[0, 0])\n",
    "        char = idx2char_tar[argmax]\n",
    "        decoded_sent += char\n",
    "        # 현재 시점의 예측 결과를 다음 시점의 입력으로 사용하기 위해 저장합니다.\n",
    "        seq = np.zeros((1, 1, len(char2idx_tar)+1))\n",
    "        seq[0, 0, argmax] = 1\n",
    "        enc_states = [h_state, c_state]\n",
    "        \n",
    "        # \"<EOS>\"에 도달하거나 최대 길이를 넘으면 stop_cond=True를 저장합니다.\n",
    "        if char == \"<EOS>\" or len(decoded_sent) == max_len_dec:\n",
    "            stop_cond = True\n",
    "    return decoded_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 741
    },
    "executionInfo": {
     "elapsed": 8532,
     "status": "ok",
     "timestamp": 1609331437952,
     "user": {
      "displayName": "Jongbeom Kim",
      "photoUrl": "",
      "userId": "17252605958116038360"
     },
     "user_tz": -540
    },
    "id": "ZbbUbHkjzpuk",
    "outputId": "d73b7b61-0b3a-46af-a650-beb4337ad829"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {white-space: pre-wrap;}\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {white-space: pre-wrap;}\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "입력 문장 : why do you need change?\n",
      "정답 문장 : ourquoi as-tu besoin de changement \n",
      "번역 문장 : jz3lw(++1yj1…w+l1+jl…zp3+lœ1ljz… <EOS\n",
      "BLEU-1 : 0\n",
      "BLEU-2 : 0\n",
      "BLEU-3 : 0\n",
      "BLEU-4 : 0\n",
      "-----------------------------------\n",
      "입력 문장 : why did you change your mind?\n",
      "정답 문장 : ourquoi as-tu changé d'avis \n",
      "번역 문장 : j(l+z0êp+lœ;(s1êjl3;(lw(+l8j8ljê(s(p//8 <EOS\n",
      "BLEU-1 : 0\n",
      "BLEU-2 : 0\n",
      "BLEU-3 : 0\n",
      "BLEU-4 : 0\n",
      "-----------------------------------\n",
      "입력 문장 : we don't want to lose you.\n",
      "정답 문장 : ous ne voulons pas vous perdre\n",
      "번역 문장 : sz0+l(s1)ljz0jlœ1l+0pj1lùl/(l…(p+z3 <EOS\n",
      "BLEU-1 : 0\n",
      "BLEU-2 : 0\n",
      "BLEU-3 : 0\n",
      "BLEU-4 : 0\n",
      "-----------------------------------\n",
      "입력 문장 : see that this never happens again.\n",
      "정답 문장 : aites en sorte que ça ne se produise plus\n",
      "번역 문장 : èj1+ysz0+lwêèj1lùlc(pê1lh(l&<EOS\n",
      "BLEU-1 : 0\n",
      "BLEU-2 : 0\n",
      "BLEU-3 : 0\n",
      "BLEU-4 : 0\n",
      "-----------------------------------\n",
      "입력 문장 : you must not lose sight of your main object.\n",
      "정답 문장 : l ne faut pas que tu perdes de vue ton objectif principal\n",
      "번역 문장 : /1+lwêp4l+z3jl+0êl/1lwzp3jlœ1lw(ê/1êlœ1l/(l3z0êêpj0ê1l1jlœ1l/;(êç13j <EOS\n",
      "BLEU-1 : 0\n",
      "BLEU-2 : 0\n",
      "BLEU-3 : 0\n",
      "BLEU-4 : 0\n"
     ]
    }
   ],
   "source": [
    "actual, pred = list(), list()\n",
    "for seq_index in range(231, 236):\n",
    "    input_seq = enc_input[seq_index:seq_index+1]\n",
    "    decoded_sent = decode_seq(input_seq)\n",
    "    \n",
    "    actual.append([data[\"tar\"][seq_index][1:len(data[\"tar\"][seq_index])-1].split()])\n",
    "    pred.append(decoded_sent[:len(decoded_sent)-1].split())\n",
    "                  \n",
    "    print(35 * \"-\")\n",
    "    print(f\"입력 문장 : {data['src'][seq_index]}\")\n",
    "    print(f\"정답 문장 : {data['tar'][seq_index][1:len(data['tar'][seq_index])-1]}\")\n",
    "    print(f\"번역 문장 : {decoded_sent[:len(decoded_sent)-1]}\")\n",
    "    sf = SmoothingFunction()\n",
    "    print(f\"BLEU-1 : {corpus_bleu(actual, pred, weights=(1, 0, 0, 0),\\\n",
    "                                  smoothing_function=sf.method1)}\")\n",
    "    print(f\"BLEU-2 : {corpus_bleu(actual, pred, weights=(1/2, 1/2, 0, 0),\\\n",
    "                                  smoothing_function=sf.method1)}\")\n",
    "    print(f\"BLEU-3 : {corpus_bleu(actual, pred, weights=(1/3, 1/3, 1/3, 0),\\\n",
    "                                  smoothing_function=sf.method1)}\")\n",
    "    print(f\"BLEU-4 : {corpus_bleu(actual, pred, weights=(1/4, 1/4, 1/4, 1/4),\\\n",
    "                                  smoothing_function=sf.method1)}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Neural Machine Translation(Character-Level seq2seq / fra-eng Dataset)",
   "provenance": []
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "191.594px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
