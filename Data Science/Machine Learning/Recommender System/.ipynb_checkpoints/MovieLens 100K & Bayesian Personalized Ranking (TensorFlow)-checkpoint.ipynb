{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#K-Core-Pruning\" data-toc-modified-id=\"K-Core-Pruning-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>K-Core Pruning</a></span></li><li><span><a href=\"#Spliting-Dataset\" data-toc-modified-id=\"Spliting-Dataset-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Spliting Dataset</a></span></li><li><span><a href=\"#Modeling\" data-toc-modified-id=\"Modeling-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Modeling</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Regularization-적용하기\" data-toc-modified-id=\"Regularization-적용하기-3.0.1\"><span class=\"toc-item-num\">3.0.1&nbsp;&nbsp;</span>Regularization 적용하기</a></span></li></ul></li><li><span><a href=\"#학습-데이터-구성하기\" data-toc-modified-id=\"학습-데이터-구성하기-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>학습 데이터 구성하기</a></span><ul class=\"toc-item\"><li><span><a href=\"#학습-데이터-구성하기\" data-toc-modified-id=\"학습-데이터-구성하기-3.1.1\"><span class=\"toc-item-num\">3.1.1&nbsp;&nbsp;</span>학습 데이터 구성하기</a></span></li><li><span><a href=\"#모델-학습하기\" data-toc-modified-id=\"모델-학습하기-3.1.2\"><span class=\"toc-item-num\">3.1.2&nbsp;&nbsp;</span>모델 학습하기</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-15T17:28:00.306555Z",
     "start_time": "2022-01-15T17:28:00.292168Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\82104\\anaconda3\\lib\\site-packages\\tqdm\\std.py:697: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from google_drive_downloader import GoogleDriveDownloader as gdd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import copy\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Input, Model, Sequential\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Dropout, Concatenate, Add, Dot, Multiply, Reshape, Activation, BatchNormalization, SimpleRNNCell, RNN, SimpleRNN, LSTM, Embedding, Bidirectional, TimeDistributed, Conv1D, Conv2D, MaxPool1D, MaxPool2D, GlobalMaxPool1D, GlobalMaxPool2D, AveragePooling1D, AveragePooling2D, GlobalAveragePooling1D, GlobalAveragePooling2D, ZeroPadding2D\n",
    "from tensorflow.keras.optimizers import SGD, Adam, Adagrad\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError, BinaryCrossentropy, SparseCategoricalAccuracy\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Rescaling\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.activations import linear, sigmoid, relu\n",
    "\n",
    "tqdm.pandas()\n",
    "np.set_printoptions(precision=3)\n",
    "plt.style.use(\"dark_background\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-15T17:28:00.363999Z",
     "start_time": "2022-01-15T17:28:00.310164Z"
    }
   },
   "outputs": [],
   "source": [
    "users = pd.read_csv(\"Datasets/MovieLens 100k/100k_users.csv\")\n",
    "movies = pd.read_csv(\"Datasets/MovieLens 100k/100k_movies.csv\")\n",
    "ratings = pd.read_csv(\"Datasets/MovieLens 100k/100k_ratings.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Core Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-15T17:28:00.408327Z",
     "start_time": "2022-01-15T17:28:00.363999Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(ratings): 99,991\n",
      "len(ratings): 99,023\n",
      "Finished!\n"
     ]
    }
   ],
   "source": [
    "thr = 5\n",
    "len_prev = -1\n",
    "len_next = -2\n",
    "while len_prev != len_next:\n",
    "    len_prev = len(ratings)\n",
    "    print(f\"len(ratings): {len(ratings):,}\")\n",
    "    \n",
    "    user_n_ratings = ratings[\"user_id\"].value_counts()\n",
    "    users_ = user_n_ratings[user_n_ratings>thr].index\n",
    "    \n",
    "    item_n_ratings = ratings[\"item_id\"].value_counts()\n",
    "    items_ = item_n_ratings[item_n_ratings>thr].index\n",
    "\n",
    "    ratings = ratings[(ratings[\"user_id\"].isin(users_)) & (ratings[\"item_id\"].isin(items_))]\n",
    "    len_next = len(ratings)\n",
    "print(\"Finished!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spliting Dataset\n",
    "- 시간 순서대로 Dataset을 나누겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-15T17:28:01.889716Z",
     "start_time": "2022-01-15T17:28:00.408327Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa4e13ff0ee741e89fe2d7adb7512a22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=943.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "len(ratings_tr): 88,681\n",
      "len(ratings_te): 10,342\n"
     ]
    }
   ],
   "source": [
    "ratings_tr = pd.DataFrame()\n",
    "ratings_te = pd.DataFrame()\n",
    "for _, group in tqdm(ratings.groupby([\"user_id\"])):\n",
    "    tr, te = train_test_split(group, test_size=0.1, shuffle=False)\n",
    "    ratings_tr = pd.concat([ratings_tr, tr], axis=0)\n",
    "    ratings_te = pd.concat([ratings_te, te], axis=0)\n",
    "\n",
    "print(f\"len(ratings_tr): {len(ratings_tr):,}\")\n",
    "print(f\"len(ratings_te): {len(ratings_te):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-15T17:28:06.506996Z",
     "start_time": "2022-01-15T17:28:01.889716Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "489f13af09a549e0bfa8c6a28631bcbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=10342.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "movie_n_ratings = ratings.groupby([\"item_id\"]).size().sort_values(ascending=False)\n",
    "\n",
    "X_te = copy.deepcopy(ratings_te)\n",
    "y_te = ratings_te[[\"rating\"]]\n",
    "user_movies = ratings.groupby([\"user_id\"])[\"item_id\"].apply(frozenset)\n",
    "X_te[\"items\"] = X_te[\"user_id\"].apply(lambda x : user_movies[x])\n",
    "X_te = X_te.drop([\"rating\"], axis=1)\n",
    "\n",
    "# `item_id`: 본 영화 1개\n",
    "# `items_100`: 보지 않은 영화 100개\n",
    "X_te[\"items_100\"] = X_te.progress_apply(lambda x:random.choices(list(x[\"items\"] - {x[\"item_id\"]}), k=100, weights=movie_n_ratings[list(x[\"items\"] - {x[\"item_id\"]})]), axis=1)\n",
    "\n",
    "# def pick_items_100(x):\n",
    "#     temp = movie_n_ratings[~movie_n_ratings.index.isin(x[\"items\"])]\n",
    "#     return set(temp.sample(100, replace=False, weights=movie_n_ratings).index)\n",
    "\n",
    "# X_te[\"items_100\"] = X_te.progress_apply(lambda x : pick_items_100(x), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-15T17:28:06.576550Z",
     "start_time": "2022-01-15T17:28:06.506996Z"
    }
   },
   "outputs": [],
   "source": [
    "input_user = Input(shape=(), name=\"Input_user\")\n",
    "input_pos = Input(shape=(), name=\"Input_pos\")\n",
    "input_neg = Input(shape=(), name=\"Input_neg\")\n",
    "inputs = [input_user, input_pos, input_neg]\n",
    "\n",
    "# n_users = ratings[\"user_id\"].nunique()\n",
    "# n_items = ratings[\"item_id\"].nunique()\n",
    "n_users = ratings[\"user_id\"].max() + 1\n",
    "n_items = ratings[\"item_id\"].max() + 1\n",
    "dim = 30\n",
    "emb_user = Embedding(input_dim=n_users, output_dim=dim + 1, name=\"Embedding_user\")\n",
    "emb_item = Embedding(input_dim=n_items, output_dim=dim + 1, name=\"Embedding_item\")\n",
    "\n",
    "z1 = emb_user(input_user)\n",
    "# z2 = emb_item(input_pos)\n",
    "# z3 = emb_item(input_neg)\n",
    "z2 = emb_item(input_pos)\n",
    "z3 = emb_item(input_neg)\n",
    "\n",
    "# 우리는 고객이 본 아이템에 대한 Score와 고객이 보지 않은 아이템에 대한 Score의 차이가 극대화되도록 학습하게 됩니다. 이를 위해 BPR에서는 Individual Probability, 즉 고객이 본 아이템에 대해 보지 않은 아이템보다 선호할 확률을 구하게 됩니다.\n",
    "# Bayesian Personalized Ranking은 위의 확률이 100%가 되도록 학습합니다.\n",
    "pos_score = Dot(axes=(1, 1))([z1, z2])\n",
    "neg_score = Dot(axes=(1, 1))([z1, z3])\n",
    "diff = pos_score - neg_score\n",
    "outputs = sigmoid(diff)\n",
    "\n",
    "# 입력값은 크게 세가지 input_user, input_pos,input_neg으로 나뉘어집니다. 그리고 출력값은 보지 않은 아이템에 대한 선호도보다 본 아이템에 대한 선호도가 높을 확률(individual probability)인 probs이 됩니다.\n",
    "model = Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-15T16:54:19.829351Z",
     "start_time": "2022-01-15T16:54:19.813704Z"
    }
   },
   "outputs": [],
   "source": [
    "#유저 임베딩에서 우리는 마지막 임베딩에 1을 추가해주어야 합니다. 아이템 임베딩의 마지막 원소값 Bias를 추가하기 위함입니다.바로 아래와 같은 방식으로 유저 임베딩과 아이템 임베딩이 형성됩니다.\n",
    "# Dot 연산으로 Bias 연산까지 같이 수행하기 위해 아래와 같이 코드를 작성하게 됩니다.\n",
    "\n",
    "# z1 = emb_user(input_user)\n",
    "# one_emb = tf.ones_like(user_emb[:, -1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "U=[u1,u2,u3,...,u60,1]I=[i1,i2,i3,...,i60,ibias]\n",
    "\n",
    "### Regularization 적용하기\n",
    "- Matrix Factoriation은 쉽게 Overfitting, 즉 학습 데이터에만 과적합되는 현상이 발생합니다. 이를 방지하기 위해 가장 기본적인 방법론 중 하나는 Weight Decay, 즉 weight의 값이 너무 커지지 않도록 방지하는 것입니다. 이를 위해 아래와 같이 Loss를 추가해주게 되면, weight가 어느정도 줄어드는 방향으로 모델이 학습하게 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-15T17:28:24.039464Z",
     "start_time": "2022-01-15T17:28:24.014663Z"
    }
   },
   "outputs": [],
   "source": [
    "# l2_user = z1**2\n",
    "# l2_pos_item = z2**2\n",
    "# l2_neg_item = z3**2\n",
    "# l2_reg = 0.0001\n",
    "\n",
    "# weight_decay = l2_reg*tf.reduce_sum(l2_user + l2_pos_item + l2_neg_item)\n",
    "\n",
    "# model.add_loss(weight_decay)\n",
    "\n",
    "model.compile(optimizer=Adagrad(1), loss=\"binary_crossentropy\", metrics=[\"acc\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습 데이터 구성하기\n",
    "- 우리가 가지고 있는 데이터는 고객이 특정 영화에 대해 몇점의 평점을 주었는지에 대한 데이터입니다. 우리는 고객이 평가하지 않은 영화에 대한 정보를 생성해서 Pair 단위로 모델을 학습해야 합니다.\n",
    "\n",
    "### 학습 데이터 구성하기\n",
    "우리는 매 Epoch마다 본것과 보지 않은 것에 대한 쌍을 무작위로 추출합니다. 그리고 학습 데이터에서 출력값은 항상 1로 나와야 합니다.(보지 않은 것에 대한 본것의 확률 = 100%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-15T17:28:25.422290Z",
     "start_time": "2022-01-15T17:28:25.314829Z"
    }
   },
   "outputs": [],
   "source": [
    "all_movies = set(ratings_tr[\"item_id\"])\n",
    "user_not_movies = all_movies - user_movies\n",
    "user_not_movies = user_not_movies.map(list)\n",
    "\n",
    "def get_bpr_dataset(ratings_tr, user_not_movies):\n",
    "    ratings_tr_batch = copy.deepcopy(ratings_tr)\n",
    "#     ratings_tr_batch = ratings_tr_batch.sample(frac=1)\n",
    "    ratings_tr_batch[\"neg_item\"] = ratings_tr_batch.apply(lambda x : random.choice(user_not_movies[x[\"user_id\"]]), axis=1)\n",
    "    \n",
    "#     x = {\"Input_user\":ratings_tr_batch[\"user_id\"].values, \"Input_pos\":ratings_tr_batch[\"item_id\"].values, \"Input_neg\":ratings_tr_batch[\"neg_item\"].values}\n",
    "    x = [ratings_tr_batch[\"user_id\"].values, ratings_tr_batch[\"item_id\"].values, ratings_tr_batch[\"neg_item\"].values]\n",
    "    y = np.ones(shape=(len(ratings_tr_batch), 1))\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 학습하기\n",
    "- epoch 10번에 걸쳐 모델을 학습시키도록 하겠습니다. 매 Epoch마다 새로운 학습 pair를 생성하도록 하였습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-15T17:28:25.940868Z",
     "start_time": "2022-01-15T17:28:25.925252Z"
    }
   },
   "outputs": [],
   "source": [
    "# ratings_tr_batch = ratings_tr.copy()\n",
    "# ratings_tr_batch = ratings_tr_batch.sample(frac=1)\n",
    "# ratings_tr_batch[\"neg_item\"] = ratings_tr_batch.apply(lambda x : random.choice(user_not_movies.loc[x[\"user_id\"]]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-15T17:28:57.921924Z",
     "start_time": "2022-01-15T17:28:33.353987Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:   1\n",
      "1386/1386 - 2s - loss: 0.6914 - acc: 0.5854 - 2s/epoch - 1ms/step\n",
      "epoch:   2\n",
      "1386/1386 - 1s - loss: 0.5640 - acc: 0.8013 - 1s/epoch - 898us/step\n",
      "epoch:   3\n",
      "1386/1386 - 1s - loss: 0.4198 - acc: 0.8178 - 1s/epoch - 916us/step\n",
      "epoch:   4\n",
      "1386/1386 - 1s - loss: 0.3671 - acc: 0.8447 - 1s/epoch - 914us/step\n",
      "epoch:   5\n",
      "1386/1386 - 1s - loss: 0.3198 - acc: 0.8682 - 1s/epoch - 891us/step\n",
      "epoch:   6\n",
      "1386/1386 - 1s - loss: 0.2810 - acc: 0.8846 - 1s/epoch - 936us/step\n",
      "epoch:   7\n",
      "1386/1386 - 1s - loss: 0.2573 - acc: 0.8948 - 1s/epoch - 916us/step\n",
      "epoch:   8\n",
      "1386/1386 - 1s - loss: 0.2380 - acc: 0.9032 - 1s/epoch - 976us/step\n",
      "epoch:   9\n",
      "1386/1386 - 1s - loss: 0.2170 - acc: 0.9117 - 1s/epoch - 997us/step\n",
      "epoch:  10\n",
      "1386/1386 - 1s - loss: 0.2079 - acc: 0.9159 - 1s/epoch - 958us/step\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 10\n",
    "for i in range(1, n_epochs + 1):\n",
    "    print(f\"epoch: {i:>3d}\")\n",
    "    X, y = get_bpr_dataset(ratings_tr, user_not_movies)\n",
    "    model.fit(x=X, y=y, batch_size=64, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=inputs, outputs=outputs)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
