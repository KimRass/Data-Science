{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Training\" data-toc-modified-id=\"Training-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Training</a></span></li><li><span><a href=\"#Inference\" data-toc-modified-id=\"Inference-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Inference</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-23T10:18:18.768054Z",
     "start_time": "2022-01-23T10:18:18.752269Z"
    }
   },
   "source": [
    "- ![seq2seq](https://wikidocs.net/images/page/24996/%EC%9D%B8%EC%BD%94%EB%8D%94%EB%94%94%EC%BD%94%EB%8D%94%EB%AA%A8%EB%8D%B8.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_data = raw_data.sample(60000, random_state=777)\n",
    "# raw_data = raw_data.reset_index(drop=True)\n",
    "# raw_data[\"src\"] = raw_data[\"src\"].str.lower()\n",
    "# raw_data[\"tar\"] = raw_data[\"tar\"].str.lower()\n",
    "\n",
    "# chars_src = set([char for sent in data[\"src\"] for char in sent])\n",
    "# chars_tar = set([char for sent in data[\"tar\"] for char in sent])\n",
    "\n",
    "# char2idx_src = {}\n",
    "# char2idx_src.update({char:idx+1 for idx, char in enumerate(chars_src)})\n",
    "# idx2char_src = {value:key for key, value in char2idx_src.items()}\n",
    "\n",
    "# char2idx_tar = {}\n",
    "# char2idx_tar[\"<SOS>\"] = 1\n",
    "# char2idx_tar[\"<EOS>\"] = 2\n",
    "# char2idx_tar.update({char:idx+3 for idx, char in enumerate(chars_tar)})\n",
    "# idx2char_tar = {value:key for key, value in char2idx_tar.items()}\n",
    "\n",
    "# print(char2idx_src)\n",
    "# print(char2idx_tar)\n",
    "\n",
    "# enc_input = data[\"src\"].apply(lambda x:[char2idx_src[char] for char in x]).tolist()\n",
    "# dec_input = data[\"tar\"].apply(lambda x:[1]+[char2idx_tar[char] for char in x]).tolist()\n",
    "# dec_gt = data[\"tar\"].apply(lambda x:[char2idx_tar[char] for char in x]+[2]).tolist()\n",
    "\n",
    "# name = \"./fra_eng_char-level_seq2seq\"\n",
    "# model_path = f\"{name}.h5\"\n",
    "# hist_path = f\"{name}_hist.npy\"\n",
    "# if os.path.exists(model_path):\n",
    "#     model = load_model(model_path)\n",
    "#     hist = np.load(hist_path, allow_pickle=\"TRUE\").item()\n",
    "# else:\n",
    "#     inputs_enc = Input(shape=(None, len(char2idx_src)+1), name=\"inputs_enc\")\n",
    "#     _, h_state, c_state = LSTM(units=256, return_state=True, name=\"lstm_enc\")(inputs_enc)\n",
    "\n",
    "#     inputs_dec = Input(shape=(None, len(char2idx_tar)+1), name=\"inputs_dec\")\n",
    "#     lstm_dec_layer = LSTM(units=256, return_sequences=True, return_state=True, name=\"lstm_dec\")\n",
    "#     lstm_dec, _, _ = lstm_dec_layer(inputs_dec, initial_state=[h_state, c_state])\n",
    "#     # 디코더의 첫 상태를 인코더의 Hidden state, 셀 상태로 합니다.\n",
    "#     dense_dec_layer = Dense(units=len(char2idx_tar)+1, activation=\"softmax\", name=\"dense_dec\")\n",
    "#     dense_dec = dense_dec_layer(lstm_dec)\n",
    "\n",
    "#     model = Model(inputs=[inputs_enc, inputs_dec], outputs=dense_dec)\n",
    "\n",
    "#     model.summary()\n",
    "    \n",
    "#     model.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\",\n",
    "#                   metrics=[\"categorical_accuracy\"])\n",
    "\n",
    "#     es = EarlyStopping(monitor=\"val_loss\", mode=\"auto\", verbose=1, patience=4)\n",
    "#     mc = ModelCheckpoint(filepath=model_path, monitor=\"val_categorical_accuracy\",\n",
    "#                          mode=\"auto\", verbose=1, save_best_only=True)\n",
    "    \n",
    "#     hist = model.fit(x=[enc_input, dec_input], y=dec_gt, batch_size=128, epochs=50, validation_split=0.2, callbacks=[es, mc])\n",
    "    \n",
    "#     np.save(hist_path, hitst.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-23T15:09:42.697561Z",
     "start_time": "2022-01-23T15:09:35.116776Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 22029,
     "status": "ok",
     "timestamp": 1609330819777,
     "user": {
      "displayName": "Jongbeom Kim",
      "photoUrl": "",
      "userId": "17252605958116038360"
     },
     "user_tz": -540
    },
    "id": "l34_bpbmfVPK",
    "outputId": "56154e30-4c71-476f-ad31-546e3d0da6de"
   },
   "outputs": [],
   "source": [
    "# from IPython.display import HTML, display\n",
    "# def set_css():\n",
    "#   display(HTML('''\n",
    "#   <style>\n",
    "#     pre {white-space: pre-wrap;}\n",
    "#   </style>\n",
    "#   '''))\n",
    "# get_ipython().events.register(\"pre_run_cell\", set_css)\n",
    "# from google.colab import drive\n",
    "# drive.mount(\"/content/drive\", force_remount=True)\n",
    "# import os\n",
    "# import sys\n",
    "# try:\n",
    "#     my_path = \"/content/notebooks\"\n",
    "#     os.symlink(\"/content/drive/MyDrive/ColabNotebooks/my_env\", my_path)\n",
    "#     sys.path.insert(0, my_path)\n",
    "# except:\n",
    "#     pass\n",
    "# os.chdir(my_path)\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Input, Model, Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator\n",
    "from tensorflow.keras.layers import Layer, Dense, Flatten, Dropout, Concatenate, Add, Dot, Multiply, Reshape, Activation, BatchNormalization, SimpleRNNCell, RNN, SimpleRNN, LSTM, Embedding, Bidirectional, TimeDistributed, Conv1D, Conv2D, MaxPool1D, MaxPool2D, GlobalMaxPool1D, GlobalMaxPool2D, AveragePooling1D, AveragePooling2D, GlobalAveragePooling1D, GlobalAveragePooling2D, ZeroPadding2D\n",
    "from tensorflow.keras.optimizers import SGD, Adam, Adagrad\n",
    "from tensorflow.keras.metrics import MeanSquaredError, RootMeanSquaredError, MeanAbsoluteError, MeanAbsolutePercentageError, BinaryCrossentropy, CategoricalCrossentropy, SparseCategoricalCrossentropy, CosineSimilarity\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Rescaling\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.activations import linear, sigmoid, relu\n",
    "from tensorflow.keras.initializers import RandomNormal, glorot_uniform, he_uniform, Constant\n",
    "from tensorflow.keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import urllib3\n",
    "import zipfile\n",
    "import shutil\n",
    "import json\n",
    "import os\n",
    "from nltk.translate.bleu_score import sentence_bleu, corpus_bleu, SmoothingFunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-23T15:11:25.726196Z",
     "start_time": "2022-01-23T15:11:25.360526Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "executionInfo": {
     "elapsed": 2574,
     "status": "ok",
     "timestamp": 1609327961361,
     "user": {
      "displayName": "Jongbeom Kim",
      "photoUrl": "",
      "userId": "17252605958116038360"
     },
     "user_tz": -540
    },
    "id": "w650GKn9YTN8",
    "outputId": "3d7f6ef5-600a-4fde-eb2d-420e3c697097"
   },
   "outputs": [],
   "source": [
    "raw_data = pd.read_table(\"./Datasets/fra-eng/fra.txt\", usecols=[0, 1], names=[\"tar\", \"src\"])\n",
    "\n",
    "raw_data = raw_data.sample(len(raw_data)//3, random_state=777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-23T15:11:28.306876Z",
     "start_time": "2022-01-23T15:11:25.726196Z"
    }
   },
   "outputs": [],
   "source": [
    "# `lower`: Whether to convert the texts to lowercase.\n",
    "# `char_level`: If `True`, every character will be treated as a token.\n",
    "tokenizer_src = Tokenizer(char_level=True)\n",
    "tokenizer_src.fit_on_texts(raw_data[\"src\"])\n",
    "char2idx_src = tokenizer_src.word_index\n",
    "vocab_size_src = len(char2idx_src)\n",
    "enc_input = tokenizer_src.texts_to_sequences(raw_data[\"src\"])\n",
    "\n",
    "tokenizer_tar = Tokenizer(char_level=True)\n",
    "tokenizer_tar.fit_on_texts(\"시\" + raw_data[\"tar\"] + \"종\")\n",
    "char2idx_tar = tokenizer_tar.word_index\n",
    "vocab_size_tar = len(char2idx_tar)\n",
    "dec_input = tokenizer_tar.texts_to_sequences(raw_data[\"tar\"] + \"종\")\n",
    "dec_gt = tokenizer_tar.texts_to_sequences(\"시\" + raw_data[\"tar\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-23T15:11:28.362881Z",
     "start_time": "2022-01-23T15:11:28.306876Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "executionInfo": {
     "elapsed": 751,
     "status": "ok",
     "timestamp": 1609328042825,
     "user": {
      "displayName": "Jongbeom Kim",
      "photoUrl": "",
      "userId": "17252605958116038360"
     },
     "user_tz": -540
    },
    "id": "spk0qLNOa0jE",
    "outputId": "b59e1a47-4a29-4e4a-c2ab-6d4d07e02ffb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "길이가 가장 긴 문장의 길이는 305이고 길이가 86 이하인 문장이 전체의 99%를 차지합니다.\n",
      "길이가 가장 긴 문장의 길이는 240이고 길이가 72 이하인 문장이 전체의 99%를 차지합니다.\n"
     ]
    }
   ],
   "source": [
    "ratio = 0.99\n",
    "\n",
    "lens_enc = sorted([len(doc) for doc in enc_input])\n",
    "max_len_enc = int(np.quantile(lens_enc, ratio))\n",
    "print(f\"길이가 가장 긴 문장의 길이는 {np.max(lens_enc)}이고 길이가 {max_len_enc} 이하인 문장이 전체의 {ratio:.0%}를 차지합니다.\")\n",
    "\n",
    "lens_dec = sorted([len(doc) for doc in dec_input])\n",
    "max_len_dec = int(np.quantile(lens_dec, ratio))\n",
    "print(f\"길이가 가장 긴 문장의 길이는 {np.max(lens_dec)}이고 길이가 {max_len_dec} 이하인 문장이 전체의 {ratio:.0%}를 차지합니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-23T15:11:29.729151Z",
     "start_time": "2022-01-23T15:11:28.365581Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "executionInfo": {
     "elapsed": 4784,
     "status": "ok",
     "timestamp": 1609328054802,
     "user": {
      "displayName": "Jongbeom Kim",
      "photoUrl": "",
      "userId": "17252605958116038360"
     },
     "user_tz": -540
    },
    "id": "mPi-I91BYTOB",
    "outputId": "8c596da2-8979-476b-9f83-58bbdb7e6d8a"
   },
   "outputs": [],
   "source": [
    "enc_input = pad_sequences(enc_input, padding=\"post\", maxlen=max_len_enc)\n",
    "dec_input = pad_sequences(dec_input, padding=\"post\", maxlen=max_len_dec)\n",
    "dec_gt = pad_sequences(dec_gt, padding=\"post\", maxlen=max_len_dec)\n",
    "\n",
    "enc_input = to_categorical(enc_input)\n",
    "dec_input = to_categorical(dec_input)\n",
    "dec_gt = to_categorical(dec_gt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-01-23T15:13:30.908Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " Input_enc (InputLayer)         [(None, 86, 76)]     0           []                               \n",
      "                                                                                                  \n",
      " Input_dec (InputLayer)         [(None, 72, 61)]     0           []                               \n",
      "                                                                                                  \n",
      " LSTM_enc (LSTM)                [(None, 128),        104960      ['Input_enc[0][0]']              \n",
      "                                 (None, 128),                                                     \n",
      "                                 (None, 128)]                                                     \n",
      "                                                                                                  \n",
      " LSTM_dec (LSTM)                [(None, 72, 128),    97280       ['Input_dec[0][0]',              \n",
      "                                 (None, 128),                     'LSTM_enc[0][1]',               \n",
      "                                 (None, 128)]                     'LSTM_enc[0][2]']               \n",
      "                                                                                                  \n",
      " Dense_dec (Dense)              (None, 72, 61)       7869        ['LSTM_dec[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 210,109\n",
      "Trainable params: 210,109\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/32\n",
      "21/21 [==============================] - ETA: 0s - loss: 2.7977 - acc: 0.5256\n",
      "Epoch 00001: val_acc improved from -inf to 0.58905, saving model to .\\fra_eng_char-level_seq2seq.h5\n",
      "21/21 [==============================] - 126s 6s/step - loss: 2.7977 - acc: 0.5256 - val_loss: 1.8842 - val_acc: 0.5890\n",
      "Epoch 2/32\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.6926 - acc: 0.6045\n",
      "Epoch 00002: val_acc improved from 0.58905 to 0.62511, saving model to .\\fra_eng_char-level_seq2seq.h5\n",
      "21/21 [==============================] - 117s 6s/step - loss: 1.6926 - acc: 0.6045 - val_loss: 1.5110 - val_acc: 0.6251\n",
      "Epoch 3/32\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.4350 - acc: 0.6276\n",
      "Epoch 00003: val_acc improved from 0.62511 to 0.64687, saving model to .\\fra_eng_char-level_seq2seq.h5\n",
      "21/21 [==============================] - 114s 5s/step - loss: 1.4350 - acc: 0.6276 - val_loss: 1.3967 - val_acc: 0.6469\n",
      "Epoch 4/32\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.3445 - acc: 0.6353\n",
      "Epoch 00004: val_acc did not improve from 0.64687\n",
      "21/21 [==============================] - 113s 5s/step - loss: 1.3445 - acc: 0.6353 - val_loss: 1.2991 - val_acc: 0.6419\n",
      "Epoch 5/32\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.2772 - acc: 0.6435\n",
      "Epoch 00005: val_acc did not improve from 0.64687\n",
      "21/21 [==============================] - 107s 5s/step - loss: 1.2772 - acc: 0.6435 - val_loss: 1.2524 - val_acc: 0.6469\n",
      "Epoch 6/32\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.2327 - acc: 0.6488\n",
      "Epoch 00006: val_acc improved from 0.64687 to 0.65321, saving model to .\\fra_eng_char-level_seq2seq.h5\n",
      "21/21 [==============================] - 108s 5s/step - loss: 1.2327 - acc: 0.6488 - val_loss: 1.2116 - val_acc: 0.6532\n",
      "Epoch 7/32\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.1930 - acc: 0.6537\n",
      "Epoch 00007: val_acc improved from 0.65321 to 0.65398, saving model to .\\fra_eng_char-level_seq2seq.h5\n",
      "21/21 [==============================] - 107s 5s/step - loss: 1.1930 - acc: 0.6537 - val_loss: 1.1711 - val_acc: 0.6540\n",
      "Epoch 8/32\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.1505 - acc: 0.6571\n",
      "Epoch 00008: val_acc improved from 0.65398 to 0.66135, saving model to .\\fra_eng_char-level_seq2seq.h5\n",
      "21/21 [==============================] - 107s 5s/step - loss: 1.1505 - acc: 0.6571 - val_loss: 1.1259 - val_acc: 0.6613\n",
      "Epoch 9/32\n",
      " 3/21 [===>..........................] - ETA: 1:25 - loss: 1.1259 - acc: 0.6601"
     ]
    }
   ],
   "source": [
    "name = \"./fra_eng_char-level_seq2seq\"\n",
    "model_path = f\"{name}.h5\"\n",
    "hist_path = f\"{name}_hist.npy\"\n",
    "if os.path.exists(model_path):\n",
    "    model = load_model(model_path)\n",
    "    hist = np.load(hist_path, allow_pickle=\"TRUE\").item()\n",
    "else:\n",
    "    inputs_enc = Input(shape=(max_len_enc, vocab_size_src + 1), name=\"Input_enc\")\n",
    "    inputs_dec = Input(shape=(max_len_dec, vocab_size_tar + 1), name=\"Input_dec\")\n",
    "    \n",
    "    _, h_state, c_state = LSTM(units=128, return_state=True, name=\"LSTM_enc\")(inputs_enc)\n",
    "    z, _, _ = LSTM(units=128, return_sequences=True, return_state=True, name=\"LSTM_dec\")(inputs_dec, initial_state=[h_state, c_state])\n",
    "    outputs = Dense(units=vocab_size_tar + 1, activation=\"softmax\", name=\"Dense_dec\")(z)\n",
    "\n",
    "    model = Model(inputs=[inputs_enc, inputs_dec], outputs=outputs)\n",
    "    \n",
    "    model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"acc\"])\n",
    "    model.summary()\n",
    "\n",
    "    es = EarlyStopping(monitor=\"val_loss\", mode=\"auto\", verbose=1, patience=1)\n",
    "    mc = ModelCheckpoint(filepath=model_path, monitor=\"val_acc\", mode=\"auto\", verbose=1, save_best_only=True)\n",
    "    hist = model.fit(x=[enc_input, dec_input], y=dec_gt, batch_size=2048, epochs=32, validation_split=0.3, callbacks=[es, mc])\n",
    "    \n",
    "    np.save(hist_path, hitst.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 216
    },
    "executionInfo": {
     "elapsed": 1399,
     "status": "ok",
     "timestamp": 1609330224589,
     "user": {
      "displayName": "Jongbeom Kim",
      "photoUrl": "",
      "userId": "17252605958116038360"
     },
     "user_tz": -540
    },
    "id": "uQqqHIhRYTOD",
    "outputId": "8f14345f-e65b-40f0-e71a-456d13660337",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {white-space: pre-wrap;}\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 7 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f97525d46a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "je suis contre ce projet de loi.<EOS>\n",
      "œ1ll1zp1lp/j90999 9,  + ,,, 9,3ê9\n"
     ]
    }
   ],
   "source": [
    "# 학습이 맞게 됐는지 확인\n",
    "i = 110\n",
    "pred = model.predict([tf.expand_dims(enc_input[i], axis=0), tf.expand_dims(dec_input[i], axis=0)])\n",
    "\n",
    "sent = \"\"\n",
    "for idx in tf.argmax(dec_gt[i], axis=1).numpy():\n",
    "    if idx != 0:\n",
    "        sent += idx2char_tar[idx]\n",
    "print(sent)\n",
    "\n",
    "sent = \"\"\n",
    "for idx in tf.argmax(pred[0], axis=1).numpy():\n",
    "    if idx != 0:\n",
    "        sent += idx2char_tar[idx]\n",
    "print(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YQDLJkvCYTOE"
   },
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rD5vl9rcYTOF"
   },
   "source": [
    "- 우선 인코더를 정의합니다. enc_inputs와 encoder_states는 훈련 과정에서 이미 정의한 것들을 재사용하는 것입니다. 이제 디코더를 설계해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 107
    },
    "executionInfo": {
     "elapsed": 997,
     "status": "ok",
     "timestamp": 1609330243042,
     "user": {
      "displayName": "Jongbeom Kim",
      "photoUrl": "",
      "userId": "17252605958116038360"
     },
     "user_tz": -540
    },
    "id": "54KFid58fJoC",
    "outputId": "3a4c805b-effe-4f00-a98b-94e1a91603f1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {white-space: pre-wrap;}\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.engine.input_layer.InputLayer at 0x7f97529d7438>,\n",
       " <tensorflow.python.keras.engine.input_layer.InputLayer at 0x7f9752d01f60>,\n",
       " <tensorflow.python.keras.layers.recurrent_v2.LSTM at 0x7f97529d7908>,\n",
       " <tensorflow.python.keras.layers.recurrent_v2.LSTM at 0x7f9753533278>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x7f9753533cc0>]"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "executionInfo": {
     "elapsed": 855,
     "status": "ok",
     "timestamp": 1609330243361,
     "user": {
      "displayName": "Jongbeom Kim",
      "photoUrl": "",
      "userId": "17252605958116038360"
     },
     "user_tz": -540
    },
    "id": "NGBHG4gTYTOF",
    "outputId": "e729e08f-5fd7-4d20-8568-4c2de1753ae1",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {white-space: pre-wrap;}\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "inputs_enc = model.layers[0].output\n",
    "_, h_state, c_state = model.layers[2].output\n",
    "\n",
    "enc_model = tf.keras.Model(inputs=inputs_enc, outputs=[h_state, c_state])\n",
    "\n",
    "inputs_dec = model.layers[1].output\n",
    "h_state_bef = Input(shape=(256,))\n",
    "c_state_bef = Input(shape=(256,))\n",
    "# 문장의 다음 단어를 예측하기 위해서 initial_state를 이전 시점의 상태로 사용합니다.\n",
    "lstm_dec_layer = model.layers[3]\n",
    "lstm_dec, h_state_aft, c_state_aft = lstm_dec_layer(inputs_dec, initial_state=[h_state_bef, c_state_bef])\n",
    "dense_dec_layer = model.layers[4]\n",
    "dense_dec = dense_dec_layer(lstm_dec)\n",
    "\n",
    "dec_model = tf.keras.Model(inputs=[inputs_dec]+[h_state_bef, c_state_bef], outputs=[dense_dec]+[h_state_aft, c_state_aft])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "executionInfo": {
     "elapsed": 776,
     "status": "ok",
     "timestamp": 1609331354782,
     "user": {
      "displayName": "Jongbeom Kim",
      "photoUrl": "",
      "userId": "17252605958116038360"
     },
     "user_tz": -540
    },
    "id": "MqbVBmExYTOG",
    "outputId": "9be7b630-3b2b-429e-a87a-7af26720a027"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {white-space: pre-wrap;}\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {white-space: pre-wrap;}\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def decode_seq(input_seq):\n",
    "# seq = enc_input[i:i+1]\n",
    "    enc_states = enc_model.predict(input_seq)\n",
    "\n",
    "    # <SOS>에 해당하는 OHE를 생성합니다.\n",
    "    seq = np.zeros((1, 1, len(char2idx_tar)+1))\n",
    "    seq[0, 0, char2idx_tar[\"<SOS>\"]] = 1\n",
    "\n",
    "    stop_cond = False\n",
    "    decoded_sent = \"\"\n",
    "    # stop_cond이 True가 될 때까지 반복합니다.\n",
    "    while not stop_cond:\n",
    "        # 이점 시점의 states를 현재 시점의 states로 사용합니다.\n",
    "        output_tokens, h_state, c_state = dec_model.predict([seq] + enc_states)\n",
    "        argmax = np.argmax(output_tokens[0, -1, :])\n",
    "    #     argmax = np.argmax(output_tokens[0, 0])\n",
    "        char = idx2char_tar[argmax]\n",
    "        decoded_sent += char\n",
    "        # 현재 시점의 예측 결과를 다음 시점의 입력으로 사용하기 위해 저장합니다.\n",
    "        seq = np.zeros((1, 1, len(char2idx_tar)+1))\n",
    "        seq[0, 0, argmax] = 1\n",
    "        enc_states = [h_state, c_state]\n",
    "        \n",
    "        # \"<EOS>\"에 도달하거나 최대 길이를 넘으면 stop_cond=True를 저장합니다.\n",
    "        if char == \"<EOS>\" or len(decoded_sent) == max_len_dec:\n",
    "            stop_cond = True\n",
    "    return decoded_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 741
    },
    "executionInfo": {
     "elapsed": 8532,
     "status": "ok",
     "timestamp": 1609331437952,
     "user": {
      "displayName": "Jongbeom Kim",
      "photoUrl": "",
      "userId": "17252605958116038360"
     },
     "user_tz": -540
    },
    "id": "ZbbUbHkjzpuk",
    "outputId": "d73b7b61-0b3a-46af-a650-beb4337ad829"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {white-space: pre-wrap;}\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {white-space: pre-wrap;}\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "입력 문장 : why do you need change?\n",
      "정답 문장 : ourquoi as-tu besoin de changement \n",
      "번역 문장 : jz3lw(++1yj1…w+l1+jl…zp3+lœ1ljz… <EOS\n",
      "BLEU-1 : 0\n",
      "BLEU-2 : 0\n",
      "BLEU-3 : 0\n",
      "BLEU-4 : 0\n",
      "-----------------------------------\n",
      "입력 문장 : why did you change your mind?\n",
      "정답 문장 : ourquoi as-tu changé d'avis \n",
      "번역 문장 : j(l+z0êp+lœ;(s1êjl3;(lw(+l8j8ljê(s(p//8 <EOS\n",
      "BLEU-1 : 0\n",
      "BLEU-2 : 0\n",
      "BLEU-3 : 0\n",
      "BLEU-4 : 0\n",
      "-----------------------------------\n",
      "입력 문장 : we don't want to lose you.\n",
      "정답 문장 : ous ne voulons pas vous perdre\n",
      "번역 문장 : sz0+l(s1)ljz0jlœ1l+0pj1lùl/(l…(p+z3 <EOS\n",
      "BLEU-1 : 0\n",
      "BLEU-2 : 0\n",
      "BLEU-3 : 0\n",
      "BLEU-4 : 0\n",
      "-----------------------------------\n",
      "입력 문장 : see that this never happens again.\n",
      "정답 문장 : aites en sorte que ça ne se produise plus\n",
      "번역 문장 : èj1+ysz0+lwêèj1lùlc(pê1lh(l&<EOS\n",
      "BLEU-1 : 0\n",
      "BLEU-2 : 0\n",
      "BLEU-3 : 0\n",
      "BLEU-4 : 0\n",
      "-----------------------------------\n",
      "입력 문장 : you must not lose sight of your main object.\n",
      "정답 문장 : l ne faut pas que tu perdes de vue ton objectif principal\n",
      "번역 문장 : /1+lwêp4l+z3jl+0êl/1lwzp3jlœ1lw(ê/1êlœ1l/(l3z0êêpj0ê1l1jlœ1l/;(êç13j <EOS\n",
      "BLEU-1 : 0\n",
      "BLEU-2 : 0\n",
      "BLEU-3 : 0\n",
      "BLEU-4 : 0\n"
     ]
    }
   ],
   "source": [
    "actual, pred = list(), list()\n",
    "for seq_index in range(231, 236):\n",
    "    input_seq = enc_input[seq_index:seq_index+1]\n",
    "    decoded_sent = decode_seq(input_seq)\n",
    "    \n",
    "    actual.append([data[\"tar\"][seq_index][1:len(data[\"tar\"][seq_index])-1].split()])\n",
    "    pred.append(decoded_sent[:len(decoded_sent)-1].split())\n",
    "                  \n",
    "    print(35 * \"-\")\n",
    "    print(f\"입력 문장 : {data['src'][seq_index]}\")\n",
    "    print(f\"정답 문장 : {data['tar'][seq_index][1:len(data['tar'][seq_index])-1]}\")\n",
    "    print(f\"번역 문장 : {decoded_sent[:len(decoded_sent)-1]}\")\n",
    "    sf = SmoothingFunction()\n",
    "    print(f\"BLEU-1 : {corpus_bleu(actual, pred, weights=(1, 0, 0, 0),\\\n",
    "                                  smoothing_function=sf.method1)}\")\n",
    "    print(f\"BLEU-2 : {corpus_bleu(actual, pred, weights=(1/2, 1/2, 0, 0),\\\n",
    "                                  smoothing_function=sf.method1)}\")\n",
    "    print(f\"BLEU-3 : {corpus_bleu(actual, pred, weights=(1/3, 1/3, 1/3, 0),\\\n",
    "                                  smoothing_function=sf.method1)}\")\n",
    "    print(f\"BLEU-4 : {corpus_bleu(actual, pred, weights=(1/4, 1/4, 1/4, 1/4),\\\n",
    "                                  smoothing_function=sf.method1)}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Neural Machine Translation(Character-Level seq2seq / fra-eng Dataset)",
   "provenance": []
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "191.594px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
