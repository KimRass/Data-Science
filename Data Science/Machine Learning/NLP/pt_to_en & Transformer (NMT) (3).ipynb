{"cells":[{"cell_type":"markdown","metadata":{"id":"ktJMirEOT8iR","toc":true},"source":["<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n","<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#데이터-로드\" data-toc-modified-id=\"데이터-로드-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>데이터 로드</a></span></li><li><span><a href=\"#옵티마이저-설정하기\" data-toc-modified-id=\"옵티마이저-설정하기-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>옵티마이저 설정하기</a></span></li><li><span><a href=\"#Loss-함수-설정하기\" data-toc-modified-id=\"Loss-함수-설정하기-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Loss 함수 설정하기</a></span></li><li><span><a href=\"#모델-훈련\" data-toc-modified-id=\"모델-훈련-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>모델 훈련</a></span></li><li><span><a href=\"#Inference\" data-toc-modified-id=\"Inference-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Inference</a></span></li></ul></div>"]},{"cell_type":"markdown","metadata":{"id":"WRvYAI5bn4dF"},"source":["# 데이터 로드\n","데이터 로드는 tensorflow 2에서 제공하는 tf.data.dataset 형식으로 로드하도록 하겠습니다. dataset 형식으로 데이터를 불러오면, 향후 모델을 훈련시킬 때 @tf.function 데코레이터를 활용하여 상당히 빠르게 학습할 수 있습니다."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eBs0IY0ma8-g"},"outputs":[],"source":["# d_model = 512\n","# x = np.float32(np.random.uniform(size=(1, 40))) # 문장 길이 40\n","# embedded = TransformerEmbedding(100 + 2, 10000)(x, False)\n","# print(embedded) # 문장이 위치 임베딩 + 포지션 임베딩\n","\n","# q = tf.cast(np.random.uniform(size=(1, 2, d_model)), dtype=tf.float32)\n","# k = tf.cast(np.random.uniform(size=(1, 7, d_model)), dtype=tf.float32)\n","# v = tf.cast(np.random.uniform(size=(1, 7, d_model)), dtype=tf.float32)\n","# encoder_output, _ = MultiheadAttention()(v, k, q, mask=None)\n","# print(encoder_output.shape)\n","# q = split_heads(q)\n","# k = split_heads(k)\n","# v = split_heads(v)\n","\n","# print(scaled_dot_product_attention(q, k, v, None)[0].shape)\n","# print(scaled_dot_product_attention(q, k, v, None)[1].shape)\n","\n","# # 임베딩\n","# x = np.float32(np.random.uniform(size=(1, 40))) # 문장 길이 40\n","# Embedder = TransformerEmbedding(1000 + 2, 10000)\n","# embedded = Embedder(x, False)\n","# print(embedded) # 문장이 위치 임베딩 + 포지션 임베딩\n","# #인코더\n","# sample_encoder = EncoderLayer(rate=0.1)\n","# sample_encoding = sample_encoder(embedded, training=None, mask=None)\n","# print(sample_encoding)\n","# #최종출력\n","# print(\"Encoded 차원 :\", sample_encoding.shape)\n","\n","# Encoder_layer = Encoder(6)\n","# embedded : 위치 임베딩 + 단어 임베딩\n","# Encoded = Encoder(6)(embedded, training=False, mask=None)\n","# print(Encoded, Encoded.shape)\n","\n","# # 위치 임베딩 + 포지셔널 임베딩\n","# embedded\n","# #인코더 아웃풋 \n","# Encoded\n","\n","# # 디코더의 위치+포지셔널 임베딩(Teaching Force 과정이라 디코더 부분에 타겟(영어)도 넣어줌)\n","# tarbedder = TransformerEmbedding(vocab_size_src=1000, seq_len=512)\n","# tar_embedding = tar_embedder(tf.cast(np.random.uniform(size=(1,40)), dtype=tf.float32), True)\n","\n","# # 6층 디코더\n","# Decoder_layer = Decoder()\n","\n","# Decoded, _ = Decoder_layer(tar_embedding, Encoded, False, None, None) # Decoded에서 인코더와 디코더의 정보 결합\n","# print(Decoded, Decoded.shape)\n","# #최종출력\n","# print(\"6층 Decoder 출력 :\", sample_encoding.shape)\n","\n","# temp_mask = 1 - tf.linalg.band_part(tf.ones((10, 10)), -1, 0)\n","# print(temp_mask)\n","\n","# # 예제 문장 (1, 40) 즉, 1문장, 40개의 단어를 가짐\n","# example_sentence = np.hstack([np.random.randint(20, size=6), np.zeros(4)])[np.newaxis, :]\n","# print(example_sentence) # 예제 문장\n","# example_sentence = tf.cast(tf.math.equal(example_sentence, 0), dtype=tf.float32)\n","# print(example_sentence) # 패딩 된 것(문장에서 0이 아닌 부분은 0으로, 0인 부분은 1로)\n","# example_sentence = example_sentence[:, tf.newaxis, tf.newaxis, :] # 차원 변경\n","# print(example_sentence)\n","\n","# look_ahead_mask = tf.maximum(temp_mask, example_sentence) # 상삼각행렬과 example sentence를 비교해가며 최대값만 취해서 패딩을 1로 처리함\n","# # look ahead mask\n","# print(look_ahead_mask)\n","\n","# example_sentence = np.hstack([np.random.randint(20, size=10), np.zeros(30)])[np.newaxis, :]\n","# # 패딩 되기 전\n","# print(example_sentence)\n","# # 패딩 된 후\n","# print(padding_mask(example_sentence))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0aGrR8n1J9lt"},"outputs":[],"source":["# class TransformerEmbedding(Layer):\n","#     def __init__(self):\n","#         super().__init__()\n","    \n","#     # `x`: (batch_size, seq_len)\n","#     def call(self, x, training):\n","#         seq_len = tf.shape(x)[1]\n","#         # (batch_size, seq_len, d_model)\n","#         z = Embedding(input_dim=vocab_size_src, output_dim=d_model)(x)\n","#         # 포지셔널 인코딩은 순서만을 의미하기 때문에 그 영향을 줄이도록 합니다.\n","#         pe_mat = positional_encoding_matrix(max_pe_dim)\n","        \n","#         z = (d_model**0.5)*z + pe_mat[:, :seq_len, :]\n","#         z = Dropout(rate=0.1)(z, training=training)\n","#         # (batch_size, seq_len, d_model)\n","#         return z\n","\n","# class Encoder(Layer):\n","#     def __init__(self):\n","#         super().__init__()\n","\n","#     def call(self, x, training, mask):\n","#         for _ in range(n_layers):\n","#             x = EncoderLayer()(x, training, mask)\n","#         return x\n","\n","# class EncoderLayer(Layer):\n","#     def __init__(self):\n","#         super().__init__()\n","\n","#     # `x`: (batch_size, seq_len_enc, d_model)\n","#     def call(self, x, training, mask=None):\n","#         # ENCODER #1\n","#         z, _ = MultiheadAttention()(x, x, x, mask) \n","#         z = Dropout(rate=0.1)(z, training=training)\n","#         ## \"Add & Normalize\" Part\n","#         z1 = LayerNormalization(epsilon=1e-6)(x + z)\n","\n","#         # ENCODER #2\n","#         z2 = PositionwiseFFNN()(z1)\n","#         z2 = Dropout(rate=0.1)(z2, training=training)\n","#         ## \"Add & Normalize\" Part\n","#         z3 = LayerNormalization(epsilon=1e-6)(z1 + z2)\n","#         # (batch_size, seq_len_enc, d_model)\n","#         return z3\n","\n","# class DecoderLayer(Layer):\n","#     def __init__(self):\n","#         super().__init__()\n","\n","#     def call(self, x, enc_output, training, padding_mask, look_ahead_mask):\n","#         ## \"Self-Attention\" Part\n","#         z1, attn_weights1 = MultiheadAttention()(x, x, x, mask=look_ahead_mask)\n","#         z1 = Dropout(rate=0.1)(z1, training=training)\n","#         ## \"Add & Normalize\" Part\n","#         z1 = LayerNormalization(epsilon=1e-6)(z1 + x)\n","\n","#         ## \"Encoder-Decoder Attention\" Part\n","#         z2, attn_weights2 = MultiheadAttention()(enc_output, enc_output, z1, mask=padding_mask)\n","#         z2 = Dropout(rate=0.1)(z2, training=training)\n","#         ## \"Add & Normalize\" Part\n","#         z2 = LayerNormalization(epsilon=1e-6)(z2 + z1)\n","\n","#         z3 = PositionwiseFFNN()(z2)\n","#         z3 = Dropout(rate=0.1)(z3, training=training)\n","#         ## \"Add & Normalize\" Part\n","#         # (batch_size, seq_len_dec, d_model)\n","#         z3 = LayerNormalization(epsilon=1e-6)(z3 + z2)\n","\n","#         return z3, attn_weights1, attn_weights2\n","\n","# class MultiheadAttention(Layer):\n","#     def __init__(self):\n","#         super().__init__()\n","\n","#     def call(self, values, keys, queries, mask):\n","#         batch_size = tf.shape(queries)[0]\n","        \n","#         def split_heads(x):\n","#             x = tf.reshape(x, shape=(batch_size, -1, n_heads, dk))\n","#             return tf.transpose(x, perm=[0, 2, 1, 3])\n","        \n","#         queries = Dense(units=d_model)(queries)\n","#         keys = Dense(units=d_model)(keys)\n","#         values = Dense(units=d_model)(values)\n","\n","#         # (batch_size, n_heads, seq_len_dec, dk)\n","#         queries = split_heads(queries)\n","#         # (batch_size, n_heads, seq_len_enc, dk)\n","#         keys = split_heads(keys)\n","#         # (batch_size, n_heads, seq_len_enc, dk)\n","#         values = split_heads(values)\n","\n","#         # (batch_size, n_heads, seq_len_dec, dk)\n","#         context_vec, attn_weights = scaled_dot_product_attention(queries, keys, values, mask)\n","#         # (batch_size, seq_len_dec, n_heads, dk)\n","#         z = tf.transpose(context_vec, perm=[0, 2, 1, 3])\n","#         # (batch_size, seq_len_dec, d_model)\n","#         z = tf.reshape(z, shape=(batch_size, -1, d_model))\n","#         z = Dense(units=d_model)(z)\n","#         return z, attn_weights\n","\n","# class PositionwiseFFNN(Layer):\n","#     def __init__(self):\n","#         super().__init__()\n","\n","#     def call(self, x):\n","#         # (batch_size, seq_len, dff)\n","#         z = Dense(units=dff, activation=\"relu\")(x)\n","#         # (batch_size, seq_len, d_model)\n","#         z = Dense(d_model)(z)\n","#         return z\n","\n","# class Decoder(Layer):\n","#     def __init__(self, rate=0.1):\n","#         super().__init__()\n","\n","#     def call(self, x, enc_output, training, padding_mask, look_ahead_mask):\n","#         dic = dict()\n","#         for i in range(n_layers):\n","#             x, attn_weights1, attn_weights2 = decoder_layer(x, enc_output, training=training, padding_mask=padding_mask, look_ahead_mask=look_ahead_mask)\n","#             dic[f\"decoder_layer{i + 1}_block1\"] = attn_weights1\n","#             dic[f\"decoder_layer{i + 1}_block2\"] = attn_weights2\n","#         return x, dic"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2022-02-08T02:58:09.160061Z","start_time":"2022-02-08T02:56:40.176626Z"},"id":"C42H5OZMmJL1","outputId":"02d436b5-1504-4731-9add-6e66f2cfbb14"},"outputs":[{"name":"stdout","output_type":"stream","text":["^C\n"]}],"source":["!pip install -q tf-nightly"]},{"cell_type":"code","execution_count":45,"metadata":{"ExecuteTime":{"end_time":"2022-02-08T15:12:09.701179Z","start_time":"2022-02-08T15:12:05.747991Z"},"id":"JS458ZL3T8iZ","executionInfo":{"status":"ok","timestamp":1644395028246,"user_tz":-540,"elapsed":379,"user":{"displayName":"Jongbeom Kim","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17252605958116038360"}}},"outputs":[],"source":["import tensorflow_datasets as tfds\n","import os\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sb\n","import tensorflow as tf\n","from tensorflow.keras import Input, Model, Sequential\n","from tensorflow.keras.models import load_model\n","from tensorflow.keras.layers import Layer, Dense, Flatten, Dropout, Concatenate, Add, Dot, Multiply, Reshape, Activation, BatchNormalization, LayerNormalization, SimpleRNNCell, RNN, SimpleRNN, LSTM, Embedding, Bidirectional, TimeDistributed, Conv1D, Conv2D, MaxPool1D, MaxPool2D, GlobalMaxPool1D, GlobalMaxPool2D, AveragePooling1D, AveragePooling2D, GlobalAveragePooling1D, GlobalAveragePooling2D, ZeroPadding2D, RepeatVector\n","from tensorflow.keras.layers.experimental.preprocessing import Rescaling\n","from tensorflow.keras.utils import to_categorical, plot_model\n","from tensorflow.keras.preprocessing import image_dataset_from_directory\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator\n","from tensorflow.keras.optimizers import SGD, Adagrad, Adam\n","from tensorflow.keras.losses import MeanSquaredError, MeanAbsoluteError, MeanAbsolutePercentageError, BinaryCrossentropy, CategoricalCrossentropy, SparseCategoricalCrossentropy, CosineSimilarity\n","from tensorflow.keras.metrics import MeanSquaredError, RootMeanSquaredError, MeanAbsoluteError, MeanAbsolutePercentageError, BinaryCrossentropy, CategoricalCrossentropy, SparseCategoricalCrossentropy, CosineSimilarity\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n","from tensorflow.keras.activations import linear, sigmoid, relu\n","from tensorflow.keras.initializers import RandomNormal, glorot_uniform, he_uniform, Constant\n","\n","plt.style.use(\"dark_background\")"]},{"cell_type":"code","source":["n_layers = 4\n","d_model = 128\n","dff = 512\n","n_heads = 8\n","# SEQ_LEN = 40\n","dk = d_model//n_heads\n","\n","max_pe_dim = 512\n","vocab_size_src = 1024\n","vocab_size_tar = 2048\n","# batch_size = 256\n","\n","def positional_encoding_matrix(seq_len):\n","    a, b = np.meshgrid(np.arange(d_model), np.arange(seq_len))\n","    pe_mat = b/10000**(2*(a//2)/d_model)\n","    pe_mat[:, 0::2] = np.sin(pe_mat[:, 0::2])\n","    pe_mat[:, 1::2] = np.cos(pe_mat[:, 1::2])\n","    pe_mat = pe_mat[None, :]\n","    return pe_mat\n","\n","def padding_mask(seq):\n","    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n","    # (batch_size, 1, 1, seq_len)\n","    return seq[:, None, None, :]\n","\n","def look_ahead_mask(tar):\n","    size = tf.shape(tar)[1]\n","    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n","    p_mask = padding_mask(tar)\n","    return tf.maximum(p_mask, mask)\n","\n","# 패딩 마스킹을 써야하는 경우에는 스케일드 닷 프로덕트 어텐션 함수에 패딩 마스크를 전달하고\n","# 룩-어헤드 마스킹을 써야하는 경우에는 스케일드 닷 프로덕트 어텐션 함수에 룩-어헤드 마스크를 전달합니다.\n","def scaled_dot_product_attention(queries, keys, values, mask=None):\n","    attn_scores = tf.matmul(queries, keys, transpose_b=True)/dk**0.5\n","    if mask is not None:\n","        attn_scores = attn_scores + (mask*-1e9)\n","    # (batch_size, seq_len_dec, seq_len_enc)\n","    attn_weights = tf.nn.softmax(attn_scores, axis=-1)\n","    # (batch_size, seq_len_dec, dk) (Same shape as queries)\n","    context_vec = tf.matmul(attn_weights, values)\n","    return context_vec, attn_weights\n","\n","def multihead_attention(values, keys, queries, mask):\n","    batch_size = tf.shape(queries)[0]\n","\n","    def split_heads(x):\n","        x = tf.reshape(x, shape=(batch_size, -1, n_heads, dk))\n","        return tf.transpose(x, perm=[0, 2, 1, 3])\n","    \n","    queries = Dense(units=d_model)(queries)\n","    keys = Dense(units=d_model)(keys)\n","    values = Dense(units=d_model)(values)\n","\n","    # (batch_size, n_heads, seq_len_dec, dk)\n","    queries = split_heads(queries)\n","    # (batch_size, n_heads, seq_len_enc, dk)\n","    keys = split_heads(keys)\n","    # (batch_size, n_heads, seq_len_enc, dk)\n","    values = split_heads(values)\n","\n","    # (batch_size, n_heads, seq_len_dec, dk)\n","    context_vec, attn_weights = scaled_dot_product_attention(queries, keys, values, mask)\n","    # (batch_size, seq_len_dec, n_heads, dk)\n","    z = tf.transpose(context_vec, perm=[0, 2, 1, 3])\n","    # (batch_size, seq_len_dec, d_model)\n","    z = tf.reshape(z, shape=(batch_size, -1, d_model))\n","    z = Dense(units=d_model)(z)\n","    return z, attn_weights\n","\n","def positionwise_ffnn(x):\n","    # (batch_size, seq_len, dff)\n","    z = Dense(units=dff, activation=\"relu\")(x)\n","    # (batch_size, seq_len, d_model)\n","    z = Dense(d_model)(z)\n","    return z\n","\n","def t_embedding(x, training):\n","    seq_len = tf.shape(x)[1]\n","    # (batch_size, seq_len, d_model)\n","    z = Embedding(input_dim=vocab_size_src, output_dim=d_model)(x)\n","    # 포지셔널 인코딩은 순서만을 의미하기 때문에 그 영향을 줄이도록 합니다.\n","    pe_mat = positional_encoding_matrix(max_pe_dim)\n","\n","    z = (d_model**0.5)*z + pe_mat[:, :seq_len, :]\n","    z = Dropout(rate=0.1)(z, training=training)\n","    # (batch_size, seq_len, d_model)\n","    return z\n","\n","def encoder_layer(x, training, mask):\n","    # ENCODER #1\n","    z, _ = multihead_attention(x, x, x, mask) \n","    z = Dropout(rate=0.1)(z, training=training)\n","    ## \"Add & Normalize\" Part\n","    z1 = LayerNormalization(epsilon=1e-6)(x + z)\n","\n","    # ENCODER #2\n","    z2 = positionwise_ffnn(z1)\n","    z2 = Dropout(rate=0.1)(z2, training=training)\n","    ## \"Add & Normalize\" Part\n","    z3 = LayerNormalization(epsilon=1e-6)(z1 + z2)\n","    # (batch_size, seq_len_enc, d_model)\n","    return z3\n","\n","# DECODER #1\n","def decoder_layer(x, enc_output, training, padding_mask, look_ahead_mask):\n","    ## \"Self-Attention\" Part\n","    z1, attn_weights1 = multihead_attention(x, x, x, mask=look_ahead_mask)\n","    z1 = Dropout(rate=0.1)(z1, training=training)\n","    ## \"Add & Normalize\" Part\n","    z1 = LayerNormalization(epsilon=1e-6)(z1 + x)\n","\n","    ## \"Encoder-Decoder Attention\" Part\n","    z2, attn_weights2 = multihead_attention(enc_output, enc_output, z1, mask=padding_mask)\n","    z2 = Dropout(rate=0.1)(z2, training=training)\n","    ## \"Add & Normalize\" Part\n","    z2 = LayerNormalization(epsilon=1e-6)(z2 + z1)\n","\n","    z3 = positionwise_ffnn(z2)\n","    z3 = Dropout(rate=0.1)(z3, training=training)\n","    ## \"Add & Normalize\" Part\n","    # (batch_size, seq_len_dec, d_model)\n","    z3 = LayerNormalization(epsilon=1e-6)(z3 + z2)\n","\n","    return z3, attn_weights1, attn_weights2\n","\n","# pe_input : 별로 중요한 것은 아니지만, 위치 임베딩 할 때 위치 임베딩의 길이의 상한을 뜻함(포르투갈어)\n","# pe_tar : 위치 임베딩의 상한(영어)\n","class Transformer(Model):\n","    def __init__(self):\n","        super().__init__()\n","\n","    def call(self, src, tar, training):\n","        enc_mask = padding_mask(src)\n","        dec_mask = padding_mask(src)\n","        l_mask = look_ahead_mask(tar)\n","\n","        src_embedding = t_embedding(src, training=True)\n","        z = src_embedding\n","        for _ in range(n_layers):\n","            z = encoder_layer(z, training=training, mask=enc_mask)\n","        enc_output = z\n","\n","        tar_embedding = t_embedding(tar, training=True)\n","\n","        dic = dict()\n","        for i in range(n_layers):\n","            tar_embedding, attn_weights1, attn_weights2 = decoder_layer(tar_embedding, enc_output, training=training, padding_mask=dec_mask, look_ahead_mask=l_mask)\n","            dic[f\"decoder_layer{i + 1}_block1\"] = attn_weights1\n","            dic[f\"decoder_layer{i + 1}_block2\"] = attn_weights2\n","        dec_output = tar_embedding\n","\n","        final_output = Dense(units=vocab_size_tar)(dec_output)\n","        return final_output\n","# 트랜스포머 테스트하기\n","sample_transformer = Transformer()\n","src = tf.cast(np.random.randint(100,size=40)[np.newaxis, :], dtype=tf.int32)\n","tar = tf.cast(np.random.randint(100,size=40)[np.newaxis, :], dtype=tf.int32)\n","transformer = sample_transformer(src, tar, False)\n","print(transformer)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WiCHag85KHvs","executionInfo":{"status":"ok","timestamp":1644395029133,"user_tz":-540,"elapsed":383,"user":{"displayName":"Jongbeom Kim","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17252605958116038360"}},"outputId":"906ef565-b402-4ab7-ab49-878a4eb49e09"},"execution_count":46,"outputs":[{"output_type":"stream","name":"stdout","text":["tf.Tensor(\n","[[[ 1.0638801   0.19714275 -0.05003973 ... -0.36791906 -0.41061783\n","   -0.5707639 ]\n","  [ 1.0661123   0.19447348 -0.08111559 ... -0.35333604 -0.4396859\n","   -0.5624925 ]\n","  [ 1.0717965   0.22954686 -0.10544316 ... -0.342729   -0.43486932\n","   -0.56223774]\n","  ...\n","  [ 0.9879183   0.12427015 -0.24944708 ... -0.40025964 -0.37509662\n","   -0.5023753 ]\n","  [ 1.0452101   0.13375866 -0.21822314 ... -0.4027721  -0.4036381\n","   -0.5282049 ]\n","  [ 1.0331978   0.13592795 -0.24215147 ... -0.383679   -0.38680533\n","   -0.5397198 ]]], shape=(1, 40, 2048), dtype=float32)\n"]}]},{"cell_type":"code","execution_count":61,"metadata":{"ExecuteTime":{"end_time":"2022-02-07T08:57:36.308038Z","start_time":"2022-02-07T08:56:35.787894Z"},"id":"cv7qcd-GmMNY","executionInfo":{"status":"ok","timestamp":1644398146412,"user_tz":-540,"elapsed":411,"user":{"displayName":"Jongbeom Kim","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17252605958116038360"}}},"outputs":[],"source":["# `with_info`: If `True`, `tfds.load()` will return the tuple `(tf.data.Dataset, tfds.core.DatasetInfo)`, the latter containing the info associated with the builder.\n","# `as_supervised`: If `True`, the returned `tf.data.Dataset` will have a 2-tuple structure `(input, label)` according to `builder.info.supervised_keys`. If `False`, the returned `tf.data.Dataset` will have a dictionary with all the features.\n","dataset, metadata = tfds.load(\"ted_hrlr_translate/pt_to_en\", with_info=True, as_supervised=True)\n","dataset_tr, dataset_val, dataset_te = dataset[\"train\"], dataset[\"validation\"], dataset[\"test\"]"]},{"cell_type":"code","execution_count":48,"metadata":{"id":"RHE5JQ1hs9rs","executionInfo":{"status":"ok","timestamp":1644395196558,"user_tz":-540,"elapsed":164853,"user":{"displayName":"Jongbeom Kim","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17252605958116038360"}}},"outputs":[],"source":["tokenizer_pt = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus((pt.numpy() for pt, en in dataset_tr), target_vocab_size=2**13)\n","tokenizer_en = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus((en.numpy() for pt, en in dataset_tr), target_vocab_size=2**13)"]},{"cell_type":"code","execution_count":58,"metadata":{"id":"uFmp4-h1tA20","colab":{"base_uri":"https://localhost:8080/","height":433},"executionInfo":{"status":"error","timestamp":1644398103982,"user_tz":-540,"elapsed":385,"user":{"displayName":"Jongbeom Kim","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17252605958116038360"}},"outputId":"fe559948-6699-4135-c1c6-c50c6211631e"},"outputs":[{"output_type":"stream","name":"stdout","text":["([8214, 141, 77, 33, 1566, 873, 4501, 217, 642, 4, 217, 101, 1073, 4824, 17, 5, 488, 200, 8004, 8215], [8087, 7903, 2429, 439, 406, 7345, 7907, 1283, 7870, 9, 527, 6514, 7945, 7864, 8088])\n"]},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-58-f65a66a5513e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;31m# 그 다음 배치에서 문장의 길이가 39 라면, 그 배치에서는 문장의 길이를 39로 유지\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;31m# 가변길이의 배치를 돌릴때 꼭 쓰자\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0mtr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBUFFER_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadded_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;31m# 데이터 로드와 처리의 시간을 overlap하여 속도 향상\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0mtr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprefetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAUTOTUNE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mpadded_batch\u001b[0;34m(self, batch_size, padded_shapes, padding_values, drop_remainder, name)\u001b[0m\n\u001b[1;32m   1835\u001b[0m         \u001b[0;31m# A `tf.TensorShape` is only false if its *rank* is unknown.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1836\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1837\u001b[0;31m           raise ValueError(f\"You must provide `padded_shapes` argument because \"\n\u001b[0m\u001b[1;32m   1838\u001b[0m                            f\"component {i} has unknown rank.\")\n\u001b[1;32m   1839\u001b[0m     return PaddedBatchDataset(\n","\u001b[0;31mValueError\u001b[0m: You must provide `padded_shapes` argument because component 0 has unknown rank."]}],"source":["https://www.tensorflow.org/api_docs/python/tf/data/Dataset\n","def encode(lang1, lang2):\n","    lang1 = [tokenizer_pt.vocab_size] + tokenizer_pt.encode(lang1.numpy()) + [tokenizer_pt.vocab_size + 1]\n","    lang2 = [tokenizer_en.vocab_size] + tokenizer_en.encode(lang2.numpy()) + [tokenizer_en.vocab_size + 1]\n","    return lang1, lang2\n","    \n","lang1 = tf.constant(\"vou então muito rapidamente partilhar convosco algumas histórias de algumas coisas mágicas que aconteceram.\", dtype=tf.string)\n","lang2 = tf.constant(\"Hello man, Let's run transformer!\", dtype=tf.string)\n","print(encode(lang1, lang2))\n","\n","MAX_LENGTH = 40\n","BUFFER_SIZE = 60000\n","BATCH_SIZE = 64\n","\n","# `func`: A Python function that accepts `inp` as arguments, and returns a value (or list of values) whose type is described by `Tout`.\n","# `inpt`: Input arguments for func. A list whose elements are Tensors or a single Tensor.\n","def tf_encode(pt, en):\n","    result_pt, result_en = tf.py_function(func=encode, inp=[pt, en], Tout=[tf.int64, tf.int64])\n","    # result_pt.set_shape([None])\n","    # result_en.set_shape([None])\n","    return result_pt, result_en\n","# This transformation applies `map_func` to each element of this dataset, and returns a new dataset containing the transformed elements, in the same order as they appeared in the input. `map_func` can be used to change both the values and the structure of a dataset's elements.\n","dataset_tr = dataset_tr.map(tf_encode)\n","def filter_max_length(x, y, max_length=MAX_LENGTH):\n","    return tf.logical_and(tf.size(x) <= max_length, tf.size(y) <= max_length)\n","# `predicate`: A function mapping a dataset element to a boolean.\n","# Returns the dataset containing the elements of this dataset for which `predicate` is `True`.\n","dataset_tr = dataset_tr.filter(filter_max_length)\n","# The first time the dataset is iterated over, its elements will be cached either in the specified file or in memory. Subsequent iterations will use the cached data.\n","# `filename`: When caching to a file, the cached data will persist across runs. Even the first iteration through the data will read from the cache file. Changing the input pipeline before the call to `cache()` will have no effect until the cache file is removed or the `filename` is changed. If a `filename` is not provided, the dataset will be cached in memory.\n","dataset_tr = dataset_tr.cache()\n","# 전체 데이터의 수가 50000인데 50000보다 큰 숫자를 입력하면 완전하게 전체 데이터를 섞는 것이며\n","# 전체 데이터 수보다 작은 수를 입력하면 전체 데이터에서 일부만 섞음\n","# padded_batch는 무엇이냐면, 이번 데이터셋은 문장마다 길이가 모두 다르기에\n","# 배치 사이즈(32) 만큼의 문장을 뽑을 때마다\n","# 배치 사이즈에 해당하는 만큼의 문장의 길이는 일정하게 유지됨\n","# 무슨 말이냐면 배치가 2개라면  이 중 하나의 문장의 길이는 37이 될 수 있고\n","# 두 개의 배치(32) 중 하나의 배치는 문장의 길이를 37개로 모두 유지\n","# 그 다음 배치에서 문장의 길이가 39 라면, 그 배치에서는 문장의 길이를 39로 유지\n","# 가변길이의 배치를 돌릴때 꼭 쓰자\n","dataset_tr = dataset_tr.shuffle(BUFFER_SIZE).padded_batch(BATCH_SIZE) \n","# 데이터 로드와 처리의 시간을 overlap하여 속도 향상       \n","dataset_tr = dataset_tr.prefetch(tf.data.experimental.AUTOTUNE)\n","\n","dataset_val = dataset_val.map(tf_encode)\n","dataset_val = dataset_val.filter(filter_max_length)\n","dataset_val = dataset_val.padded_batch(BATCH_SIZE)"]},{"cell_type":"markdown","metadata":{"id":"6Wxi5ftvtRNr"},"source":["- ![Imgur](https://i.imgur.com/Tl2zsFL.png)\n","- ![Imgur](https://i.imgur.com/SNIEhlA.png)"]},{"cell_type":"markdown","metadata":{"id":"0LuW2OLQ_LC3"},"source":["#하이퍼파라미터 설정하기\n","테스트를 위해서 층을 가볍게 쌓아보도록 하겠습니다."]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2022-02-04T16:29:51.289828Z","start_time":"2022-02-04T16:29:51.258832Z"},"id":"3IBl1m3T_KdU","outputId":"93924bc2-c76e-4d6d-f1eb-27fb49893885"},"outputs":[{"ename":"NameError","evalue":"name 'tokenizer_pt' is not defined","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[1;32m<ipython-input-160-67e59806f03d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mSEQ_LEN\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m40\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0minput_vocab_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtokenizer_pt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab_size\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mtarget_vocab_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtokenizer_en\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab_size\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mdropout_rate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mNameError\u001b[0m: name 'tokenizer_pt' is not defined"]}],"source":["vocab_size_src = tokenizer_pt.vocab_size + 2\n","vocab_size_tar = tokenizer_en.vocab_size + 2\n","dropout_rate = 0.1"]},{"cell_type":"markdown","metadata":{"id":"oJlCBwNE_Sex"},"source":["# 옵티마이저 설정하기\n","옵티마이저는 논문에 따라서 성능이 좋았다는 옵티마이저를 복사 붙여넣기 하였습니다."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wH6O3Gvs_R0O"},"outputs":[],"source":["class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n","  def __init__(self, d_model, warmup_steps=4000):\n","    super(CustomSchedule, self).__init__()\n","    \n","    self.d_model = d_model\n","    self.d_model = tf.cast(self.d_model, tf.float32)\n","\n","    self.warmup_steps = warmup_steps\n","    \n","  def __call__(self, step):\n","    arg1 = tf.math.rsqrt(step)\n","    arg2 = step * (self.warmup_steps ** -1.5)\n","    \n","    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n","\n","learning_rate = CustomSchedule(d_model)\n","\n","optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, \n","                                     epsilon=1e-9)"]},{"cell_type":"markdown","metadata":{"id":"ZemqrgPw_bPe"},"source":["# Loss 함수 설정하기\n","loss 함수 또한 중요한 부분인데, transformer에서는 패딩되는 부분을 Loss를 계산할 때 연산하지 않겠습니다."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vl-ogg3D_eru"},"outputs":[],"source":["loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none') #from_logits=True로 하면 Dense 이후 softmax layer 값 출력\n","\n","def loss_function(real, pred):\n","  mask = tf.math.logical_not(tf.math.equal(real, 0)) # 예를 들어서 실제 자료(0은 패딩)가 [1,2,3,4,5,0,0,0,0,0] 이라면 [0,0,0,0,0,1,1,1,1,1]로 바꿔 줌\n","                                                     # 이후 tf.math.logical_not을 활용해서 [True,True,True,True,True,False,False,False,False,False]으로 바꿔 줌\n","  loss_ = loss_object(real, pred) # loss_는 패딩을 고려하지 않은 loss 값\n","\n","  mask = tf.cast(mask, dtype=loss_.dtype) # [True,True,True,True,True,False,False,False,False,False]를 [1,1,1,1,1,0,0,0,0,0] 으로 바꿔 줌\n","  loss_ *= mask # loss에 mask를 곱해서, 패딩인 부분은 0처리 해줌\n","\n","  return tf.reduce_sum(loss_)/tf.reduce_sum(mask)\n","\n","train_loss = tf.keras.metrics.Mean(name='train_loss')\n","train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')"]},{"cell_type":"markdown","metadata":{"id":"6zZ0hEBSD5ka"},"source":["# 모델 훈련"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z2GySrPlEx2l"},"outputs":[],"source":["transformer = Transformer(n_layers, d_model, n_heads, dff,\n","                          vocab_size_src, vocab_size_tar, \n","                          pe_input=10000, \n","                          pe_tar=10000,\n","                          rate=0.1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k07jNkQIw9N6"},"outputs":[],"source":["# 인풋, 아웃풋의 텐셔 shape 정의\n","train_step_signature = [\n","    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n","    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n","]\n","\n","# tf.function을 사용하면 그래프를 미리 컴파일 하기 때문에 속도가 상당히 빠름\n","# 같은 GPU여도 케라스에 비해서 체감상 7~8배 정도의 차이가 나는 것 같음\n","@tf.function(input_signature=train_step_signature)\n","def train_step(src, tar):\n","  tar_src = tar[:, :-1]\n","  tar_real = tar[:, 1:]\n","  \n","  with tf.GradientTape() as tape:\n","    predictions = transformer(src, tar_src, True)\n","    loss = loss_function(tar_real, predictions)\n","\n","  gradients = tape.gradient(loss, transformer.trainable_variables)    \n","  optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n","  \n","  train_loss(loss)\n","  train_accuracy(tar_real, predictions)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1Iq2uReVFS1J"},"outputs":[],"source":["# 저장할 체크포인트 지정\n","checkpoint_path = \"./\"\n","\n","ckpt = tf.train.Checkpoint(transformer=transformer,\n","                           optimizer=optimizer)\n","\n","ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n","\n","# if a checkpoint exists, restore the latest checkpoint.\n","if ckpt_manager.latest_checkpoint:\n","  ckpt.restore(ckpt_manager.latest_checkpoint)\n","  print ('Latest checkpoint restored!!')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"xHAeCJP-xZCu","outputId":"36a8fe30-f744-4a6c-bf73-4a5e74e96bc7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1 Batch 0 Loss 8.9987 Accuracy 0.0000\n","Epoch 1 Batch 50 Loss 8.9453 Accuracy 0.0034\n","Epoch 1 Batch 100 Loss 8.8529 Accuracy 0.0134\n","Epoch 1 Batch 150 Loss 8.7466 Accuracy 0.0168\n","Epoch 1 Batch 200 Loss 8.6171 Accuracy 0.0184\n","Epoch 1 Batch 250 Loss 8.4618 Accuracy 0.0195\n","Epoch 1 Batch 300 Loss 8.2848 Accuracy 0.0236\n","Epoch 1 Batch 350 Loss 8.1004 Accuracy 0.0273\n","Epoch 1 Batch 400 Loss 7.9196 Accuracy 0.0301\n","Epoch 1 Batch 450 Loss 7.7574 Accuracy 0.0326\n","Epoch 1 Batch 500 Loss 7.6136 Accuracy 0.0355\n","Epoch 1 Batch 550 Loss 7.4792 Accuracy 0.0388\n","Epoch 1 Batch 600 Loss 7.3546 Accuracy 0.0427\n","Epoch 1 Batch 650 Loss 7.2348 Accuracy 0.0465\n","Epoch 1 Batch 700 Loss 7.1196 Accuracy 0.0503\n","Epoch 1 Loss 7.1152 Accuracy 0.0504\n","Time taken for 1 epoch: 79.08091878890991 secs\n","\n","Epoch 2 Batch 0 Loss 5.7278 Accuracy 0.0938\n","Epoch 2 Batch 50 Loss 5.4732 Accuracy 0.1046\n","Epoch 2 Batch 100 Loss 5.4041 Accuracy 0.1061\n","Epoch 2 Batch 150 Loss 5.3532 Accuracy 0.1085\n","Epoch 2 Batch 200 Loss 5.3088 Accuracy 0.1099\n","Epoch 2 Batch 250 Loss 5.2682 Accuracy 0.1124\n","Epoch 2 Batch 300 Loss 5.2265 Accuracy 0.1145\n","Epoch 2 Batch 350 Loss 5.1899 Accuracy 0.1161\n","Epoch 2 Batch 400 Loss 5.1555 Accuracy 0.1177\n","Epoch 2 Batch 450 Loss 5.1229 Accuracy 0.1194\n","Epoch 2 Batch 500 Loss 5.0927 Accuracy 0.1209\n","Epoch 2 Batch 550 Loss 5.0652 Accuracy 0.1222\n","Epoch 2 Batch 600 Loss 5.0397 Accuracy 0.1234\n","Epoch 2 Batch 650 Loss 5.0119 Accuracy 0.1247\n","Epoch 2 Batch 700 Loss 4.9883 Accuracy 0.1259\n","Epoch 2 Loss 4.9868 Accuracy 0.1259\n","Time taken for 1 epoch: 44.30380201339722 secs\n","\n","Epoch 3 Batch 0 Loss 4.6232 Accuracy 0.1753\n","Epoch 3 Batch 50 Loss 4.5817 Accuracy 0.1450\n","Epoch 3 Batch 100 Loss 4.5632 Accuracy 0.1459\n","Epoch 3 Batch 150 Loss 4.5604 Accuracy 0.1459\n","Epoch 3 Batch 200 Loss 4.5491 Accuracy 0.1465\n","Epoch 3 Batch 250 Loss 4.5413 Accuracy 0.1470\n","Epoch 3 Batch 300 Loss 4.5299 Accuracy 0.1475\n","Epoch 3 Batch 350 Loss 4.5184 Accuracy 0.1482\n","Epoch 3 Batch 400 Loss 4.5085 Accuracy 0.1485\n","Epoch 3 Batch 450 Loss 4.5005 Accuracy 0.1490\n","Epoch 3 Batch 500 Loss 4.4873 Accuracy 0.1495\n","Epoch 3 Batch 550 Loss 4.4756 Accuracy 0.1498\n","Epoch 3 Batch 600 Loss 4.4677 Accuracy 0.1501\n","Epoch 3 Batch 650 Loss 4.4568 Accuracy 0.1505\n","Epoch 3 Batch 700 Loss 4.4470 Accuracy 0.1510\n","Epoch 3 Loss 4.4468 Accuracy 0.1510\n","Time taken for 1 epoch: 44.45479679107666 secs\n","\n","Epoch 4 Batch 0 Loss 4.2324 Accuracy 0.1636\n","Epoch 4 Batch 50 Loss 4.1740 Accuracy 0.1633\n","Epoch 4 Batch 100 Loss 4.1639 Accuracy 0.1627\n","Epoch 4 Batch 150 Loss 4.1519 Accuracy 0.1631\n","Epoch 4 Batch 200 Loss 4.1324 Accuracy 0.1641\n","Epoch 4 Batch 250 Loss 4.1250 Accuracy 0.1651\n","Epoch 4 Batch 300 Loss 4.1188 Accuracy 0.1660\n","Epoch 4 Batch 350 Loss 4.1145 Accuracy 0.1666\n","Epoch 4 Batch 400 Loss 4.1005 Accuracy 0.1673\n","Epoch 4 Batch 450 Loss 4.0890 Accuracy 0.1679\n","Epoch 4 Batch 500 Loss 4.0780 Accuracy 0.1688\n","Epoch 4 Batch 550 Loss 4.0656 Accuracy 0.1697\n","Epoch 4 Batch 600 Loss 4.0532 Accuracy 0.1705\n","Epoch 4 Batch 650 Loss 4.0402 Accuracy 0.1714\n","Epoch 4 Batch 700 Loss 4.0248 Accuracy 0.1724\n","Epoch 4 Loss 4.0242 Accuracy 0.1725\n","Time taken for 1 epoch: 44.30045199394226 secs\n","\n","Epoch 5 Batch 0 Loss 3.4033 Accuracy 0.2066\n","Epoch 5 Batch 50 Loss 3.6744 Accuracy 0.1919\n","Epoch 5 Batch 100 Loss 3.6507 Accuracy 0.1927\n","Epoch 5 Batch 150 Loss 3.6447 Accuracy 0.1930\n","Epoch 5 Batch 200 Loss 3.6315 Accuracy 0.1935\n","Epoch 5 Batch 250 Loss 3.6214 Accuracy 0.1949\n","Epoch 5 Batch 300 Loss 3.6175 Accuracy 0.1955\n","Epoch 5 Batch 350 Loss 3.6045 Accuracy 0.1963\n","Epoch 5 Batch 400 Loss 3.5996 Accuracy 0.1968\n","Epoch 5 Batch 450 Loss 3.5912 Accuracy 0.1975\n","Epoch 5 Batch 500 Loss 3.5839 Accuracy 0.1977\n","Epoch 5 Batch 550 Loss 3.5748 Accuracy 0.1985\n","Epoch 5 Batch 600 Loss 3.5650 Accuracy 0.1990\n","Epoch 5 Batch 650 Loss 3.5589 Accuracy 0.1998\n","Epoch 5 Batch 700 Loss 3.5506 Accuracy 0.2004\n","Saving checkpoint for epoch 5 at ./ckpt-1\n","Epoch 5 Loss 3.5497 Accuracy 0.2004\n","Time taken for 1 epoch: 44.612069606781006 secs\n","\n","Epoch 6 Batch 0 Loss 3.0750 Accuracy 0.2216\n","Epoch 6 Batch 50 Loss 3.1687 Accuracy 0.2194\n","Epoch 6 Batch 100 Loss 3.1730 Accuracy 0.2190\n","Epoch 6 Batch 150 Loss 3.1820 Accuracy 0.2170\n","Epoch 6 Batch 200 Loss 3.1866 Accuracy 0.2174\n","Epoch 6 Batch 250 Loss 3.1848 Accuracy 0.2187\n","Epoch 6 Batch 300 Loss 3.1812 Accuracy 0.2195\n","Epoch 6 Batch 350 Loss 3.1806 Accuracy 0.2197\n","Epoch 6 Batch 400 Loss 3.1767 Accuracy 0.2200\n","Epoch 6 Batch 450 Loss 3.1744 Accuracy 0.2203\n","Epoch 6 Batch 500 Loss 3.1683 Accuracy 0.2205\n","Epoch 6 Batch 550 Loss 3.1619 Accuracy 0.2211\n","Epoch 6 Batch 600 Loss 3.1561 Accuracy 0.2215\n","Epoch 6 Batch 650 Loss 3.1484 Accuracy 0.2222\n","Epoch 6 Batch 700 Loss 3.1421 Accuracy 0.2229\n","Epoch 6 Loss 3.1415 Accuracy 0.2229\n","Time taken for 1 epoch: 44.359644174575806 secs\n","\n","Epoch 7 Batch 0 Loss 2.6573 Accuracy 0.2393\n","Epoch 7 Batch 50 Loss 2.7642 Accuracy 0.2404\n","Epoch 7 Batch 100 Loss 2.7670 Accuracy 0.2407\n","Epoch 7 Batch 150 Loss 2.7668 Accuracy 0.2406\n","Epoch 7 Batch 200 Loss 2.7715 Accuracy 0.2397\n","Epoch 7 Batch 250 Loss 2.7681 Accuracy 0.2396\n","Epoch 7 Batch 300 Loss 2.7650 Accuracy 0.2407\n","Epoch 7 Batch 350 Loss 2.7639 Accuracy 0.2420\n","Epoch 7 Batch 400 Loss 2.7613 Accuracy 0.2425\n","Epoch 7 Batch 450 Loss 2.7583 Accuracy 0.2431\n","Epoch 7 Batch 500 Loss 2.7541 Accuracy 0.2433\n","Epoch 7 Batch 550 Loss 2.7502 Accuracy 0.2437\n","Epoch 7 Batch 600 Loss 2.7465 Accuracy 0.2442\n","Epoch 7 Batch 650 Loss 2.7427 Accuracy 0.2445\n","Epoch 7 Batch 700 Loss 2.7391 Accuracy 0.2447\n","Epoch 7 Loss 2.7391 Accuracy 0.2447\n","Time taken for 1 epoch: 44.38622713088989 secs\n","\n","Epoch 8 Batch 0 Loss 2.3553 Accuracy 0.2520\n","Epoch 8 Batch 50 Loss 2.3678 Accuracy 0.2643\n","Epoch 8 Batch 100 Loss 2.3673 Accuracy 0.2646\n","Epoch 8 Batch 150 Loss 2.3807 Accuracy 0.2658\n","Epoch 8 Batch 200 Loss 2.3894 Accuracy 0.2654\n","Epoch 8 Batch 250 Loss 2.3896 Accuracy 0.2648\n","Epoch 8 Batch 300 Loss 2.3910 Accuracy 0.2652\n","Epoch 8 Batch 350 Loss 2.3955 Accuracy 0.2654\n","Epoch 8 Batch 400 Loss 2.4008 Accuracy 0.2655\n","Epoch 8 Batch 450 Loss 2.4007 Accuracy 0.2655\n","Epoch 8 Batch 500 Loss 2.4016 Accuracy 0.2658\n","Epoch 8 Batch 550 Loss 2.4038 Accuracy 0.2654\n","Epoch 8 Batch 600 Loss 2.4054 Accuracy 0.2653\n","Epoch 8 Batch 650 Loss 2.4071 Accuracy 0.2652\n","Epoch 8 Batch 700 Loss 2.4059 Accuracy 0.2651\n","Epoch 8 Loss 2.4056 Accuracy 0.2651\n","Time taken for 1 epoch: 44.65272235870361 secs\n","\n","Epoch 9 Batch 0 Loss 2.1085 Accuracy 0.3173\n","Epoch 9 Batch 50 Loss 2.0877 Accuracy 0.2828\n","Epoch 9 Batch 100 Loss 2.0966 Accuracy 0.2807\n","Epoch 9 Batch 150 Loss 2.1006 Accuracy 0.2810\n","Epoch 9 Batch 200 Loss 2.1152 Accuracy 0.2807\n","Epoch 9 Batch 250 Loss 2.1257 Accuracy 0.2805\n","Epoch 9 Batch 300 Loss 2.1357 Accuracy 0.2800\n","Epoch 9 Batch 350 Loss 2.1423 Accuracy 0.2795\n","Epoch 9 Batch 400 Loss 2.1448 Accuracy 0.2790\n","Epoch 9 Batch 450 Loss 2.1508 Accuracy 0.2790\n","Epoch 9 Batch 500 Loss 2.1557 Accuracy 0.2791\n","Epoch 9 Batch 550 Loss 2.1559 Accuracy 0.2793\n","Epoch 9 Batch 600 Loss 2.1574 Accuracy 0.2793\n","Epoch 9 Batch 650 Loss 2.1622 Accuracy 0.2790\n","Epoch 9 Batch 700 Loss 2.1654 Accuracy 0.2789\n","Epoch 9 Loss 2.1653 Accuracy 0.2789\n","Time taken for 1 epoch: 44.233455419540405 secs\n","\n","Epoch 10 Batch 0 Loss 1.8756 Accuracy 0.2834\n","Epoch 10 Batch 50 Loss 1.8793 Accuracy 0.2984\n","Epoch 10 Batch 100 Loss 1.8912 Accuracy 0.2946\n","Epoch 10 Batch 150 Loss 1.9065 Accuracy 0.2933\n","Epoch 10 Batch 200 Loss 1.9212 Accuracy 0.2928\n","Epoch 10 Batch 250 Loss 1.9342 Accuracy 0.2919\n","Epoch 10 Batch 300 Loss 1.9413 Accuracy 0.2912\n","Epoch 10 Batch 350 Loss 1.9483 Accuracy 0.2908\n","Epoch 10 Batch 400 Loss 1.9546 Accuracy 0.2905\n","Epoch 10 Batch 450 Loss 1.9630 Accuracy 0.2906\n","Epoch 10 Batch 500 Loss 1.9661 Accuracy 0.2902\n","Epoch 10 Batch 550 Loss 1.9707 Accuracy 0.2896\n","Epoch 10 Batch 600 Loss 1.9729 Accuracy 0.2896\n","Epoch 10 Batch 650 Loss 1.9780 Accuracy 0.2896\n","Epoch 10 Batch 700 Loss 1.9842 Accuracy 0.2895\n","Saving checkpoint for epoch 10 at ./ckpt-2\n","Epoch 10 Loss 1.9850 Accuracy 0.2896\n","Time taken for 1 epoch: 44.6807496547699 secs\n","\n","Epoch 11 Batch 0 Loss 1.6583 Accuracy 0.2910\n","Epoch 11 Batch 50 Loss 1.7554 Accuracy 0.3036\n","Epoch 11 Batch 100 Loss 1.7630 Accuracy 0.3031\n","Epoch 11 Batch 150 Loss 1.7672 Accuracy 0.3026\n","Epoch 11 Batch 200 Loss 1.7777 Accuracy 0.3023\n","Epoch 11 Batch 250 Loss 1.7821 Accuracy 0.3023\n","Epoch 11 Batch 300 Loss 1.7942 Accuracy 0.3016\n","Epoch 11 Batch 350 Loss 1.7979 Accuracy 0.3009\n","Epoch 11 Batch 400 Loss 1.8074 Accuracy 0.3001\n","Epoch 11 Batch 450 Loss 1.8148 Accuracy 0.2999\n","Epoch 11 Batch 500 Loss 1.8219 Accuracy 0.2997\n","Epoch 11 Batch 550 Loss 1.8271 Accuracy 0.2987\n","Epoch 11 Batch 600 Loss 1.8334 Accuracy 0.2987\n","Epoch 11 Batch 650 Loss 1.8386 Accuracy 0.2983\n","Epoch 11 Batch 700 Loss 1.8418 Accuracy 0.2979\n","Epoch 11 Loss 1.8421 Accuracy 0.2979\n","Time taken for 1 epoch: 44.32446074485779 secs\n","\n","Epoch 12 Batch 0 Loss 1.7401 Accuracy 0.3160\n","Epoch 12 Batch 50 Loss 1.6039 Accuracy 0.3171\n","Epoch 12 Batch 100 Loss 1.6199 Accuracy 0.3134\n","Epoch 12 Batch 150 Loss 1.6305 Accuracy 0.3125\n","Epoch 12 Batch 200 Loss 1.6466 Accuracy 0.3117\n","Epoch 12 Batch 250 Loss 1.6590 Accuracy 0.3104\n","Epoch 12 Batch 300 Loss 1.6704 Accuracy 0.3096\n","Epoch 12 Batch 350 Loss 1.6805 Accuracy 0.3088\n","Epoch 12 Batch 400 Loss 1.6886 Accuracy 0.3078\n","Epoch 12 Batch 450 Loss 1.6941 Accuracy 0.3072\n","Epoch 12 Batch 500 Loss 1.6983 Accuracy 0.3066\n","Epoch 12 Batch 550 Loss 1.7061 Accuracy 0.3061\n","Epoch 12 Batch 600 Loss 1.7130 Accuracy 0.3058\n","Epoch 12 Batch 650 Loss 1.7191 Accuracy 0.3056\n","Epoch 12 Batch 700 Loss 1.7226 Accuracy 0.3050\n","Epoch 12 Loss 1.7227 Accuracy 0.3050\n","Time taken for 1 epoch: 44.53757357597351 secs\n","\n","Epoch 13 Batch 0 Loss 1.4844 Accuracy 0.3349\n","Epoch 13 Batch 50 Loss 1.5040 Accuracy 0.3219\n","Epoch 13 Batch 100 Loss 1.5169 Accuracy 0.3208\n","Epoch 13 Batch 150 Loss 1.5308 Accuracy 0.3187\n","Epoch 13 Batch 200 Loss 1.5406 Accuracy 0.3179\n","Epoch 13 Batch 250 Loss 1.5506 Accuracy 0.3169\n","Epoch 13 Batch 300 Loss 1.5573 Accuracy 0.3166\n","Epoch 13 Batch 350 Loss 1.5668 Accuracy 0.3159\n","Epoch 13 Batch 400 Loss 1.5764 Accuracy 0.3147\n","Epoch 13 Batch 450 Loss 1.5884 Accuracy 0.3145\n","Epoch 13 Batch 500 Loss 1.5955 Accuracy 0.3139\n","Epoch 13 Batch 550 Loss 1.6034 Accuracy 0.3135\n","Epoch 13 Batch 600 Loss 1.6101 Accuracy 0.3130\n","Epoch 13 Batch 650 Loss 1.6177 Accuracy 0.3126\n","Epoch 13 Batch 700 Loss 1.6227 Accuracy 0.3121\n","Epoch 13 Loss 1.6229 Accuracy 0.3121\n","Time taken for 1 epoch: 45.53956842422485 secs\n","\n","Epoch 14 Batch 0 Loss 1.3664 Accuracy 0.3628\n","Epoch 14 Batch 50 Loss 1.4419 Accuracy 0.3263\n","Epoch 14 Batch 100 Loss 1.4345 Accuracy 0.3253\n","Epoch 14 Batch 150 Loss 1.4512 Accuracy 0.3228\n","Epoch 14 Batch 200 Loss 1.4614 Accuracy 0.3228\n","Epoch 14 Batch 250 Loss 1.4696 Accuracy 0.3227\n","Epoch 14 Batch 300 Loss 1.4805 Accuracy 0.3218\n","Epoch 14 Batch 350 Loss 1.4866 Accuracy 0.3217\n","Epoch 14 Batch 400 Loss 1.4968 Accuracy 0.3206\n","Epoch 14 Batch 450 Loss 1.5069 Accuracy 0.3201\n","Epoch 14 Batch 500 Loss 1.5126 Accuracy 0.3195\n","Epoch 14 Batch 550 Loss 1.5201 Accuracy 0.3186\n","Epoch 14 Batch 600 Loss 1.5266 Accuracy 0.3184\n","Epoch 14 Batch 650 Loss 1.5326 Accuracy 0.3179\n","Epoch 14 Batch 700 Loss 1.5357 Accuracy 0.3175\n","Epoch 14 Loss 1.5363 Accuracy 0.3175\n","Time taken for 1 epoch: 45.02189350128174 secs\n","\n","Epoch 15 Batch 0 Loss 1.3980 Accuracy 0.3264\n","Epoch 15 Batch 50 Loss 1.3330 Accuracy 0.3386\n","Epoch 15 Batch 100 Loss 1.3475 Accuracy 0.3332\n","Epoch 15 Batch 150 Loss 1.3621 Accuracy 0.3320\n","Epoch 15 Batch 200 Loss 1.3744 Accuracy 0.3307\n","Epoch 15 Batch 250 Loss 1.3803 Accuracy 0.3291\n","Epoch 15 Batch 300 Loss 1.3911 Accuracy 0.3281\n","Epoch 15 Batch 350 Loss 1.4005 Accuracy 0.3274\n","Epoch 15 Batch 400 Loss 1.4124 Accuracy 0.3264\n","Epoch 15 Batch 450 Loss 1.4211 Accuracy 0.3254\n","Epoch 15 Batch 500 Loss 1.4297 Accuracy 0.3247\n","Epoch 15 Batch 550 Loss 1.4350 Accuracy 0.3240\n","Epoch 15 Batch 600 Loss 1.4447 Accuracy 0.3236\n","Epoch 15 Batch 650 Loss 1.4527 Accuracy 0.3234\n","Epoch 15 Batch 700 Loss 1.4604 Accuracy 0.3227\n","Saving checkpoint for epoch 15 at ./ckpt-3\n","Epoch 15 Loss 1.4602 Accuracy 0.3228\n","Time taken for 1 epoch: 45.342923402786255 secs\n","\n","Epoch 16 Batch 0 Loss 1.0781 Accuracy 0.3229\n","Epoch 16 Batch 50 Loss 1.2595 Accuracy 0.3371\n","Epoch 16 Batch 100 Loss 1.2736 Accuracy 0.3376\n","Epoch 16 Batch 150 Loss 1.2938 Accuracy 0.3356\n","Epoch 16 Batch 200 Loss 1.3076 Accuracy 0.3345\n","Epoch 16 Batch 250 Loss 1.3196 Accuracy 0.3338\n","Epoch 16 Batch 300 Loss 1.3290 Accuracy 0.3327\n","Epoch 16 Batch 350 Loss 1.3344 Accuracy 0.3319\n","Epoch 16 Batch 400 Loss 1.3451 Accuracy 0.3305\n","Epoch 16 Batch 450 Loss 1.3558 Accuracy 0.3295\n","Epoch 16 Batch 500 Loss 1.3615 Accuracy 0.3293\n","Epoch 16 Batch 550 Loss 1.3697 Accuracy 0.3291\n","Epoch 16 Batch 600 Loss 1.3796 Accuracy 0.3286\n","Epoch 16 Batch 650 Loss 1.3871 Accuracy 0.3282\n","Epoch 16 Batch 700 Loss 1.3930 Accuracy 0.3280\n","Epoch 16 Loss 1.3932 Accuracy 0.3281\n","Time taken for 1 epoch: 44.752070903778076 secs\n","\n","Epoch 17 Batch 0 Loss 1.2447 Accuracy 0.3290\n","Epoch 17 Batch 50 Loss 1.1962 Accuracy 0.3427\n","Epoch 17 Batch 100 Loss 1.2119 Accuracy 0.3427\n","Epoch 17 Batch 150 Loss 1.2303 Accuracy 0.3413\n","Epoch 17 Batch 200 Loss 1.2430 Accuracy 0.3406\n","Epoch 17 Batch 250 Loss 1.2576 Accuracy 0.3384\n","Epoch 17 Batch 300 Loss 1.2662 Accuracy 0.3378\n","Epoch 17 Batch 350 Loss 1.2733 Accuracy 0.3369\n","Epoch 17 Batch 400 Loss 1.2822 Accuracy 0.3366\n","Epoch 17 Batch 450 Loss 1.2910 Accuracy 0.3361\n","Epoch 17 Batch 500 Loss 1.3018 Accuracy 0.3349\n","Epoch 17 Batch 550 Loss 1.3092 Accuracy 0.3344\n","Epoch 17 Batch 600 Loss 1.3173 Accuracy 0.3343\n","Epoch 17 Batch 650 Loss 1.3250 Accuracy 0.3332\n","Epoch 17 Batch 700 Loss 1.3319 Accuracy 0.3330\n","Epoch 17 Loss 1.3320 Accuracy 0.3329\n","Time taken for 1 epoch: 44.743831634521484 secs\n","\n","Epoch 18 Batch 0 Loss 0.9768 Accuracy 0.3506\n","Epoch 18 Batch 50 Loss 1.1597 Accuracy 0.3449\n","Epoch 18 Batch 100 Loss 1.1689 Accuracy 0.3432\n","Epoch 18 Batch 150 Loss 1.1853 Accuracy 0.3427\n","Epoch 18 Batch 200 Loss 1.1996 Accuracy 0.3417\n","Epoch 18 Batch 250 Loss 1.2107 Accuracy 0.3412\n","Epoch 18 Batch 300 Loss 1.2179 Accuracy 0.3406\n","Epoch 18 Batch 350 Loss 1.2236 Accuracy 0.3400\n","Epoch 18 Batch 400 Loss 1.2332 Accuracy 0.3391\n","Epoch 18 Batch 450 Loss 1.2427 Accuracy 0.3387\n","Epoch 18 Batch 500 Loss 1.2513 Accuracy 0.3382\n","Epoch 18 Batch 550 Loss 1.2566 Accuracy 0.3379\n","Epoch 18 Batch 600 Loss 1.2634 Accuracy 0.3374\n","Epoch 18 Batch 650 Loss 1.2710 Accuracy 0.3370\n","Epoch 18 Batch 700 Loss 1.2777 Accuracy 0.3366\n","Epoch 18 Loss 1.2774 Accuracy 0.3367\n","Time taken for 1 epoch: 44.47447395324707 secs\n","\n","Epoch 19 Batch 0 Loss 1.0398 Accuracy 0.3698\n","Epoch 19 Batch 50 Loss 1.1146 Accuracy 0.3477\n","Epoch 19 Batch 100 Loss 1.1219 Accuracy 0.3496\n","Epoch 19 Batch 150 Loss 1.1362 Accuracy 0.3464\n","Epoch 19 Batch 200 Loss 1.1474 Accuracy 0.3457\n","Epoch 19 Batch 250 Loss 1.1572 Accuracy 0.3451\n","Epoch 19 Batch 300 Loss 1.1672 Accuracy 0.3435\n","Epoch 19 Batch 350 Loss 1.1768 Accuracy 0.3431\n","Epoch 19 Batch 400 Loss 1.1841 Accuracy 0.3427\n","Epoch 19 Batch 450 Loss 1.1887 Accuracy 0.3424\n","Epoch 19 Batch 500 Loss 1.1962 Accuracy 0.3417\n","Epoch 19 Batch 550 Loss 1.2048 Accuracy 0.3415\n","Epoch 19 Batch 600 Loss 1.2142 Accuracy 0.3406\n","Epoch 19 Batch 650 Loss 1.2215 Accuracy 0.3404\n","Epoch 19 Batch 700 Loss 1.2298 Accuracy 0.3393\n","Epoch 19 Loss 1.2299 Accuracy 0.3394\n","Time taken for 1 epoch: 44.57541823387146 secs\n","\n","Epoch 20 Batch 0 Loss 1.0221 Accuracy 0.3498\n","Epoch 20 Batch 50 Loss 1.0534 Accuracy 0.3617\n","Epoch 20 Batch 100 Loss 1.0729 Accuracy 0.3588\n","Epoch 20 Batch 150 Loss 1.0862 Accuracy 0.3541\n","Epoch 20 Batch 200 Loss 1.0935 Accuracy 0.3535\n","Epoch 20 Batch 250 Loss 1.1069 Accuracy 0.3523\n","Epoch 20 Batch 300 Loss 1.1191 Accuracy 0.3519\n","Epoch 20 Batch 350 Loss 1.1304 Accuracy 0.3501\n","Epoch 20 Batch 400 Loss 1.1404 Accuracy 0.3491\n","Epoch 20 Batch 450 Loss 1.1501 Accuracy 0.3484\n","Epoch 20 Batch 500 Loss 1.1566 Accuracy 0.3472\n","Epoch 20 Batch 550 Loss 1.1619 Accuracy 0.3463\n","Epoch 20 Batch 600 Loss 1.1689 Accuracy 0.3454\n","Epoch 20 Batch 650 Loss 1.1756 Accuracy 0.3445\n","Epoch 20 Batch 700 Loss 1.1817 Accuracy 0.3442\n","Saving checkpoint for epoch 20 at ./ckpt-4\n","Epoch 20 Loss 1.1820 Accuracy 0.3441\n","Time taken for 1 epoch: 44.694963693618774 secs\n","\n"]}],"source":["import time\n","# 20 에포크 훈련\n","for epoch in range(20):\n","  start = time.time()\n","  \n","  train_loss.reset_states()\n","  train_accuracy.reset_states()\n","  \n","  # input : 포루투갈어, tar : 영어\n","  for (batch, (src, tar)) in enumerate(tr):\n","    train_step(src, tar)\n","    \n","    if batch % 50 == 0:\n","      print ('Epoch {} Batch {} Loss {:.4f} Accuracy {:.4f}'.format(\n","          epoch + 1, batch, train_loss.result(), train_accuracy.result()))\n","      \n","  if (epoch + 1) % 5 == 0:\n","    ckpt_save_path = ckpt_manager.save()\n","    print ('Saving checkpoint for epoch {} at {}'.format(epoch+1,\n","                                                         ckpt_save_path))\n","    \n","  print ('Epoch {} Loss {:.4f} Accuracy {:.4f}'.format(epoch + 1, \n","                                                train_loss.result(), \n","                                                train_accuracy.result()))\n","\n","  print ('Time taken for 1 epoch: {} secs\\n'.format(time.time() - start))"]},{"cell_type":"markdown","metadata":{"id":"45sJJKmdL8u-"},"source":["# Inference\n","![Imgur](https://i.imgur.com/cUjg18g.png)  \n","\n","\n","평가는 훈련과는 다르게 진행됩니다.  \n","번역할 포르투갈어는 인코더 레이어를 거쳐 인코딩이 되고,  \n","디코더에는 영어 문장을 넣지 않고, 영어 문장의 시작 토큰만 디코더의 인풋으로 들어가게 됩니다.  \n","그러면 인코딩 된 것과 + 시작 토큰을 활용해서 다음 단어를 예측하고,  \n","인코딩 된 것 + 시작 토큰 + 전에 예측된 단어를 활용해서 다음 단어를 예측하는 방식입니다. \n","  \n","그림에서는 bos가 시작 토큰입니다.\n","![Imgur](https://i.imgur.com/F6QseH6.png)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fdaL7LLfGzaQ"},"outputs":[],"source":["def evaluate(src_sentence):\n","  # src_sentence : 문자 (string)\n","  start_token = [tokenizer_pt.vocab_size] # 포르투갈어의 시작 토큰\n","  end_token = [tokenizer_pt.vocab_size + 1] # 포르투갈어의 끝 토큰\n","  \n","  # 시작 토큰 + 포르투갈 어 + 끝 토큰\n","  src_sentence = start_token + tokenizer_pt.encode(src_sentence) + end_token\n","  encoder_input = tf.expand_dims(src_sentence, 0)\n","  \n","  # 디코더의 인풋은 영어 문장의 시작 토큰만 들어감\n","  decoder_input = [tokenizer_en.vocab_size]\n","  output = tf.expand_dims(decoder_input, 0)\n","  \n","  for i in range(MAX_LENGTH):\n","    # predictions.shape == (batch_size, seq_len, vocab_size)\n","    predictions = transformer(encoder_input, output, False)\n","    \n","    # 예측 결과에서 마지막 부분만 추출\n","    predictions = predictions[: ,-1:, :]  # (batch_size, 1, vocab_size)\n","\n","    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n","\n","    # 만약에 예측된 영어 단어가 영어의 끝 토큰에 해당한다면 예측을 끝냄\n","    if predicted_id == tokenizer_en.vocab_size+1:\n","      return tf.squeeze(output, axis=0)\n","    \n","    # 예측된 단어를 전 단어와 결합하여 다음 예측에 써먹음\n","    output = tf.concat([output, predicted_id], axis=-1)\n","\n","  return tf.squeeze(output, axis=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ECK0XFzCHBxv"},"outputs":[],"source":["def translate(sentence):\n","  result= evaluate(sentence)\n","  \n","  predicted_sentence = tokenizer_en.decode([i for i in result \n","                                            if i < tokenizer_en.vocab_size])  \n","\n","  print('input: {}'.format(sentence))\n","  print('Predicted translation: {}'.format(predicted_sentence))"]},{"cell_type":"markdown","metadata":{"id":"Fe6y5oDePZOI"},"source":["실제로 번역해보기  \n","제법 포르투갈 어를 영어 문법에 맞게 번역하는 것을 알 수 있습니다."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":73},"id":"czjSk64HHCq5","outputId":"88cdd289-4a37-4537-c101-5d9d5a81c7d2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Input: este é um problema que temos que resolver.\n","Predicted translation: this is a problem we have to solve the united states .\n","Real translation: this is a problem we have to solve .\n"]}],"source":["translate(\"este é um problema que temos que resolver.\")\n","print (\"Real translation: this is a problem we have to solve .\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":73},"id":"WkQuQyvjHcbJ","outputId":"fae2b14c-acf1-46ca-ed26-ede08c782d42"},"outputs":[{"name":"stdout","output_type":"stream","text":["Input: os meus vizinhos ouviram sobre esta ideia.\n","Predicted translation: my neighbors heard about this idea .\n","Real translation: and my neighboring homes heard about this idea .\n"]}],"source":["translate(\"os meus vizinhos ouviram sobre esta ideia.\")\n","print (\"Real translation: and my neighboring homes heard about this idea .\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":93},"id":"76ZizBuyPbd8","outputId":"898b2073-8a09-4b22-9218-25cc434df106"},"outputs":[{"name":"stdout","output_type":"stream","text":["Input: vou então muito rapidamente partilhar convosco algumas histórias de algumas coisas mágicas que aconteceram.\n","Predicted translation: so i 'm going to quickly share with you some stories of a few magic things that happened .\n","Real translation: so i 'll just share with you some stories very quickly of some magical things that have happened .\n"]}],"source":["translate(\"vou então muito rapidamente partilhar convosco algumas histórias de algumas coisas mágicas que aconteceram.\")\n","print (\"Real translation: so i 'll just share with you some stories very quickly of some magical things that have happened .\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":73},"id":"29vxXk81PlbE","outputId":"af846b13-dbba-4d83-e267-f9fb68c8417b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Input: este é o primeiro livro que eu fiz.\n","Predicted translation: this is the first book that i did n't .\n","Real translation: this is the first book i've ever done.\n"]}],"source":["translate(\"este é o primeiro livro que eu fiz.\")\n","print (\"Real translation: this is the first book i've ever done.\")"]},{"cell_type":"markdown","metadata":{"id":"xn44IonrZhnV"},"source":["출처  \n","http://jalammar.github.io/illustrated-gpt2/  \n","https://d2l.ai/chapter_recurrent-modern/seq2seq.html  \n","https://www.tensorflow.org/tutorials/text/transformer\n"]}],"metadata":{"colab":{"collapsed_sections":["oJlCBwNE_Sex","ZemqrgPw_bPe","45sJJKmdL8u-"],"machine_shape":"hm","name":"pt_to_en & Transformer (NMT) (3).ipynb","provenance":[]},"hide_input":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":true,"toc_position":{},"toc_section_display":true,"toc_window_display":false},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false}},"nbformat":4,"nbformat_minor":0}