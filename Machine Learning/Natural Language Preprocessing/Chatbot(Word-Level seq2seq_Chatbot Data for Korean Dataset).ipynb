{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Chatbot(Word-Level seq2seq / Chatbot Data for Korean Dataset)","provenance":[],"collapsed_sections":[],"toc_visible":true,"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.9"}},"cells":[{"cell_type":"markdown","metadata":{"id":"wgyWaYYUZMAW"},"source":["# 단어 레벨 챗봇 (함수형 API)"]},{"cell_type":"markdown","metadata":{"id":"a-OZb2-8Zb99"},"source":["이 챗봇은 데이터를 매우 적게 학습하였습니다. 더 많은 데이터를 학습할수록 일반화 능력이 높아집니다."]},{"cell_type":"code","metadata":{"id":"CT-_Zm6lXyku"},"source":["import tensorflow as tf\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import os\n","import re\n","import MeCab\n","import urllib\n","\n","class Mecab:\n","    def pos(self, text):\n","        p = re.compile(\".+\\t[A-Z]+\")\n","        return [tuple(p.match(line).group().split(\"\\t\")) for line in MeCab.Tagger().parse(text).splitlines()[:-1]]\n","    \n","    def morphs(self, text):\n","        p = re.compile(\".+\\t[A-Z]+\")\n","        return [p.match(line).group().split(\"\\t\")[0] for line in MeCab.Tagger().parse(text).splitlines()[:-1]]\n","    \n","    def nouns(self, text):\n","        p = re.compile(\".+\\t[A-Z]+\")\n","        temp = [tuple(p.match(line).group().split(\"\\t\")) for line in MeCab.Tagger().parse(text).splitlines()[:-1]]\n","        nouns=[]\n","        for word in temp:\n","            if word[1] in [\"NNG\", \"NNP\", \"NNB\", \"NNBC\", \"NP\", \"NR\"]:\n","                nouns.append(word[0])\n","        return nouns\n","    \n","mcb = Mecab()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yqNMdM2sygQ5"},"source":["# urllib.request.urlretrieve(\"https://raw.githubusercontent.com/songys/data/master/ChatbotData%20.csv\", filename=\"ChatbotData.csv\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"o_iLXSDtX3Ny"},"source":["# 태그 단어\n","PAD = \"<PAD>\"   # 패딩\n","STA = \"<SOS>\"     # 시작\n","END = \"<EOS>\"       # 끝\n","UNK = \"<UNK>\"       # 없는 단어(Out of Vocabulary)\n","\n","# 태그 인덱스\n","PAD_INDEX = 0\n","STA_INDEX = 1\n","END_INDEX = 2\n","UNK_INDEX = 3\n","\n","# 데이터 타입\n","enc_input  = 0\n","dec_input  = 1\n","dec_output = 2"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7UDGYrvUygQ6"},"source":["# 한 문장에서 단어 시퀀스의 최대 개수\n","max_len = 30\n","# 임베딩 벡터 차원\n","emb_dim = 100\n","\n","# LSTM 히든레이어 차원\n","h_size = 128\n","\n","# 정규 표현식 필터\n","RE_FILTER = re.compile(r\"[.,!?\\'':;~()]\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"r4xQLjCRygQ7"},"source":["data = pd.read_csv(\"ChatbotData .csv\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"b6iq5qQzygQ7","outputId":"513c491c-d494-41bc-9506-aa61467e3e6b"},"source":["data.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Q</th>\n","      <th>A</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>12시 땡!</td>\n","      <td>하루가 또 가네요.</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1지망 학교 떨어졌어</td>\n","      <td>위로해 드립니다.</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3박4일 놀러가고 싶다</td>\n","      <td>여행은 언제나 좋죠.</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3박4일 정도 놀러가고 싶다</td>\n","      <td>여행은 언제나 좋죠.</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>PPL 심하네</td>\n","      <td>눈살이 찌푸려지죠.</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                 Q            A  label\n","0           12시 땡!   하루가 또 가네요.      0\n","1      1지망 학교 떨어졌어    위로해 드립니다.      0\n","2     3박4일 놀러가고 싶다  여행은 언제나 좋죠.      0\n","3  3박4일 정도 놀러가고 싶다  여행은 언제나 좋죠.      0\n","4          PPL 심하네   눈살이 찌푸려지죠.      0"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"afr5Gml7ygQ8","outputId":"d4f5e475-dd16-4750-e1a1-4c3871ebd7bb"},"source":["len(data)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["11823"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"nFafXAy2ygQ9"},"source":["Qs = data[\"Q\"].tolist()[:100]\n","As = data[\"A\"].tolist()[:100]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wPiHbiqPYNx8"},"source":["# # 형태소분석 함수\n","# def pos_tag(sentences):\n","    \n","#     # KoNLPy 형태소분석기 설정\n","#     tagger = Okt()\n","    \n","#     # 문장 품사 변수 초기화\n","#     sentences_pos = []\n","    \n","#     # 모든 문장 반복\n","#     for sentence in sentences:\n","#         # 특수기호 제거\n","#         sentence = re.sub(RE_FILTER, \"\", sentence)\n","        \n","#         # 배열인 형태소분석의 출력을 띄어쓰기로 구분하여 붙임\n","#         sentence = \" \".join(tagger.morphs(sentence))\n","#         sentences_pos.append(sentence)\n","        \n","#     return sentences_pos\n","\n","# # 형태소분석 수행\n","# Q = pos_tag(Q)\n","# A = pos_tag(A)\n","\n","# # 형태소분석으로 변환된 챗봇 데이터 출력\n","# for i in range(10):\n","#     print('Q : ' + Q[i])\n","#     print('A : ' + A[i])\n","#     print()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"h1iJrUckYSK2"},"source":["# # 질문과 대답 문장들을 하나로 합침\n","# sentences = []\n","# sentences.extend(Qs)\n","# sentences.extend(As)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nJY7zE26ygQ-"},"source":["QAs = Qs + As\n","\n","tkn = tf.keras.preprocessing.text.Tokenizer(oov_token=\"UNK\")\n","tkn.fit_on_texts(QAs)\n","\n","word2idx = tkn.word_index\n","idx2word = tkn.index_word"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xZruRs6xygQ-"},"source":["# 태그 단어\n","PAD = \"<PAD>\"   # 패딩\n","STA = \"<SOS>\"     # 시작\n","END = \"<EOS>\"       # 끝\n","UNK = \"<UNK>\"       # 없는 단어(Out of Vocabulary)\n","\n","# 태그 인덱스\n","PAD_INDEX = 0\n","STA_INDEX = 1\n","END_INDEX = 2\n","UNK_INDEX = 3"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jDCtjnQaygQ_","outputId":"8bfff31b-74d7-46c9-9221-5f162ab0a105"},"source":["QAs[2]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'3박4일 놀러가고 싶다'"]},"metadata":{"tags":[]},"execution_count":78}]},{"cell_type":"code","metadata":{"id":"gPFh-5SyygRA","outputId":"260e49ff-5a38-4903-92d7-90ad61180ce6"},"source":["tkn.texts_to_sequences(['3박4일 놀러가고 싶다'])"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[[63, 64, 31]]"]},"metadata":{"tags":[]},"execution_count":79}]},{"cell_type":"code","metadata":{"id":"88QFC-JXYdaq"},"source":["max_len = 30\n","# 문장을 인덱스로 변환\n","def convert_text_to_idx(sents, word2idx, type): \n","    \n","    sents_idx = []\n","    \n","    # 모든 문장에 대해서 반복\n","    for sent in sents:\n","        sent_idx = []\n","        # 디코더 입력일 경우 맨 앞에 START 태그 추가\n","        if type == \"dec_input\":\n","            sent_idx.extend([word2idx[\"<SOS>\"]])\n","        # 문장의 단어들을 띄어쓰기로 분리\n","        for word in sent.split():\n","            # 사전에 있는 단어면 해당 인덱스를 추가\n","            if word2idx[word] != None:\n","                sent_idx.append(word2idx[word])\n","            # 사전에 없는 단어면 UNK 인덱스를 추가\n","            else:\n","                sent_idx.append(word2idx[\"<UNK>\"])\n","\n","        # 최대 길이 검사\n","        if type == \"dec_output\":\n","            # 디코더 목표일 경우 맨 뒤에 END 태그 추가\n","            # 문장의 최대 길이 이상일 경우\n","            if len(sent_idx) >= max_len:\n","                sent_idx = sent_idx[:max_len-1] + [word2idx[\"<EOS>\"]]\n","            else:\n","                sent_idx += [word2idx[\"<EOS>\"]]\n","        else:\n","            if len(sent_idx) > max_len:\n","                sent_idx = sent_idx[:max_len]\n","            \n","        # 최대 길이에 없는 공간은 패딩 인덱스로 채움\n","        sent_idx += (max_len - len(sent_idx)) * [word2idx[\"<PAD>\"]]\n","        \n","        # 문장의 인덱스 배열을 추가\n","        sents_idx.append(sent_idx)\n","\n","    return np.array(sents_idx)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":70},"id":"YPmuWDxOYfRi","outputId":"fe13c520-635d-4953-f64f-e609bb438ab4"},"source":["# 인코더 입력 인덱스 변환\n","x_encoder = convert_text_to_idx(Qs, word_to_index, \"enc_input\")\n","\n","# 첫 번째 인코더 입력 출력 (12시 땡)\n","x_encoder[0]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([ 2775, 20868,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0])"]},"metadata":{"tags":[]},"execution_count":106}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":70},"id":"AAoOMv89YgqV","outputId":"ef4e6a0e-4b0b-4e0f-b06a-ba4895477715"},"source":["# 디코더 입력 인덱스 변환\n","x_decoder = convert_text_to_idx(As, word_to_index, \"dec_input\")\n","\n","# 첫 번째 디코더 입력 출력 (START 하루 가 또 가네요)\n","x_decoder[0]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([    1, 19616,  5970,  1688,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0])"]},"metadata":{"tags":[]},"execution_count":99}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":70},"id":"aHso80jXYhlc","outputId":"be3a6965-6be5-4682-e7d6-78d8ac6e3f25"},"source":["# 디코더 목표 인덱스 변환\n","y_decoder = convert_text_to_idx(As, word_to_index, \"dec_output\")\n","\n","# 첫 번째 디코더 목표 출력 (하루 가 또 가네요 END)\n","y_decoder[0]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([19616,  5970,  1688,     2,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0])"]},"metadata":{"tags":[]},"execution_count":100}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":141},"id":"Ahr_oCPYYkBJ","outputId":"00bc2fbe-1562-496e-c51d-f56014b01793"},"source":["# 원핫인코딩 초기화\n","one_hot_data = np.zeros((len(y_decoder), max_len, len(words)))\n","\n","# 디코더 목표를 원핫인코딩으로 변환\n","# 학습시 입력은 인덱스이지만, 출력은 원핫인코딩 형식임\n","for i, sequence in enumerate(y_decoder):\n","    for j, index in enumerate(sequence):\n","        one_hot_data[i, j, index] = 1\n","\n","# 디코더 목표 설정\n","y_decoder = one_hot_data\n","\n","# 첫 번째 디코더 목표 출력\n","y_decoder[0]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0., 0., 0., ..., 0., 0., 0.],\n","       [0., 0., 0., ..., 0., 0., 0.],\n","       [0., 0., 0., ..., 0., 0., 0.],\n","       ...,\n","       [1., 0., 0., ..., 0., 0., 0.],\n","       [1., 0., 0., ..., 0., 0., 0.],\n","       [1., 0., 0., ..., 0., 0., 0.]])"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":72},"id":"o3gCejxdYnZZ","outputId":"167a6182-a136-46e4-f5d7-11dbfba83c50"},"source":["\n","#--------------------------------------------\n","# 훈련 모델 인코더 정의\n","#--------------------------------------------\n","\n","# 입력 문장의 인덱스 시퀀스를 입력으로 받음\n","enc_inputs = layers.Input(shape=(None,))\n","\n","# 임베딩 레이어\n","encoder_outputs = layers.Embedding(len(words), emb_dim)(enc_inputs)\n","\n","# return_state가 True면 상태값 리턴\n","# LSTM은 state_h(hidden state)와 state_c(cell state) 2개의 상태 존재\n","encoder_outputs, state_h, state_c = layers.LSTM(h_size,\n","                                                dropout=0.1,\n","                                                recurrent_dropout=0.5,\n","                                                return_state=True)(encoder_outputs)\n","\n","# 히든 상태와 셀 상태를 하나로 묶음\n","encoder_states = [state_h, state_c]\n","\n","\n","\n","#--------------------------------------------\n","# 훈련 모델 디코더 정의\n","#--------------------------------------------\n","\n","# 목표 문장의 인덱스 시퀀스를 입력으로 받음\n","dec_inputs = layers.Input(shape=(None,))\n","\n","# 임베딩 레이어\n","decoder_embedding = layers.Embedding(len(words), emb_dim)\n","decoder_outputs = decoder_embedding(dec_inputs)\n","\n","# 인코더와 달리 return_sequences를 True로 설정하여 모든 타임 스텝 출력값 리턴\n","# 모든 타임 스텝의 출력값들을 다음 레이어의 Dense()로 처리하기 위함\n","decoder_lstm = layers.LSTM(h_size,\n","                           dropout=0.1,\n","                           recurrent_dropout=0.5,\n","                           return_state=True,\n","                           return_sequences=True)\n","\n","# initial_state를 인코더의 상태로 초기화\n","decoder_outputs, _, _ = decoder_lstm(decoder_outputs,\n","                                     initial_state=encoder_states)\n","\n","# 단어의 개수만큼 노드의 개수를 설정하여 원핫 형식으로 각 단어 인덱스를 출력\n","decoder_dense = layers.Dense(len(words), activation='softmax')\n","decoder_outputs = decoder_dense(decoder_outputs)\n","\n","\n","\n","#--------------------------------------------\n","# 훈련 모델 정의\n","#--------------------------------------------\n","\n","# 입력과 출력으로 함수형 API 모델 생성\n","model = models.Model([enc_inputs, dec_inputs], decoder_outputs)\n","\n","# 학습 방법 설정\n","model.compile(optimizer='rmsprop',\n","              loss='categorical_crossentropy',\n","              metrics=['accuracy'])"],"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'layers' is not defined","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[1;32m<ipython-input-38-60bac7429db0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# 입력 문장의 인덱스 시퀀스를 입력으로 받음\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mencoder_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# 임베딩 레이어\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mNameError\u001b[0m: name 'layers' is not defined"]}]},{"cell_type":"code","metadata":{"id":"wDAb3Ed1YoLG"},"source":["#--------------------------------------------\n","#  예측 모델 인코더 정의\n","#--------------------------------------------\n","\n","# 훈련 모델의 인코더 상태를 사용하여 예측 모델 인코더 설정\n","encoder_model = models.Model(enc_inputs, encoder_states)\n","\n","\n","\n","#--------------------------------------------\n","# 예측 모델 디코더 정의\n","#--------------------------------------------\n","\n","# 예측시에는 훈련시와 달리 타임 스텝을 한 단계씩 수행\n","# 매번 이전 디코더 상태를 입력으로 받아서 새로 설정\n","decoder_state_input_h = layers.Input(shape=(h_size,))\n","decoder_state_input_c = layers.Input(shape=(h_size,))\n","decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]    \n","\n","# 임베딩 레이어\n","decoder_outputs = decoder_embedding(dec_inputs)\n","\n","# LSTM 레이어\n","decoder_outputs, state_h, state_c = decoder_lstm(decoder_outputs,\n","                                                 initial_state=decoder_states_inputs)\n","\n","# 히든 상태와 셀 상태를 하나로 묶음\n","decoder_states = [state_h, state_c]\n","\n","# Dense 레이어를 통해 원핫 형식으로 각 단어 인덱스를 출력\n","decoder_outputs = decoder_dense(decoder_outputs)\n","\n","# 예측 모델 디코더 설정\n","decoder_model = models.Model([dec_inputs] + decoder_states_inputs,\n","                      [decoder_outputs] + decoder_states)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7neWJ76dYsAz"},"source":["# 인덱스를 문장으로 변환\n","def convert_index_to_text(indexs, vocabulary): \n","    \n","    sentence = ''\n","    \n","    # 모든 문장에 대해서 반복\n","    for index in indexs:\n","        if index == END_INDEX:\n","            # 종료 인덱스면 중지\n","            break;\n","        if vocabulary.get(index) is not None:\n","            # 사전에 있는 인덱스면 해당 단어를 추가\n","            sentence += vocabulary[index]\n","        else:\n","            # 사전에 없는 인덱스면 UNK 단어를 추가\n","            sentence.extend([vocabulary[UNK_INDEX]])\n","            \n","        # 빈칸 추가\n","        sentence += ' '\n","\n","    return sentence"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"669stk8RYu5R","outputId":"59c92497-00cd-4b88-94d9-6c2c60a24a81"},"source":["# 에폭 반복\n","for epoch in range(20):\n","    print('Total Epoch :', epoch + 1)\n","\n","    # 훈련 시작\n","    history = model.fit([x_encoder, x_decoder],\n","                        y_decoder,\n","                        epochs=100,\n","                        batch_size=64,\n","                        verbose=0)\n","    \n","    # 정확도와 손실 출력\n","    print('accuracy :', history.history['accuracy'][-1])\n","    print('loss :', history.history['loss'][-1])\n","    \n","    # 문장 예측 테스트\n","    # (3 박 4일 놀러 가고 싶다) -> (여행 은 언제나 좋죠)\n","    input_encoder = x_encoder[2].reshape(1, x_encoder[2].shape[0])\n","    input_decoder = x_decoder[2].reshape(1, x_decoder[2].shape[0])\n","    results = model.predict([input_encoder, input_decoder])\n","    \n","    # 결과의 원핫인코딩 형식을 인덱스로 변환\n","    # 1축을 기준으로 가장 높은 값의 위치를 구함\n","    indexs = np.argmax(results[0], 1) \n","    \n","    # 인덱스를 문장으로 변환\n","    sentence = convert_index_to_text(indexs, index_to_word)\n","    print(sentence)\n","    print()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Total Epoch : 1\n","accuracy : 0.9266666769981384\n","loss : 0.35812312364578247\n","맛있게 은 언제나 좋죠 \n","\n","Total Epoch : 2\n","accuracy : 0.968999981880188\n","loss : 0.14514704048633575\n","가세 은 언제나 좋죠 \n","\n","Total Epoch : 3\n","accuracy : 0.9739999771118164\n","loss : 0.08765653520822525\n","가세 은 언제나 좋죠 \n","\n","Total Epoch : 4\n","accuracy : 0.9783333539962769\n","loss : 0.06297517567873001\n","가세 은 언제나 좋죠 \n","\n","Total Epoch : 5\n","accuracy : 0.9853333234786987\n","loss : 0.044016480445861816\n","가세 은 언제나 좋죠 \n","\n","Total Epoch : 6\n","accuracy : 0.9919999837875366\n","loss : 0.027679210528731346\n","여행 은 언제나 좋죠 \n","\n","Total Epoch : 7\n","accuracy : 0.9953333139419556\n","loss : 0.017140144482254982\n","여행 은 언제나 좋죠 \n","\n","Total Epoch : 8\n","accuracy : 0.996999979019165\n","loss : 0.011556596495211124\n","여행 은 언제나 좋죠 \n","\n","Total Epoch : 9\n","accuracy : 0.9990000128746033\n","loss : 0.005027387291193008\n","여행 은 언제나 좋죠 \n","\n","Total Epoch : 10\n","accuracy : 0.999666690826416\n","loss : 0.0017524176510050893\n","여행 은 언제나 좋죠 \n","\n","Total Epoch : 11\n","accuracy : 1.0\n","loss : 0.0006122245686128736\n","여행 은 언제나 좋죠 \n","\n","Total Epoch : 12\n","accuracy : 0.9990000128746033\n","loss : 0.001641127746552229\n","여행 은 언제나 좋죠 \n","\n","Total Epoch : 13\n","accuracy : 1.0\n","loss : 0.00019004421483259648\n","여행 은 언제나 좋죠 \n","\n","Total Epoch : 14\n","accuracy : 0.999666690826416\n","loss : 0.0008484653662890196\n","여행 은 언제나 좋죠 \n","\n","Total Epoch : 15\n","accuracy : 1.0\n","loss : 0.00014795167953707278\n","여행 은 언제나 좋죠 \n","\n","Total Epoch : 16\n","accuracy : 0.999666690826416\n","loss : 0.001423284295015037\n","여행 은 언제나 좋죠 \n","\n","Total Epoch : 17\n","accuracy : 1.0\n","loss : 2.6036621420644224e-05\n","여행 은 언제나 좋죠 \n","\n","Total Epoch : 18\n","accuracy : 1.0\n","loss : 1.404542854288593e-05\n","여행 은 언제나 좋죠 \n","\n","Total Epoch : 19\n","accuracy : 1.0\n","loss : 2.56245239143027e-05\n","여행 은 언제나 좋죠 \n","\n","Total Epoch : 20\n","accuracy : 1.0\n","loss : 8.548993719159625e-06\n","여행 은 언제나 좋죠 \n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vwJGM_ABYxEO"},"source":["# 예측을 위한 입력 생성\n","def make_predict_input(sentence):\n","\n","    sentences = []\n","    sentences.append(sentence)\n","    sentences = pos_tag(sentences)\n","    input_seq = convert_text_to_index(sentences, word_to_index, enc_input)\n","    \n","    return input_seq"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TJgBsvDYYyvS"},"source":["# 텍스트 생성\n","def generate_text(input_seq):\n","    \n","    # 입력을 인코더에 넣어 마지막 상태 구함\n","    states = encoder_model.predict(input_seq)\n","\n","    # 목표 시퀀스 초기화\n","    target_seq = np.zeros((1, 1))\n","    \n","    # 목표 시퀀스의 첫 번째에 <SOS> 태그 추가\n","    target_seq[0, 0] = STA_INDEX\n","    \n","    # 인덱스 초기화\n","    indexs = []\n","    \n","    # 디코더 타임 스텝 반복\n","    while 1:\n","        # 디코더로 현재 타임 스텝 출력 구함\n","        # 처음에는 인코더 상태를, 다음부터 이전 디코더 상태로 초기화\n","        decoder_outputs, state_h, state_c = decoder_model.predict(\n","                                                [target_seq] + states)\n","\n","        # 결과의 원핫인코딩 형식을 인덱스로 변환\n","        index = np.argmax(decoder_outputs[0, 0, :])\n","        indexs.append(index)\n","        \n","        # 종료 검사\n","        if index == END_INDEX or len(indexs) >= max_len:\n","            break\n","\n","        # 목표 시퀀스를 바로 이전의 출력으로 설정\n","        target_seq = np.zeros((1, 1))\n","        target_seq[0, 0] = index\n","        \n","        # 디코더의 이전 상태를 다음 디코더 예측에 사용\n","        states = [state_h, state_c]\n","\n","    # 인덱스를 문장으로 변환\n","    sentence = convert_index_to_text(indexs, index_to_word)\n","        \n","    return sentence"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":70},"id":"Dt_eySPHY0dJ","outputId":"2d3c1212-b761-4616-f3a5-83307c2fbfe2"},"source":["# 문장을 인덱스로 변환\n","input_seq = make_predict_input('3박4일 놀러가고 싶다')\n","input_seq"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[372, 366, 236, 244, 412, 183,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0,   0,   0]])"]},"metadata":{"tags":[]},"execution_count":30}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"id":"LGKwqd-PY11D","outputId":"7baee97a-f36b-4a07-f1fc-8bc17391fe5e"},"source":["# 예측 모델로 텍스트 생성\n","sentence = generate_text(input_seq)\n","sentence"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic":{"type":"string"},"text/plain":["'여행 은 언제나 좋죠 '"]},"metadata":{"tags":[]},"execution_count":31}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":70},"id":"joK8S2AqY3r9","outputId":"c0bfd67c-b4c4-4c39-ea56-5757ed434d1d"},"source":["# 문장을 인덱스로 변환\n","input_seq = make_predict_input('3박4일 같이 놀러가고 싶다')\n","input_seq"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[372, 366, 236, 153, 244, 412, 183,   0,   0,   0,   0,   0,   0,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0,   0,   0]])"]},"metadata":{"tags":[]},"execution_count":32}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":214},"id":"QiJ_ZyaXY5Tc","outputId":"a0ad1572-bf99-4f0f-c339-9f7dd08ad13f"},"source":["# 예측 모델로 텍스트 생성\n","sentence = generate_text(input_seq)\n","sentence"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic":{"type":"string"},"text/plain":["'여행 은 언제나 좋죠 '"]},"metadata":{"tags":[]},"execution_count":33}]}]}