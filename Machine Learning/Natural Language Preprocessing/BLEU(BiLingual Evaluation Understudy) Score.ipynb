{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"BLEU(BiLingual Evaluation Understudy) Score","provenance":[],"collapsed_sections":[],"toc_visible":true,"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.9"}},"cells":[{"cell_type":"markdown","metadata":{"id":"5cjgTLDG0iww"},"source":["- RBMT : 언어학자 -> SMT : 언어학자를 해고할수록 성능 증가(n-gram)\n","- seq2seq는 사실 문제가 있음 -> attention 필수(기억력의 문제 보정)\n","- 단어 시퀀스에 확률을 할당하기 위한 학습 방법이 이전 단어로부터 다음 단어을 예측하는 것.\n","- seq2seq로 만든 챗봇은 open domain\n","- 마지막 단어의 hidden state = context\n","- beam search : 성능에 영향 큼\n","- 숙제 : 서브클래싱 구현"]},{"cell_type":"markdown","metadata":{"id":"iIEwBs6S0iw8"},"source":["# BiLingual Evaluation Understudy Score\n","- BLEU는 기계 번역 결과와 사람이 직접 번역한 결과가 얼마나 유사한지 비교하여 번역에 대한 성능을 측정하는 방법입니다. 측정 기준은 n-gram에 기반합니다.\n","- 번역된 문장을 `cand`(candidate), 완벽한 번역 문장을 `ref`(Reference)라고 하겠습니다."]},{"cell_type":"code","metadata":{"id":"kb9QnE3_0iw-"},"source":["import nltk\n","import tensorflow as tf\n","import tensorflow_datasets as tfds\n","import tensorflow_hub as hub\n","import matplotlib.pyplot as plt\n","import seaborn as sb\n","import pandas as pd\n","import numpy as np\n","import re\n","import os\n","import wget\n","import urllib\n","import sentencepiece as sp\n","import csv\n","import urllib3\n","import zipfile\n","import shutil\n","from collections import Counter"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"k7BhqvQ6xLTi"},"source":["## 1. 직접 구현하기"]},{"cell_type":"code","metadata":{"id":"Yi7AfUmRxYgZ"},"source":["def get_ngram2cnt(cand, n):\n","    return Counter(nltk.ngrams(cand, n))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ytGG39gC0ixA","outputId":"3799c0ac-2575-4a7b-dfda-f9de4bece902"},"source":["get_ngram2cnt(cand1, 3)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Counter({('it', 'is', 'a'): 1,\n","         ('is', 'a', 'guide'): 1,\n","         ('a', 'guide', 'to'): 1,\n","         ('guide', 'to', 'action'): 1,\n","         ('to', 'action', 'which'): 1,\n","         ('action', 'which', 'ensures'): 1,\n","         ('which', 'ensures', 'that'): 1,\n","         ('ensures', 'that', 'the'): 1,\n","         ('that', 'the', 'military'): 1,\n","         ('the', 'military', 'always'): 1,\n","         ('military', 'always', 'obeys'): 1,\n","         ('always', 'obeys', 'the'): 1,\n","         ('obeys', 'the', 'commands'): 1,\n","         ('the', 'commands', 'of'): 1,\n","         ('commands', 'of', 'the'): 1,\n","         ('of', 'the', 'party'): 1})"]},"metadata":{"tags":[]},"execution_count":240}]},{"cell_type":"markdown","metadata":{"id":"KoNmktwjxieM"},"source":["### 1-1. N-gram Precision"]},{"cell_type":"code","metadata":{"id":"i_zjPuyW0ixC"},"source":["def get_ngram_precision(cand, refs, n):\n","    ngram2cnt_refs = Counter()\n","    for ref in refs:\n","        ngram2cnt_refs += get_ngram2cnt(ref, n)\n","    ngrams_in_refs = 0\n","    len_cand = 0\n","    for ngram, cnt in get_ngram2cnt(cand, n).items():\n","        if ngram in ngram2cnt_refs:\n","            ngrams_in_refs += cnt \n","        len_cand += cnt\n","    return ngrams_in_refs/len_cand"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"id":"lTPdHH_e0ixD","outputId":"5c027715-6d09-4942-8dea-a548df56653a"},"source":["print(get_ngram_precision(cand1, refs, 1))\n","print(get_ngram_precision(cand2, refs, 1))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0.9444444444444444\n","0.5714285714285714\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"uSXUjRrN0ixE"},"source":["### 1-2. Modified N-gram Precision"]},{"cell_type":"code","metadata":{"id":"6vz7FgLi0ixE"},"source":["def get_modified_ngram_precision(cand, refs, n):\n","    def get_count_clip(ngram, cand, refs, n):\n","        def get_max_ref_count(ngram, refs, n):\n","            temp = list()\n","            for ref in refs:\n","                ngram2cnt_ref = get_ngram2cnt(ref, n)\n","                temp.append(ngram2cnt_ref[ngram])\n","            return max(temp)    \n","\n","        def get_count(ngram, cand, n):\n","            return get_ngram2cnt(cand, 1)[ngram]\n","\n","        return min(get_count(ngram, cand, n), get_max_ref_count(ngram, refs, n))\n","    \n","    sum_countclip = 0\n","    len_cand = 0\n","    for ngram, cnt in get_ngram2cnt(cand, n).items():\n","        sum_countclip += get_count_clip(ngram, cand, refs, n)\n","        len_cand += cnt\n","    return sum_countclip/len_cand"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ri4LNA260ixG","outputId":"ba5b1486-9477-48d1-f504-7e6373635219"},"source":["print(get_modified_ngram_precision(cand1, refs, 1))\n","print(get_modified_ngram_precision(cand2, refs, 1))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0.9444444444444444\n","0.5714285714285714\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4PiWATOk0ixH","outputId":"c9ceba5c-33b0-45c0-96c5-17b8d026db46"},"source":["cand = \"the the the the the the the\"\n","print(get_ngram_precision(cand.split(\" \"), refs, 1))\n","print(get_modified_ngram_precision(cand.split(\" \"), refs, 1))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["1.0\n","0.5714285714285714\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"rgsirDfSkpEF"},"source":["### 1-3. 짧은 문장 길이에 대한 패널티(Brevity Penalty)"]},{"cell_type":"markdown","metadata":{"id":"cQ9K0Zqzk_xU"},"source":["Ref가 1개라면 Ca와 Ref의 두 문장의 길이만을 가지고 계산하면 되겠지만 여기서는 Ref가 여러 개일 때를 가정하고 있으므로 r은 \"모든 Ref들 중에서 Ca와 가장 길이 차이가 작은 Ref의 길이\"로 합니다. r을 구하는 코드는 아래와 같습니다."]},{"cell_type":"code","metadata":{"id":"RQUUVtYXkhET"},"source":["def closest_ref_length(cand, ref_list): # Ca 길이와 가장 근접한 Ref의 길이를 리턴하는 함수\n","    ca_len = len(cand) # ca 길이\n","    ref_lens = (len(ref) for ref in ref_list) # Ref들의 길이\n","    closest_ref_len = min(ref_lens, key=lambda ref_len: (abs(ref_len - ca_len), ref_len))\n","    # 길이 차이를 최소화하는 Ref를 찾아서 Ref의 길이를 리턴\n","    return closest_ref_len"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9z3PfH-2lDpS"},"source":["만약 Ca와 길이가 정확히 동일한 Ref가 있다면 길이 차이가 0인 최고 수준의 매치(best match length)입니다. 또한 만약 서로 다른 길이의 Ref이지만 Ca와 길이 차이가 동일한 경우에는 더 작은 길이의 Ref를 택합니다. 예를 들어 Ca가 길이가 10인데, Ref 1, 2가 각각 9와 11이라면 길이 차이는 동일하게 1밖에 나지 않지만 9를 택합니다. closest_ref_length 함수를 통해 r을 구했다면, 이제 BP를 구하는 함수 brevity_penalty를 구현해봅시다."]},{"cell_type":"code","metadata":{"id":"MQhnL1IFlFhj"},"source":["def brevity_penalty(cand, ref_list):\n","    ca_len = len(cand)\n","    ref_len = closest_ref_length(cand, ref_list)\n","\n","    if ca_len > ref_len:\n","        return 1\n","    elif ca_len == 0 :\n","    # cand가 비어있다면 BP = 0 → BLEU = 0.0\n","        return 0\n","    else:\n","        return np.exp(1 - ref_len/ca_len)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"t-3GR1lhlNLN"},"source":["## BLEU 함수 구현하기"]},{"cell_type":"markdown","metadata":{"id":"57DM-GuqlILF"},"source":["이제 최종적으로 BLEU 점수를 계산하는 함수 bleu_score를 구현해봅시다."]},{"cell_type":"code","metadata":{"id":"v9veUzn1lGP6"},"source":["def bleu_score(cand, ref_list, weights=[0.25, 0.25, 0.25, 0.25]):\n","    bp = brevity_penalty(cand, ref_list) # 브레버티 패널티, BP\n","\n","    p_n = [modified_precision(cand, ref_list, n=n) for n, _ in enumerate(weights,start=1)] \n","    #p1, p2, p3, ..., pn\n","    score = np.sum([w_i * np.log(p_i) if p_i != 0 else 0 for w_i, p_i in zip(weights, p_n)])\n","    return bp * np.exp(score)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SbUorUGolQ4x"},"source":["위 함수가 동작하기 위해서는 앞서 구현한 get_ngram2cnt, count_clip, modified_precision, brevity_penalty 4개의 함수 또한 모두 구현되어져 있어야 합니다. 지금까지 구현한 BLEU 코드로 계산된 점수와 NLTK 패키지에 이미 구현되어져 있는 BLEU 코드로 계산된 점수를 비교해봅시다."]},{"cell_type":"markdown","metadata":{"id":"wJrYyJOqxE5b"},"source":["## 2. nltk.translate.bleu_score.sentence_bleu()"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"id":"DwlomX-d1TSa","outputId":"e733e272-62e5-4542-8778-3e20acdd5b2e"},"source":["ref = [[\"this\", \"is\", \"a\", \"test\"], [\"this\", \"is\" \"test\"]]\n","cand = [\"this\", \"is\", \"a\", \"test\"]\n","score = nltk.translate.bleu_score.sentence_bleu(ref, cand)\n","print(score)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["1.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"id":"QpDcrpU-26Lu","outputId":"f7fc1f05-e620-4c07-ddec-a647d45b1b30"},"source":["refs = [[[\"this\", \"is\", \"a\", \"test\"], [\"this\", \"is\" \"test\"]]]\n","cands = [[\"this\", \"is\", \"a\", \"test\"]]\n","score = nltk.translate.bleu_score.corpus_bleu(refs, cands)\n","print(score)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["1.0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"d3xs_bcp34V9"},"source":["- 각 N-gram(N = 1, 2, 3, 4)에 대해 가중치를 서로 다르게 설정해 weighted geometric mean을 구할 수도 있습니다.\n","- 몇 개의 N-gram을 사용하느냐에 따라 BLEU-1, BLEU-2, BLEU-3, BLEU-4라고 부릅니다."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":158},"id":"nJkNdjXA6AVO","outputId":"b7e4fbc8-3689-47f9-a33d-bf123939efcd"},"source":["# cumulative BLEU scores\n","ref = [[\"this\", \"is\", \"small\", \"test\"]]\n","cand = [\"this\", \"is\", \"a\", \"test\"]\n","\n","print(f\"BLEU-2 = {nltk.translate.bleu_score.sentence_bleu(ref, cand, weights=(1/2, 1/2, 0, 0))}\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["BLEU-2 = 0.49999999999999994\n"],"name":"stdout"},{"output_type":"stream","text":["C:\\Users\\5CG7092POZ\\Anaconda3\\envs\\tf2.3\\lib\\site-packages\\nltk\\translate\\bleu_score.py:516: UserWarning: \n","The hypothesis contains 0 counts of 3-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n","C:\\Users\\5CG7092POZ\\Anaconda3\\envs\\tf2.3\\lib\\site-packages\\nltk\\translate\\bleu_score.py:516: UserWarning: \n","The hypothesis contains 0 counts of 4-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"y3LGHmUPlUWz"},"source":["## NLTK의 BLEU Vs. 구현한 BLEU 함수"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":52},"id":"h0uOo_H-lXbz","outputId":"6ad2db98-ac10-4462-b3b0-c2a217fc06ee"},"source":["import nltk.translate.bleu_score as bleu\n","\n","\n","cand = \"It is a guide to action which ensures that the military always obeys the commands of the party\"\n","refs = [\n","    \"It is a guide to action that ensures that the military will forever heed Party commands\",\n","    \"It is the guiding principle which guarantees the military forces always being under the command of the Party\",\n","    \"It is the practical guide for the army always to heed the directions of the party\"\n","]\n","\n","# 이번 챕터에서 구현한 코드로 계산한 BLEU 점수\n","print(bleu_score(cand.split(),list(map(lambda ref: ref.split(), refs))))\n","# NLTK 패키지 구현되어져 있는 코드로 계산한 BLEU 점수\n","print(bleu.nltk.translate.bleu_score.sentence_bleu(list(map(lambda ref: ref.split(), refs)),cand.split()))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0.5045666840058485\n","0.5045666840058485\n"],"name":"stdout"}]}]}