{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Greedy Search vs. Beam Search","provenance":[],"collapsed_sections":[],"toc_visible":true,"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.9"}},"cells":[{"cell_type":"code","metadata":{"id":"6owvXYYCcPcR"},"source":["import math\n","import numpy as np"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fymMbyfGrIMU"},"source":["# 단어 집합의 크기가 5.\n","# 길이 10까지의 시퀀스가 예측된 상태라고 하였을 때, 확률 분포를 통해 각 단어를 예측한다고 해보자.\n","\n","data = [[0.1, 0.2, 0.3, 0.4, 0.5], [0.5, 0.4, 0.3, 0.2, 0.1], [0.1, 0.2, 0.3, 0.4, 0.5], [0.5, 0.4, 0.3, 0.2, 0.1], [0.1, 0.2, 0.3, 0.4, 0.5], [0.5, 0.4, 0.3, 0.2, 0.1], [0.1, 0.2, 0.3, 0.4, 0.5], [0.5, 0.4, 0.3, 0.2, 0.1], [0.1, 0.2, 0.3, 0.4, 0.5], [0.5, 0.4, 0.3, 0.2, 0.1]]\n","data = np.array(data)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wQ0wtBYIc5i7"},"source":["## 1. Greedy Search\n","- seq2seq의디코더는기본적으로는RNN 언어모델이다.\n","- •디코더(RNN 언어모델)는매시점마다가장높은확률을가지는단어를선택한다.\n","- 이를Greedy Decoding이라고한다.\n","- Greedy Decoding은매순간에서의최적의선택을한다.\n","- 하지만전체적으로봤을때는그순간의선택이최적의선택이아닐수있다.\n","- Greedy Decoding은순간잘못된선택을했더라도그결정을취소할수없다."]},{"cell_type":"code","metadata":{"id":"syY-O2YJcH6i"},"source":["# 그리디 디코더는 가장 확률이 높은 인덱스를 리턴한다.\n","def greedy_decoder(data):\n","\treturn [np.argmax(s) for s in data]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"id":"3v7dIpHLcQ2W","outputId":"1180e58f-747f-4629-eac8-bf14d0d9adf2"},"source":["result = greedy_decoder(data)\n","print(result)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[4, 0, 4, 0, 4, 0, 4, 0, 4, 0]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"sniA-i8GcZrd"},"source":["## 2. Beam Search"]},{"cell_type":"markdown","metadata":{"id":"WxDi9mmCcfqu"},"source":["- 주어진 확률 시퀀스와 빔 크기 k에 대해 빔 탐색을 수행하는 함수를 작성한다.  \n","    - 각 후보 시퀀스는 가능한한 모든 다음 스텝들에 대해 확장된다.  \n","    - 각 후보는 확률을 곱함으로써 점수가 매겨진다.  \n","    - 가장 확률이 높은 k개의 시퀀스가 선택되고, 다른 모든 후보들은 제거된다.  \n","    - 위 절차들을 시퀀스가 끝날때까지 반복한다.\n","- 매시점마다가장확률이높은k개의다음단어를선택후, 다음시점단어들의확률예측.\n","- k * Vocab-size 개의후보군중다시확률이높은k개의후보군만선택하고나머지단어는제거\n","- 최종적으로k*k개의후보군중에서가장확률이높은k개의후보군만을유지\n","- Beam Search Decoding 또한항상최적해를보장하지는않지만Exhaustive search보다효율적.\n","- Greedy Search Decoding이놓칠수있는더나은후보군을유지할수있음."]},{"cell_type":"code","metadata":{"id":"X34T2LH70xu3","outputId":"f1fbe014-122d-4366-865c-1d6a4aebca74"},"source":["k = 3\n","# def beam_search_decoder(data, k):\n","seq_score = [[[], 0.0]]\n","for probs in data:\n","    all_cands = list()\n","    for seq, score in seq_score:\n","        for idx, prob in enumerate(probs):\n","            cand = [seq + [idx], score - np.log(prob)]\n","            all_cands.append(cand)\n","    #score를 기준으로 오름차순 정렬합니다.\n","    all_cands = sorted(all_cands, key=lambda x:x[1])\n","    # score 상위 3개만 선택합니다.\n","    seq_score = all_cands[:k]\n","print(seq_score)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[[[4, 0, 4, 0, 4, 0, 4, 0, 4, 0], 6.931471805599453], [[4, 0, 4, 0, 4, 0, 4, 0, 4, 1], 7.154615356913663], [[4, 0, 4, 0, 4, 0, 4, 0, 3, 0], 7.154615356913663]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":70},"id":"z2A7V9pIcmuX","outputId":"34275dcb-01cc-4a4d-93f1-f7e8e10d7934"},"source":["result = beam_search_decoder(data, 3)\n","\n","for seq in result:\n","    print(seq)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[[4, 0, 4, 0, 4, 0, 4, 0, 4, 0], 6.931471805599453]\n","[[4, 0, 4, 0, 4, 0, 4, 0, 4, 1], 7.154615356913663]\n","[[4, 0, 4, 0, 4, 0, 4, 0, 3, 0], 7.154615356913663]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pU5K5Egk0xu4"},"source":[""],"execution_count":null,"outputs":[]}]}