# Paper Reading
- [Hide-and-Seek: Forcing a Network to be Meticulous for Weakly-supervised Object and Action Localization](https://arxiv.org/pdf/1704.04232.pdf)

- How- ever, due to intra-category variations or relying only on a classification objective, these methods often fail to identify the entire extent of the object and instead localize only the most discriminative part.

- Figure 1. Main idea. (Top row) A network tends to focus on the most discriminative parts of an image (e.g., face of the dog) for classification. (Bottom row) By hiding images patches randomly, we can force the network to focus on other relevant object parts in order to correctly classify the image as ’dog’.

- we make changes to the input image. The key idea is to hide patches from an image during training so that the model needs to seek the relevant object parts from what remains. We thus name our approach ‘Hide-and-Seek’. Figure 1 (bottom row) demonstrates the intuition: if we randomly remove some patches from the image then there is a possibility that the dog’s face, which is the most discriminative, will not be visible to the model. In this case, the model must seek other relevant parts like the tail and legs in order to do well on the classification task. By randomly hiding different patches in each training epoch, the model sees different parts of the image and is forced to focus on multiple relevant parts of the object beyond just the most discriminative one. Impor- tantly, we only apply this random hiding of patches during training and not during testing. Since the full image is ob- served during testing, the data distribution will be different to that seen during training. We show that setting the hidden pixels’ value to be the data mean can allow the two distri- butions to match, and provide a theoretical justification.

- require expensive human annotations for training (e.g. bounding box for object localization). To alle- viate expensive annotation costs, weakly-supervised approaches learn using cheaper labels, for example, image-level labels for predicting an object’s loca- tion [55, 13, 9, 41, 3, 43, 50, 8, 32, 61].

- Most weakly-supervised object localization approaches mine discriminative features or patches in the data that fre- quently appear in one class and rarely in other classes [55, 13, 9, 41, 3, 7, 42, 43, 8]. However, these approaches tend to focus only on the most discriminative parts, and thus fail to cover the entire spatial extent of an object. In our approach, we hide image patches (randomly) during training, which forces our model to focus on multiple parts of an object and not just the most discriminative ones.

- Recent work modify CNN architectures designed for im- age classification so that the convolutional layers learn to localize objects while performing image classification [32, 61]. Other network architectures have been designed for weakly-supervised object detection [20, 4, 24]. Although these methods have significantly improved the state-of-the- art, they still essentially rely on a classification objective and thus can fail to capture the full extent of an object if the less discriminative parts do not help improve classifica- tion performance.

- for object localization, [59, 1] train a CNN for image classification and then localize the regions whose masking leads to a large drop in classification performance. Since these approaches mask out the image regions only during testing and not during training, the lo- calized regions are limited to the highly-discriminative ob- ject parts