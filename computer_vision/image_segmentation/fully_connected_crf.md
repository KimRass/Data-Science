- The model employs the energy function
$$E(x) = \sum_i \theta _i(x_i) + \sum _{ij} \theta _{ij}(x_i, x_j)$$
- where $x$ is the label assignment for pixels. We use as unary potential $\theta _i(x_i) = âˆ’\log P(x_{i})$, where $P(x_i)$ is the label assignment probability at pixel $i$ as computed by a DCNN [2]
- The pairwise potential has a form that allows for efficient inference while using a fully-connected graph, i.e. when connecting all pairs of image pixels, i, j. In particular, as in [22], we use the following expression: [2]
$$\theta_{ij}(x_i, x_j) = \mu(x_i, x_j) \bigg[\omega_{1}\exp\Big(- \frac{\lVert p_{i} - p_{j} \rVert^2}{2\sigma_{\alpha}^2} - \frac{\lVert I_{i} - I_{j} \rVert^2}{2\sigma_{\beta}^2} \Big) + \omega_{2} \exp\Big(- \frac{\lVert p_{i} - p_{j} \rVert^2}{2\sigma_{\gamma}^2} \Big) \bigg]$$
- where $\mu _{ij} (x_i, x_j) = 1$ if $x_i \ne x_j$, and $0$ otherwise, which means that only nodes with distinct labels are penalized. The remaining expression uses two Gaussian kernels in different feature spaces; the first, 'bilateral' kernel depends on both pixel positions (denoted as $p$) and RGB color (denoted as $I$), and the second kernel only depends on pixel positions. The hyper parameters $\sigma _\alpha$, $\sigma _\beta$ and $\sigma _\gamma$ control the scale of Gaussian kernels. The first kernel forces pixels with similar position and color to have similar labels, while the second kernel only considers spatial proximity when enforcing smoothness. [2]

```python
import denseCRF
    Iq = img
    prob = np.dstack(
        [(segmap_text == label).astype("float32") for label in np.unique(segmap_text)]
    )

    w1    = 10.0  # weight of bilateral term
    alpha = 40    # spatial std
    beta  = 13    # rgb  std
    w2    = 3.0   # weight of spatial term
    gamma = 3     # spatial std
    it    = 10    # iteration
    lab = denseCRF.densecrf(Iq, prob, (w1, alpha, beta, w2, gamma, it))
    lab *= 255

    show_image(lab != 0)
```
```python
# `unary_from_labels`: # Get unary potentials `U` (negative log probability) from a hard labeling generated by a human or some other processing.
# `zero_unsure`:
    # If `True`, treat the label value `0` as meaning "could be anything", i.e. entries with this value will get uniform unary probability.
    # If `False`, do not treat the value `0` specially, but just as any other class.
# `U`: (n_labels, width_img * img_height)
U = unary_from_labels(
    labels=labels, n_labels=n_labels, gt_prob=0.7, zero_unsure=has_unknown_color
)
# `unary_from_softmax`: From a probability distribution computed by the softmax output of a deep network
d.setUnaryEnergy(U)
# This adds the color-independent term, features are the locations only.
d.addPairwiseGaussian(
    sxy=(1, 1),
    compat=3,
    kernel=dcrf.DIAG_KERNEL,
    normalization=dcrf.NORMALIZE_SYMMETRIC
)
# This adds the color-dependent term, i.e. features are (x,y,r,g,b).
d.addPairwiseBilateral(
    sxy=(40, 40),
    srgb=(3, 3, 3),
    rgbim=img,
    compat=10,
    kernel=dcrf.DIAG_KERNEL,
    normalization=dcrf.NORMALIZE_SYMMETRIC
)
Q = d.inference(iterations)
# Find out the most probable class for each pixel.
result = np.argmax(Q, axis=0)

# Convert the MAP (labels) back to the corresponding colors
```

# References
- [2] [DeepLab: Semantic Image Segmentation with Deep Convolutional Nets, Atrous Convolution, and Fully Connected CRFs](https://arxiv.org/pdf/1606.00915.pdf)