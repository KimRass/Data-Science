# Paper Reading
- [Improved Regularization of Convolutional Neural Networks with Cutout](https://arxiv.org/pdf/1708.04552.pdf)
## Introduction
- Figure 2: Early version of Cutout
    - <img src="https://user-images.githubusercontent.com/105417680/229456926-0e88f892-08c7-4c3e-8a9d-c2ebe42a44e3.png" width="700">
    - We initially developed Cutout as a targeted approach that specifically removed important visual features from the input of the image. This approach was similar to max-drop, ***in that we aimed to remove maximally activated features in order to encourage the network to consider less prominent features. To accomplish this goal, we extracted and stored the maximally activated feature map for each image in the dataset at each epoch. During the next epoch we then upsampled the saved feature maps back to the input resolution, and thresholded them at the mean feature map value to obtain a binary mask, which was finally overlaid on the original image before being passed through the CNN.***
    - ***While this targeted Cutout method performed well, we found that randomly removing regions of a fixed size performed just as well as the targeted approach, without requiring any manipulation of the feature maps. Due to the inherent simplicity of this alternative approach, we focus on removing fixed-size regions for all of our experiments.***
## Methodology
- Figure 1: Cutout-applied images
    - <img src="https://user-images.githubusercontent.com/105417680/229457689-1ea11dd7-4f30-4774-9e99-bccefd6c4164.png" width="400">
    - To implement Cutout, we simply apply a fixed-size zero-mask to a random location of each input image during each epoch of training. Unlike dropout and its variants, we do not apply any rescaling of weights at test time. For best performance, ***the dataset should be normalized about zero so that modified images will not have a large effect on the expected batch statistics.*** In general, we found that the size of the Cutout region is a more important hyperparameter than the shape, so for simplicity, we conduct all of our experiments using a square patch as the Cutout region. When Cutout is applied to an image, ***we randomly select a pixel coordinate within the image as a center point and then place the Cutout mask around that location. This method allows for the possibility that not all parts of the Cutout mask are contained within the image. Interestingly, we found that allowing portions of the patches to lay outside the borders of the image (rather than constraining the entire patch to be within the image) was critical to achieving good performance. Our explanation for this phenomenon is that it is important for the model to receive some examples where a large portion of the image is visible during training. An alternative approach that achieves similar performance is to randomly apply Cutout constrained within the image region, but with 50% probability so that the network sometimes receives unmodified images.***
## Experiments
- Figure 3
    - <img src="https://user-images.githubusercontent.com/105417680/229458790-c47a4ef5-dce4-42de-b257-4e914188536e.png" width="700">
    - ***We find that model accuracy follows a parabolic trend, increasing proportionally to the Cutout size until an optimal point, after which accuracy again decreases and eventually drops below that of the baseline model.***
    - ***Based on these validation results we select a Cutout size of 16 × 16 pixels to use on CIFAR-10 and a Cutout size of 8 × 8 pixels for CIFAR-100 when training on the full datasets. Interestingly, it appears that as the number of classes increases, the optimal Cutout size decreases. This makes sense, as when more fine-grained detection is required then the context of the image will be less useful for identifying the category. Instead, smaller and more nuanced details are important.*** (Comment: Cutout size가 클수록 Cutout의 효과는 커집니다. Cutout의 효과는 모델이 이미지에서 dicriminative parts만이 아니라 non-discriminative parts를 포함한 전체 context를 보도록 하는 것입니다. number of classes가 커질수록 모델이 각 클래스를 구분하기 위해서는 이미지에서 discriminative parts를 보아야 하므로 작은 Cutout size가 필요한 것입니다.)
## Conclusion
- Cutout was originally conceived as a targeted method for removing visual features with high activations in later layers of a CNN. Our motivation was to encourage the network to focus more on complimentary and less prominent features, in order to generalize to situations like occlusion. However, we discovered that the conceptually and computationally simpler approach of randomly masking square sections of the image performed equivalently in the experiments we conducted. Importantly, this simple regularizer proved to be complementary to existing forms of data augmentation and regularization
